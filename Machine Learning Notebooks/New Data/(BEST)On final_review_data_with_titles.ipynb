{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will use the same Artificial Neural Networks as in ANN(Deep and Wide with High Nodes Vs Low Nodes) but we will scale the dataset using StandardScaler from sklearn and also use the dataset with Z_Scores of Words and Helpful Votes\n",
    "TARGET LABEL: Z_Score_HelpfulVotes\n",
    "SCALER: STANDARD SCALER\n",
    "ANN'S : \n",
    "\n",
    "        Combination 1: 7-100-100-1\n",
    "        \n",
    "        Combination 2:  7-4-4-1\n",
    "\n",
    "        Combination 3:  7-50-100-200-100-50-20-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Stars', 'Helpful Votes', 'Z_Score_HelpfulVotes', 'Words',\n",
      "       'Z_Score_Words', 'Paragraphs', 'No.break tags', 'Percentage_Upper_Case',\n",
      "       'Percentage_Lower_Case', 'Avg_len_paragraph_per_review', 'Words_Title',\n",
      "       'Chars_Title', 'Upper_percentage', 'Lower_percentage'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Z_Score_Words</th>\n",
       "      <th>Paragraphs</th>\n",
       "      <th>No.break tags</th>\n",
       "      <th>Percentage_Upper_Case</th>\n",
       "      <th>Percentage_Lower_Case</th>\n",
       "      <th>Avg_len_paragraph_per_review</th>\n",
       "      <th>Words_Title</th>\n",
       "      <th>Chars_Title</th>\n",
       "      <th>Upper_percentage</th>\n",
       "      <th>Lower_percentage</th>\n",
       "      <th>Z_Score_HelpfulVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2.548167</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "      <td>202.555556</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>94</td>\n",
       "      <td>5.103923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.066097</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>79</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>11</td>\n",
       "      <td>89</td>\n",
       "      <td>-0.271598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.721210</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>701.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>94</td>\n",
       "      <td>-0.271598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1.034114</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>862.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>-0.271598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.489055</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>280.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>0.400342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stars  Z_Score_Words  Paragraphs  No.break tags  Percentage_Upper_Case  \\\n",
       "0      5       2.548167           9             11                      4   \n",
       "1      3      -0.066097           1              0                     11   \n",
       "2      5       0.721210           1              0                      1   \n",
       "3      5       1.034114           1              0                      4   \n",
       "4      5       0.489055           2              1                      5   \n",
       "\n",
       "   Percentage_Lower_Case  Avg_len_paragraph_per_review  Words_Title  \\\n",
       "0                     89                    202.555556            5   \n",
       "1                     79                    284.000000            7   \n",
       "2                     96                    701.000000            6   \n",
       "3                     92                    862.000000            7   \n",
       "4                     89                    280.500000            3   \n",
       "\n",
       "   Chars_Title  Upper_percentage  Lower_percentage  Z_Score_HelpfulVotes  \n",
       "0           35                 3                94              5.103923  \n",
       "1           41                11                89             -0.271598  \n",
       "2           38                 3                94             -0.271598  \n",
       "3           31                 4                96             -0.271598  \n",
       "4           25                 4                87              0.400342  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(r'/Users/t_velpac/mission/WorkingCopy/Final_Features_With_Titles')\n",
    "\n",
    "# The below line of code is to keep the z-scores of helpful votes and words and remove the actual values.\n",
    "\n",
    "print(dataset.columns)\n",
    "dataset = dataset[['Stars','Z_Score_Words', 'Paragraphs','No.break tags','Percentage_Upper_Case','Percentage_Lower_Case','Avg_len_paragraph_per_review'\n",
    "                  ,'Words_Title', 'Chars_Title', 'Upper_percentage', 'Lower_percentage','Z_Score_HelpfulVotes']]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating the independant variables from the dependant variable which is \"Helpful Votes\" in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,0:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Splitting the data into training data and testing data\"\"\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2,random_state=0)\n",
    "\n",
    "\"\"\"Scaling the data using StandardScaler from sklearn package\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing keras and other required functions\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/WorkingCopy/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0981\n",
      "Epoch 2/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0674\n",
      "Epoch 3/100\n",
      "80711/80711 [==============================] - 15s 181us/step - loss: 0.0632\n",
      "Epoch 4/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0587\n",
      "Epoch 5/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0487\n",
      "Epoch 6/100\n",
      "80711/80711 [==============================] - 14s 173us/step - loss: 0.0450\n",
      "Epoch 7/100\n",
      "80711/80711 [==============================] - 13s 166us/step - loss: 0.0496\n",
      "Epoch 8/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0422\n",
      "Epoch 9/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0414\n",
      "Epoch 10/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0427\n",
      "Epoch 11/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0405\n",
      "Epoch 12/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0365\n",
      "Epoch 13/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0371\n",
      "Epoch 14/100\n",
      "80711/80711 [==============================] - 13s 166us/step - loss: 0.0363\n",
      "Epoch 15/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0385\n",
      "Epoch 16/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0384\n",
      "Epoch 17/100\n",
      "80711/80711 [==============================] - 13s 166us/step - loss: 0.0377\n",
      "Epoch 18/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0406\n",
      "Epoch 19/100\n",
      "80711/80711 [==============================] - 13s 165us/step - loss: 0.0342\n",
      "Epoch 20/100\n",
      "80711/80711 [==============================] - 13s 166us/step - loss: 0.0343\n",
      "Epoch 21/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0345\n",
      "Epoch 22/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0339\n",
      "Epoch 23/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0354\n",
      "Epoch 24/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0333\n",
      "Epoch 25/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0328\n",
      "Epoch 26/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0306\n",
      "Epoch 27/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0318\n",
      "Epoch 28/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0331\n",
      "Epoch 29/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0328\n",
      "Epoch 30/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0343\n",
      "Epoch 31/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0289\n",
      "Epoch 32/100\n",
      "80711/80711 [==============================] - 13s 165us/step - loss: 0.0387\n",
      "Epoch 33/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0345\n",
      "Epoch 34/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0311\n",
      "Epoch 35/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0305\n",
      "Epoch 36/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0306\n",
      "Epoch 37/100\n",
      "80711/80711 [==============================] - 15s 184us/step - loss: 0.0302\n",
      "Epoch 38/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0296\n",
      "Epoch 39/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0284\n",
      "Epoch 40/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0339\n",
      "Epoch 41/100\n",
      "80711/80711 [==============================] - 14s 173us/step - loss: 0.0308\n",
      "Epoch 42/100\n",
      "80711/80711 [==============================] - 13s 165us/step - loss: 0.0303\n",
      "Epoch 43/100\n",
      "80711/80711 [==============================] - 13s 161us/step - loss: 0.0297\n",
      "Epoch 44/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0305\n",
      "Epoch 45/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0288\n",
      "Epoch 46/100\n",
      "80711/80711 [==============================] - 14s 167us/step - loss: 0.0364\n",
      "Epoch 47/100\n",
      "80711/80711 [==============================] - 13s 166us/step - loss: 0.0303\n",
      "Epoch 48/100\n",
      "80711/80711 [==============================] - 14s 167us/step - loss: 0.0282\n",
      "Epoch 49/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0295\n",
      "Epoch 50/100\n",
      "80711/80711 [==============================] - 13s 166us/step - loss: 0.0286\n",
      "Epoch 51/100\n",
      "80711/80711 [==============================] - 14s 175us/step - loss: 0.0282\n",
      "Epoch 52/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0298\n",
      "Epoch 53/100\n",
      "80711/80711 [==============================] - 14s 175us/step - loss: 0.0282\n",
      "Epoch 54/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0276\n",
      "Epoch 55/100\n",
      "80711/80711 [==============================] - 14s 177us/step - loss: 0.0277\n",
      "Epoch 56/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0263\n",
      "Epoch 57/100\n",
      "80711/80711 [==============================] - 14s 173us/step - loss: 0.0281\n",
      "Epoch 58/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0271\n",
      "Epoch 59/100\n",
      "80711/80711 [==============================] - 14s 167us/step - loss: 0.0294\n",
      "Epoch 60/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0286\n",
      "Epoch 61/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0250\n",
      "Epoch 62/100\n",
      "80711/80711 [==============================] - 15s 180us/step - loss: 0.02540s - loss: 0.\n",
      "Epoch 63/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0294\n",
      "Epoch 64/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0276\n",
      "Epoch 65/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0267\n",
      "Epoch 66/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0274\n",
      "Epoch 67/100\n",
      "80711/80711 [==============================] - 13s 165us/step - loss: 0.0252\n",
      "Epoch 68/100\n",
      "80711/80711 [==============================] - 14s 167us/step - loss: 0.0276\n",
      "Epoch 69/100\n",
      "80711/80711 [==============================] - 13s 166us/step - loss: 0.0253\n",
      "Epoch 70/100\n",
      "80711/80711 [==============================] - 13s 166us/step - loss: 0.0277\n",
      "Epoch 71/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0252\n",
      "Epoch 72/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0251\n",
      "Epoch 73/100\n",
      "80711/80711 [==============================] - 14s 174us/step - loss: 0.0285\n",
      "Epoch 74/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0261\n",
      "Epoch 75/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0257\n",
      "Epoch 76/100\n",
      "80711/80711 [==============================] - 13s 166us/step - loss: 0.0246\n",
      "Epoch 77/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0296\n",
      "Epoch 78/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0254\n",
      "Epoch 79/100\n",
      "80711/80711 [==============================] - 14s 167us/step - loss: 0.0242\n",
      "Epoch 80/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0296\n",
      "Epoch 81/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0243\n",
      "Epoch 82/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0263\n",
      "Epoch 83/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0235\n",
      "Epoch 84/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0256\n",
      "Epoch 85/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0243\n",
      "Epoch 86/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0265\n",
      "Epoch 87/100\n",
      "80711/80711 [==============================] - 14s 173us/step - loss: 0.0246\n",
      "Epoch 88/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "80711/80711 [==============================] - 13s 163us/step - loss: 0.0247\n",
      "Epoch 90/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0243\n",
      "Epoch 91/100\n",
      "80711/80711 [==============================] - 14s 173us/step - loss: 0.0261\n",
      "Epoch 92/100\n",
      "80711/80711 [==============================] - 13s 165us/step - loss: 0.0271\n",
      "Epoch 93/100\n",
      "80711/80711 [==============================] - 13s 166us/step - loss: 0.0267\n",
      "Epoch 94/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0250\n",
      "Epoch 95/100\n",
      "80711/80711 [==============================] - 13s 161us/step - loss: 0.0255\n",
      "Epoch 96/100\n",
      "80711/80711 [==============================] - 13s 160us/step - loss: 0.0240\n",
      "Epoch 97/100\n",
      "80711/80711 [==============================] - 13s 161us/step - loss: 0.0252\n",
      "Epoch 98/100\n",
      "80711/80711 [==============================] - 13s 161us/step - loss: 0.0251\n",
      "Epoch 99/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0242\n",
      "Epoch 100/100\n",
      "80711/80711 [==============================] - 13s 166us/step - loss: 0.0232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x139ad5cf8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Building a 3 layer ANN with high number of nodes \"\"\"\n",
    "\n",
    "regressor = Sequential()\n",
    "regressor.add(Dense(100, kernel_initializer = 'normal',activation = 'relu',input_dim = 11))\n",
    "regressor.add(Dense(100, kernel_initializer = 'normal', activation = 'relu'))\n",
    "regressor.add(Dense(1, kernel_initializer = 'normal'))\n",
    "\n",
    "\"\"\" Compiling the regressor \"\"\"\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "\"\"\" Fitting the Artifilial Neural Network to our training data \"\"\"\n",
    "regressor.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.329127</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.508167</td>\n",
       "      <td>1.547551</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.269460</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.291020</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.610709</td>\n",
       "      <td>1.602758</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.289259</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.301447</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.264721</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.202110</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.266023</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.313420</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.289948</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.374431</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.255625</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.174593</td>\n",
       "      <td>-0.189395</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.225926</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.252697</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.235493</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.384433</td>\n",
       "      <td>-0.388120</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.315835</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.269024</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.316397</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.236879</td>\n",
       "      <td>-0.246073</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.304856</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.016268</td>\n",
       "      <td>-0.042377</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.434616</td>\n",
       "      <td>-0.380707</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.276689</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.294735</td>\n",
       "      <td>1.410519</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.274164</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.336332</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20148</th>\n",
       "      <td>0.400342</td>\n",
       "      <td>0.389538</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20149</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.234172</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20150</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.293671</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20151</th>\n",
       "      <td>0.400342</td>\n",
       "      <td>0.418619</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20152</th>\n",
       "      <td>-0.235617</td>\n",
       "      <td>-0.194965</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20153</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.248448</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20154</th>\n",
       "      <td>0.295361</td>\n",
       "      <td>0.263904</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20155</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.305636</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20156</th>\n",
       "      <td>-0.235617</td>\n",
       "      <td>-0.292315</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20157</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.282207</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20158</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.276088</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20159</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.311289</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160</th>\n",
       "      <td>-0.384433</td>\n",
       "      <td>-0.379367</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20161</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.332112</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20162</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.370557</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20163</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.211033</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20164</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.475373</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20165</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.229429</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20166</th>\n",
       "      <td>1.881052</td>\n",
       "      <td>1.656590</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20167</th>\n",
       "      <td>-0.174593</td>\n",
       "      <td>-0.241542</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20168</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.261499</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20169</th>\n",
       "      <td>0.928402</td>\n",
       "      <td>0.766724</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20170</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.270394</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20171</th>\n",
       "      <td>-0.235617</td>\n",
       "      <td>-0.212413</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20172</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.242793</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20173</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.257018</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20174</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.288433</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20175</th>\n",
       "      <td>2.497956</td>\n",
       "      <td>2.661080</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20176</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.285047</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20177</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20178 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Values  Predicted Values  Mean Squared Error  \\\n",
       "0          -0.297970         -0.329127            0.032496   \n",
       "1           1.508167          1.547551            0.032496   \n",
       "2          -0.271598         -0.269460            0.032496   \n",
       "3          -0.243275         -0.291020            0.032496   \n",
       "4           1.610709          1.602758            0.032496   \n",
       "5          -0.243275         -0.289259            0.032496   \n",
       "6          -0.298449         -0.301447            0.032496   \n",
       "7          -0.271598         -0.264721            0.032496   \n",
       "8          -0.198263         -0.202110            0.032496   \n",
       "9          -0.271598         -0.266023            0.032496   \n",
       "10         -0.297406         -0.313420            0.032496   \n",
       "11         -0.243275         -0.289948            0.032496   \n",
       "12         -0.450526         -0.374431            0.032496   \n",
       "13         -0.243275         -0.255625            0.032496   \n",
       "14         -0.174593         -0.189395            0.032496   \n",
       "15         -0.160953         -0.225926            0.032496   \n",
       "16         -0.271598         -0.252697            0.032496   \n",
       "17         -0.237216         -0.235493            0.032496   \n",
       "18         -0.384433         -0.388120            0.032496   \n",
       "19         -0.298449         -0.315835            0.032496   \n",
       "20         -0.271598         -0.269024            0.032496   \n",
       "21         -0.298449         -0.316397            0.032496   \n",
       "22         -0.236879         -0.246073            0.032496   \n",
       "23         -0.298449         -0.304856            0.032496   \n",
       "24          0.016268         -0.042377            0.032496   \n",
       "25         -0.434616         -0.380707            0.032496   \n",
       "26         -0.271598         -0.276689            0.032496   \n",
       "27          1.294735          1.410519            0.032496   \n",
       "28         -0.297406         -0.274164            0.032496   \n",
       "29         -0.297970         -0.336332            0.032496   \n",
       "...              ...               ...                 ...   \n",
       "20148       0.400342          0.389538            0.032496   \n",
       "20149      -0.243275         -0.234172            0.032496   \n",
       "20150      -0.243275         -0.293671            0.032496   \n",
       "20151       0.400342          0.418619            0.032496   \n",
       "20152      -0.235617         -0.194965            0.032496   \n",
       "20153      -0.271598         -0.248448            0.032496   \n",
       "20154       0.295361          0.263904            0.032496   \n",
       "20155      -0.298449         -0.305636            0.032496   \n",
       "20156      -0.235617         -0.292315            0.032496   \n",
       "20157      -0.271598         -0.282207            0.032496   \n",
       "20158      -0.298449         -0.276088            0.032496   \n",
       "20159      -0.298449         -0.311289            0.032496   \n",
       "20160      -0.384433         -0.379367            0.032496   \n",
       "20161      -0.297970         -0.332112            0.032496   \n",
       "20162      -0.450526         -0.370557            0.032496   \n",
       "20163      -0.237216         -0.211033            0.032496   \n",
       "20164      -0.450526         -0.475373            0.032496   \n",
       "20165      -0.190985         -0.229429            0.032496   \n",
       "20166       1.881052          1.656590            0.032496   \n",
       "20167      -0.174593         -0.241542            0.032496   \n",
       "20168      -0.271598         -0.261499            0.032496   \n",
       "20169       0.928402          0.766724            0.032496   \n",
       "20170      -0.297970         -0.270394            0.032496   \n",
       "20171      -0.235617         -0.212413            0.032496   \n",
       "20172      -0.198263         -0.242793            0.032496   \n",
       "20173      -0.190985         -0.257018            0.032496   \n",
       "20174      -0.191298         -0.288433            0.032496   \n",
       "20175       2.497956          2.661080            0.032496   \n",
       "20176      -0.271598         -0.285047            0.032496   \n",
       "20177      -0.243275         -0.272599            0.032496   \n",
       "\n",
       "       Root Mean Squared Error  \n",
       "0                     0.180267  \n",
       "1                     0.180267  \n",
       "2                     0.180267  \n",
       "3                     0.180267  \n",
       "4                     0.180267  \n",
       "5                     0.180267  \n",
       "6                     0.180267  \n",
       "7                     0.180267  \n",
       "8                     0.180267  \n",
       "9                     0.180267  \n",
       "10                    0.180267  \n",
       "11                    0.180267  \n",
       "12                    0.180267  \n",
       "13                    0.180267  \n",
       "14                    0.180267  \n",
       "15                    0.180267  \n",
       "16                    0.180267  \n",
       "17                    0.180267  \n",
       "18                    0.180267  \n",
       "19                    0.180267  \n",
       "20                    0.180267  \n",
       "21                    0.180267  \n",
       "22                    0.180267  \n",
       "23                    0.180267  \n",
       "24                    0.180267  \n",
       "25                    0.180267  \n",
       "26                    0.180267  \n",
       "27                    0.180267  \n",
       "28                    0.180267  \n",
       "29                    0.180267  \n",
       "...                        ...  \n",
       "20148                 0.180267  \n",
       "20149                 0.180267  \n",
       "20150                 0.180267  \n",
       "20151                 0.180267  \n",
       "20152                 0.180267  \n",
       "20153                 0.180267  \n",
       "20154                 0.180267  \n",
       "20155                 0.180267  \n",
       "20156                 0.180267  \n",
       "20157                 0.180267  \n",
       "20158                 0.180267  \n",
       "20159                 0.180267  \n",
       "20160                 0.180267  \n",
       "20161                 0.180267  \n",
       "20162                 0.180267  \n",
       "20163                 0.180267  \n",
       "20164                 0.180267  \n",
       "20165                 0.180267  \n",
       "20166                 0.180267  \n",
       "20167                 0.180267  \n",
       "20168                 0.180267  \n",
       "20169                 0.180267  \n",
       "20170                 0.180267  \n",
       "20171                 0.180267  \n",
       "20172                 0.180267  \n",
       "20173                 0.180267  \n",
       "20174                 0.180267  \n",
       "20175                 0.180267  \n",
       "20176                 0.180267  \n",
       "20177                 0.180267  \n",
       "\n",
       "[20178 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Predicting the values for Helpful Votes on the test data \"\"\"\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against predicted values \"\"\"\n",
    "y_pred = y_pred.reshape(20178,)\n",
    "temp = {'Actual Values': y_test,'Predicted Values': y_pred}\n",
    "y_compare = pd.DataFrame(temp)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare['Mean Squared Error'] = (np.diff(y_compare.values) ** 2)\n",
    "y_compare['Mean Squared Error'] = np.mean(y_compare['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare['Root Mean Squared Error'] = y_compare['Mean Squared Error']**0.5\n",
    "y_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values(Training)</th>\n",
       "      <th>Predicted Values(Training)</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.254767</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.619072</td>\n",
       "      <td>1.744931</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.322004</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.227666</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.165430</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.284439</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.016268</td>\n",
       "      <td>0.345361</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.799391</td>\n",
       "      <td>0.790113</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.274415</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.243744</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.423481</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.250270</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.238500</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.708209</td>\n",
       "      <td>2.909372</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.233631</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.174593</td>\n",
       "      <td>-0.224954</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.296861</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.247382</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.234336</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.256048</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.319149</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.255358</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.251896</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.217301</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.960844</td>\n",
       "      <td>0.908832</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.167573</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.200734</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.247748</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.333847</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.255578</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80681</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.221451</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80682</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.221603</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80683</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.260685</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80684</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.212879</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80685</th>\n",
       "      <td>-0.235617</td>\n",
       "      <td>-0.239102</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80686</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.212844</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80687</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.200999</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80688</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.306584</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80689</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.353979</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80690</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.214359</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80691</th>\n",
       "      <td>-0.434616</td>\n",
       "      <td>-0.412220</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80692</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.236826</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80693</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.285087</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80694</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.256296</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80695</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.252077</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80696</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.280510</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80697</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.215130</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80698</th>\n",
       "      <td>5.228654</td>\n",
       "      <td>3.758734</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80699</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.301427</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80700</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.235686</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80701</th>\n",
       "      <td>-0.239534</td>\n",
       "      <td>-0.272367</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80702</th>\n",
       "      <td>-0.434616</td>\n",
       "      <td>-0.411714</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80703</th>\n",
       "      <td>-0.384433</td>\n",
       "      <td>-0.374433</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80704</th>\n",
       "      <td>-0.236879</td>\n",
       "      <td>-0.219079</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80705</th>\n",
       "      <td>6.252968</td>\n",
       "      <td>6.127892</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80706</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.242767</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80707</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.212263</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80708</th>\n",
       "      <td>-0.384433</td>\n",
       "      <td>-0.378124</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80709</th>\n",
       "      <td>1.218371</td>\n",
       "      <td>1.269984</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80710</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.209137</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.141303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80711 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Values(Training)  Predicted Values(Training)  \\\n",
       "0                    -0.271598                   -0.254767   \n",
       "1                     1.619072                    1.744931   \n",
       "2                    -0.297406                   -0.322004   \n",
       "3                    -0.237216                   -0.227666   \n",
       "4                    -0.237216                   -0.165430   \n",
       "5                    -0.198263                   -0.284439   \n",
       "6                     0.016268                    0.345361   \n",
       "7                     0.799391                    0.790113   \n",
       "8                    -0.243275                   -0.274415   \n",
       "9                    -0.298449                   -0.243744   \n",
       "10                   -0.450526                   -0.423481   \n",
       "11                   -0.191298                   -0.250270   \n",
       "12                   -0.190985                   -0.238500   \n",
       "13                    2.708209                    2.909372   \n",
       "14                   -0.237216                   -0.233631   \n",
       "15                   -0.174593                   -0.224954   \n",
       "16                   -0.298449                   -0.296861   \n",
       "17                   -0.160953                   -0.247382   \n",
       "18                   -0.191298                   -0.234336   \n",
       "19                   -0.243275                   -0.256048   \n",
       "20                   -0.450526                   -0.319149   \n",
       "21                   -0.271598                   -0.255358   \n",
       "22                   -0.271598                   -0.251896   \n",
       "23                   -0.160953                   -0.217301   \n",
       "24                    0.960844                    0.908832   \n",
       "25                   -0.198263                   -0.167573   \n",
       "26                   -0.160953                   -0.200734   \n",
       "27                   -0.271598                   -0.247748   \n",
       "28                   -0.297406                   -0.333847   \n",
       "29                   -0.271598                   -0.255578   \n",
       "...                        ...                         ...   \n",
       "80681                -0.271598                   -0.221451   \n",
       "80682                -0.160953                   -0.221603   \n",
       "80683                -0.298449                   -0.260685   \n",
       "80684                -0.237216                   -0.212879   \n",
       "80685                -0.235617                   -0.239102   \n",
       "80686                -0.190985                   -0.212844   \n",
       "80687                -0.237216                   -0.200999   \n",
       "80688                -0.298449                   -0.306584   \n",
       "80689                -0.297406                   -0.353979   \n",
       "80690                -0.160953                   -0.214359   \n",
       "80691                -0.434616                   -0.412220   \n",
       "80692                -0.271598                   -0.236826   \n",
       "80693                -0.298449                   -0.285087   \n",
       "80694                -0.271598                   -0.256296   \n",
       "80695                -0.191298                   -0.252077   \n",
       "80696                -0.297970                   -0.280510   \n",
       "80697                -0.237216                   -0.215130   \n",
       "80698                 5.228654                    3.758734   \n",
       "80699                -0.191298                   -0.301427   \n",
       "80700                -0.191298                   -0.235686   \n",
       "80701                -0.239534                   -0.272367   \n",
       "80702                -0.434616                   -0.411714   \n",
       "80703                -0.384433                   -0.374433   \n",
       "80704                -0.236879                   -0.219079   \n",
       "80705                 6.252968                    6.127892   \n",
       "80706                -0.271598                   -0.242767   \n",
       "80707                -0.198263                   -0.212263   \n",
       "80708                -0.384433                   -0.378124   \n",
       "80709                 1.218371                    1.269984   \n",
       "80710                -0.190985                   -0.209137   \n",
       "\n",
       "       Mean Squared Error  Root Mean Squared Error  \n",
       "0                0.019967                 0.141303  \n",
       "1                0.019967                 0.141303  \n",
       "2                0.019967                 0.141303  \n",
       "3                0.019967                 0.141303  \n",
       "4                0.019967                 0.141303  \n",
       "5                0.019967                 0.141303  \n",
       "6                0.019967                 0.141303  \n",
       "7                0.019967                 0.141303  \n",
       "8                0.019967                 0.141303  \n",
       "9                0.019967                 0.141303  \n",
       "10               0.019967                 0.141303  \n",
       "11               0.019967                 0.141303  \n",
       "12               0.019967                 0.141303  \n",
       "13               0.019967                 0.141303  \n",
       "14               0.019967                 0.141303  \n",
       "15               0.019967                 0.141303  \n",
       "16               0.019967                 0.141303  \n",
       "17               0.019967                 0.141303  \n",
       "18               0.019967                 0.141303  \n",
       "19               0.019967                 0.141303  \n",
       "20               0.019967                 0.141303  \n",
       "21               0.019967                 0.141303  \n",
       "22               0.019967                 0.141303  \n",
       "23               0.019967                 0.141303  \n",
       "24               0.019967                 0.141303  \n",
       "25               0.019967                 0.141303  \n",
       "26               0.019967                 0.141303  \n",
       "27               0.019967                 0.141303  \n",
       "28               0.019967                 0.141303  \n",
       "29               0.019967                 0.141303  \n",
       "...                   ...                      ...  \n",
       "80681            0.019967                 0.141303  \n",
       "80682            0.019967                 0.141303  \n",
       "80683            0.019967                 0.141303  \n",
       "80684            0.019967                 0.141303  \n",
       "80685            0.019967                 0.141303  \n",
       "80686            0.019967                 0.141303  \n",
       "80687            0.019967                 0.141303  \n",
       "80688            0.019967                 0.141303  \n",
       "80689            0.019967                 0.141303  \n",
       "80690            0.019967                 0.141303  \n",
       "80691            0.019967                 0.141303  \n",
       "80692            0.019967                 0.141303  \n",
       "80693            0.019967                 0.141303  \n",
       "80694            0.019967                 0.141303  \n",
       "80695            0.019967                 0.141303  \n",
       "80696            0.019967                 0.141303  \n",
       "80697            0.019967                 0.141303  \n",
       "80698            0.019967                 0.141303  \n",
       "80699            0.019967                 0.141303  \n",
       "80700            0.019967                 0.141303  \n",
       "80701            0.019967                 0.141303  \n",
       "80702            0.019967                 0.141303  \n",
       "80703            0.019967                 0.141303  \n",
       "80704            0.019967                 0.141303  \n",
       "80705            0.019967                 0.141303  \n",
       "80706            0.019967                 0.141303  \n",
       "80707            0.019967                 0.141303  \n",
       "80708            0.019967                 0.141303  \n",
       "80709            0.019967                 0.141303  \n",
       "80710            0.019967                 0.141303  \n",
       "\n",
       "[80711 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Now we will also predict the y values on the training set just to calculate MSE and RMSE \"\"\"\n",
    "\n",
    "y_pred_train = regressor.predict(X_train)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against the predicted values for the training set \"\"\"\n",
    "y_pred_train = y_pred_train.reshape(80711,)\n",
    "temp_train = {'Actual Values(Training)':y_train, 'Predicted Values(Training)': y_pred_train }\n",
    "y_compare_train = pd.DataFrame(temp_train)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN on TRAINING SET\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_train['Mean Squared Error'] = (np.diff(y_compare_train.values) ** 2)\n",
    "y_compare_train['Mean Squared Error'] = np.mean(y_compare_train['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_train['Root Mean Squared Error'] = y_compare_train['Mean Squared Error']**0.5\n",
    "y_compare_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nNow we will be training a different ANN with lower number of nodes\\n\\n11-4-4-1\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "Now we will be training a different ANN with lower number of nodes\n",
    "\n",
    "11-4-4-1\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.12800s -\n",
      "Epoch 2/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0846\n",
      "Epoch 3/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0819\n",
      "Epoch 4/100\n",
      "80711/80711 [==============================] - 13s 166us/step - loss: 0.0776\n",
      "Epoch 5/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0721\n",
      "Epoch 6/100\n",
      "80711/80711 [==============================] - 13s 166us/step - loss: 0.0684\n",
      "Epoch 7/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0643\n",
      "Epoch 8/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0591\n",
      "Epoch 9/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0544\n",
      "Epoch 10/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0516\n",
      "Epoch 11/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0471\n",
      "Epoch 12/100\n",
      "80711/80711 [==============================] - 14s 176us/step - loss: 0.0472\n",
      "Epoch 13/100\n",
      "80711/80711 [==============================] - 15s 182us/step - loss: 0.0457\n",
      "Epoch 14/100\n",
      "80711/80711 [==============================] - 15s 181us/step - loss: 0.0454\n",
      "Epoch 15/100\n",
      "80711/80711 [==============================] - 13s 165us/step - loss: 0.0455\n",
      "Epoch 16/100\n",
      "80711/80711 [==============================] - 13s 163us/step - loss: 0.0442\n",
      "Epoch 17/100\n",
      "80711/80711 [==============================] - 13s 166us/step - loss: 0.0431\n",
      "Epoch 18/100\n",
      "80711/80711 [==============================] - 15s 186us/step - loss: 0.0429\n",
      "Epoch 19/100\n",
      "80711/80711 [==============================] - 14s 167us/step - loss: 0.0430\n",
      "Epoch 20/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0433\n",
      "Epoch 21/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0424\n",
      "Epoch 22/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0433\n",
      "Epoch 23/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0418\n",
      "Epoch 24/100\n",
      "80711/80711 [==============================] - 13s 165us/step - loss: 0.0410\n",
      "Epoch 25/100\n",
      "80711/80711 [==============================] - 15s 185us/step - loss: 0.0410\n",
      "Epoch 26/100\n",
      "80711/80711 [==============================] - 16s 198us/step - loss: 0.0432\n",
      "Epoch 27/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0417\n",
      "Epoch 28/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0412\n",
      "Epoch 29/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0411\n",
      "Epoch 30/100\n",
      "80711/80711 [==============================] - 14s 173us/step - loss: 0.0412\n",
      "Epoch 31/100\n",
      "80711/80711 [==============================] - 13s 164us/step - loss: 0.0427\n",
      "Epoch 32/100\n",
      "80711/80711 [==============================] - 15s 191us/step - loss: 0.0418\n",
      "Epoch 33/100\n",
      "80711/80711 [==============================] - 14s 179us/step - loss: 0.0424\n",
      "Epoch 34/100\n",
      "80711/80711 [==============================] - 13s 165us/step - loss: 0.0412\n",
      "Epoch 35/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.0418\n",
      "Epoch 36/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0397\n",
      "Epoch 37/100\n",
      "80711/80711 [==============================] - 14s 169us/step - loss: 0.04180s - lo\n",
      "Epoch 38/100\n",
      "80711/80711 [==============================] - 14s 177us/step - loss: 0.0425\n",
      "Epoch 39/100\n",
      "80711/80711 [==============================] - 15s 180us/step - loss: 0.04050s\n",
      "Epoch 40/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0420\n",
      "Epoch 41/100\n",
      "80711/80711 [==============================] - 14s 174us/step - loss: 0.0400\n",
      "Epoch 42/100\n",
      "80711/80711 [==============================] - 14s 175us/step - loss: 0.0407\n",
      "Epoch 43/100\n",
      "80711/80711 [==============================] - 14s 174us/step - loss: 0.0414\n",
      "Epoch 44/100\n",
      "80711/80711 [==============================] - 14s 174us/step - loss: 0.0402\n",
      "Epoch 45/100\n",
      "80711/80711 [==============================] - 15s 182us/step - loss: 0.0417\n",
      "Epoch 46/100\n",
      "80711/80711 [==============================] - 15s 183us/step - loss: 0.0385\n",
      "Epoch 47/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0422\n",
      "Epoch 48/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0396\n",
      "Epoch 49/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0395\n",
      "Epoch 50/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0400\n",
      "Epoch 51/100\n",
      "80711/80711 [==============================] - 13s 163us/step - loss: 0.0407\n",
      "Epoch 52/100\n",
      "80711/80711 [==============================] - 13s 163us/step - loss: 0.0406\n",
      "Epoch 53/100\n",
      "80711/80711 [==============================] - 13s 164us/step - loss: 0.0392\n",
      "Epoch 54/100\n",
      "80711/80711 [==============================] - 13s 163us/step - loss: 0.0396\n",
      "Epoch 55/100\n",
      "80711/80711 [==============================] - 13s 164us/step - loss: 0.0414\n",
      "Epoch 56/100\n",
      "80711/80711 [==============================] - 13s 165us/step - loss: 0.0405\n",
      "Epoch 57/100\n",
      "80711/80711 [==============================] - 13s 162us/step - loss: 0.0400\n",
      "Epoch 58/100\n",
      "80711/80711 [==============================] - 13s 163us/step - loss: 0.0405\n",
      "Epoch 59/100\n",
      "80711/80711 [==============================] - 13s 162us/step - loss: 0.0417\n",
      "Epoch 60/100\n",
      "80711/80711 [==============================] - 13s 163us/step - loss: 0.0406\n",
      "Epoch 61/100\n",
      "80711/80711 [==============================] - 13s 163us/step - loss: 0.0393\n",
      "Epoch 62/100\n",
      "80711/80711 [==============================] - 13s 163us/step - loss: 0.0398\n",
      "Epoch 63/100\n",
      "80711/80711 [==============================] - 13s 164us/step - loss: 0.0409\n",
      "Epoch 64/100\n",
      "80711/80711 [==============================] - 13s 164us/step - loss: 0.0409\n",
      "Epoch 65/100\n",
      "80711/80711 [==============================] - 13s 164us/step - loss: 0.0406\n",
      "Epoch 66/100\n",
      "80711/80711 [==============================] - 13s 163us/step - loss: 0.0392\n",
      "Epoch 67/100\n",
      "80711/80711 [==============================] - 13s 163us/step - loss: 0.0418\n",
      "Epoch 68/100\n",
      "80711/80711 [==============================] - 13s 165us/step - loss: 0.0415\n",
      "Epoch 69/100\n",
      "80711/80711 [==============================] - 13s 163us/step - loss: 0.0400\n",
      "Epoch 70/100\n",
      "80711/80711 [==============================] - 13s 164us/step - loss: 0.0388\n",
      "Epoch 71/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0394\n",
      "Epoch 72/100\n",
      "80711/80711 [==============================] - 14s 173us/step - loss: 0.0402\n",
      "Epoch 73/100\n",
      "80711/80711 [==============================] - 14s 179us/step - loss: 0.0402\n",
      "Epoch 74/100\n",
      "80711/80711 [==============================] - 14s 176us/step - loss: 0.0415\n",
      "Epoch 75/100\n",
      "80711/80711 [==============================] - 13s 166us/step - loss: 0.0393\n",
      "Epoch 76/100\n",
      "80711/80711 [==============================] - 13s 162us/step - loss: 0.0388\n",
      "Epoch 77/100\n",
      "80711/80711 [==============================] - 13s 161us/step - loss: 0.0394\n",
      "Epoch 78/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0402\n",
      "Epoch 79/100\n",
      "80711/80711 [==============================] - 13s 162us/step - loss: 0.0390\n",
      "Epoch 80/100\n",
      "80711/80711 [==============================] - 13s 162us/step - loss: 0.0397\n",
      "Epoch 81/100\n",
      "80711/80711 [==============================] - 13s 163us/step - loss: 0.0391\n",
      "Epoch 82/100\n",
      "80711/80711 [==============================] - 13s 161us/step - loss: 0.0397\n",
      "Epoch 83/100\n",
      "80711/80711 [==============================] - 13s 167us/step - loss: 0.0407\n",
      "Epoch 84/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0394\n",
      "Epoch 85/100\n",
      "80711/80711 [==============================] - 15s 183us/step - loss: 0.0396\n",
      "Epoch 86/100\n",
      "80711/80711 [==============================] - 14s 177us/step - loss: 0.0402\n",
      "Epoch 87/100\n",
      "80711/80711 [==============================] - 15s 181us/step - loss: 0.0399\n",
      "Epoch 88/100\n",
      "80711/80711 [==============================] - 15s 188us/step - loss: 0.0391\n",
      "Epoch 89/100\n",
      "80711/80711 [==============================] - 14s 170us/step - loss: 0.0395\n",
      "Epoch 90/100\n",
      "80711/80711 [==============================] - 14s 179us/step - loss: 0.0399\n",
      "Epoch 91/100\n",
      "80711/80711 [==============================] - 14s 168us/step - loss: 0.0384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100\n",
      "80711/80711 [==============================] - 13s 161us/step - loss: 0.0392\n",
      "Epoch 93/100\n",
      "80711/80711 [==============================] - 13s 162us/step - loss: 0.0401\n",
      "Epoch 94/100\n",
      "80711/80711 [==============================] - 13s 161us/step - loss: 0.0383\n",
      "Epoch 95/100\n",
      "80711/80711 [==============================] - 14s 171us/step - loss: 0.0386\n",
      "Epoch 96/100\n",
      "80711/80711 [==============================] - 14s 174us/step - loss: 0.0384\n",
      "Epoch 97/100\n",
      "80711/80711 [==============================] - 14s 172us/step - loss: 0.0387\n",
      "Epoch 98/100\n",
      "80711/80711 [==============================] - 14s 180us/step - loss: 0.0395\n",
      "Epoch 99/100\n",
      "80711/80711 [==============================] - 16s 195us/step - loss: 0.04110s - loss: 0.0\n",
      "Epoch 100/100\n",
      "80711/80711 [==============================] - 16s 202us/step - loss: 0.0395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13a15fd30>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Building a 3 layer ANN with less number of nodes \"\"\"\n",
    "\n",
    "regressor_1 = Sequential()\n",
    "regressor_1.add(Dense(4, kernel_initializer = 'normal',activation = 'relu',input_dim = 11))\n",
    "regressor_1.add(Dense(4, kernel_initializer = 'normal', activation = 'relu'))\n",
    "regressor_1.add(Dense(1, kernel_initializer = 'normal'))\n",
    "\n",
    "\"\"\" Compiling the regressor \"\"\"\n",
    "regressor_1.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "\"\"\" Fitting the Artifilial Neural Network to our training data \"\"\"\n",
    "regressor_1.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.329127</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.508167</td>\n",
       "      <td>1.547551</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.269460</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.291020</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.610709</td>\n",
       "      <td>1.602758</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.289259</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.301447</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.264721</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.202110</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.266023</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.313420</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.289948</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.374431</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.255625</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.174593</td>\n",
       "      <td>-0.189395</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.225926</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.252697</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.235493</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.384433</td>\n",
       "      <td>-0.388120</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.315835</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.269024</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.316397</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.236879</td>\n",
       "      <td>-0.246073</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.304856</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.016268</td>\n",
       "      <td>-0.042377</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.434616</td>\n",
       "      <td>-0.380707</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.276689</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.294735</td>\n",
       "      <td>1.410519</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.274164</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.336332</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20148</th>\n",
       "      <td>0.400342</td>\n",
       "      <td>0.389538</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20149</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.234172</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20150</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.293671</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20151</th>\n",
       "      <td>0.400342</td>\n",
       "      <td>0.418619</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20152</th>\n",
       "      <td>-0.235617</td>\n",
       "      <td>-0.194965</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20153</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.248448</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20154</th>\n",
       "      <td>0.295361</td>\n",
       "      <td>0.263904</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20155</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.305636</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20156</th>\n",
       "      <td>-0.235617</td>\n",
       "      <td>-0.292315</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20157</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.282207</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20158</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.276088</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20159</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.311289</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160</th>\n",
       "      <td>-0.384433</td>\n",
       "      <td>-0.379367</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20161</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.332112</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20162</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.370557</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20163</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.211033</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20164</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.475373</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20165</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.229429</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20166</th>\n",
       "      <td>1.881052</td>\n",
       "      <td>1.656590</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20167</th>\n",
       "      <td>-0.174593</td>\n",
       "      <td>-0.241542</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20168</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.261499</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20169</th>\n",
       "      <td>0.928402</td>\n",
       "      <td>0.766724</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20170</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.270394</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20171</th>\n",
       "      <td>-0.235617</td>\n",
       "      <td>-0.212413</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20172</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.242793</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20173</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.257018</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20174</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.288433</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20175</th>\n",
       "      <td>2.497956</td>\n",
       "      <td>2.661080</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20176</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.285047</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20177</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20178 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Values  Predicted Values  Mean Squared Error  \\\n",
       "0          -0.297970         -0.329127            0.032496   \n",
       "1           1.508167          1.547551            0.032496   \n",
       "2          -0.271598         -0.269460            0.032496   \n",
       "3          -0.243275         -0.291020            0.032496   \n",
       "4           1.610709          1.602758            0.032496   \n",
       "5          -0.243275         -0.289259            0.032496   \n",
       "6          -0.298449         -0.301447            0.032496   \n",
       "7          -0.271598         -0.264721            0.032496   \n",
       "8          -0.198263         -0.202110            0.032496   \n",
       "9          -0.271598         -0.266023            0.032496   \n",
       "10         -0.297406         -0.313420            0.032496   \n",
       "11         -0.243275         -0.289948            0.032496   \n",
       "12         -0.450526         -0.374431            0.032496   \n",
       "13         -0.243275         -0.255625            0.032496   \n",
       "14         -0.174593         -0.189395            0.032496   \n",
       "15         -0.160953         -0.225926            0.032496   \n",
       "16         -0.271598         -0.252697            0.032496   \n",
       "17         -0.237216         -0.235493            0.032496   \n",
       "18         -0.384433         -0.388120            0.032496   \n",
       "19         -0.298449         -0.315835            0.032496   \n",
       "20         -0.271598         -0.269024            0.032496   \n",
       "21         -0.298449         -0.316397            0.032496   \n",
       "22         -0.236879         -0.246073            0.032496   \n",
       "23         -0.298449         -0.304856            0.032496   \n",
       "24          0.016268         -0.042377            0.032496   \n",
       "25         -0.434616         -0.380707            0.032496   \n",
       "26         -0.271598         -0.276689            0.032496   \n",
       "27          1.294735          1.410519            0.032496   \n",
       "28         -0.297406         -0.274164            0.032496   \n",
       "29         -0.297970         -0.336332            0.032496   \n",
       "...              ...               ...                 ...   \n",
       "20148       0.400342          0.389538            0.032496   \n",
       "20149      -0.243275         -0.234172            0.032496   \n",
       "20150      -0.243275         -0.293671            0.032496   \n",
       "20151       0.400342          0.418619            0.032496   \n",
       "20152      -0.235617         -0.194965            0.032496   \n",
       "20153      -0.271598         -0.248448            0.032496   \n",
       "20154       0.295361          0.263904            0.032496   \n",
       "20155      -0.298449         -0.305636            0.032496   \n",
       "20156      -0.235617         -0.292315            0.032496   \n",
       "20157      -0.271598         -0.282207            0.032496   \n",
       "20158      -0.298449         -0.276088            0.032496   \n",
       "20159      -0.298449         -0.311289            0.032496   \n",
       "20160      -0.384433         -0.379367            0.032496   \n",
       "20161      -0.297970         -0.332112            0.032496   \n",
       "20162      -0.450526         -0.370557            0.032496   \n",
       "20163      -0.237216         -0.211033            0.032496   \n",
       "20164      -0.450526         -0.475373            0.032496   \n",
       "20165      -0.190985         -0.229429            0.032496   \n",
       "20166       1.881052          1.656590            0.032496   \n",
       "20167      -0.174593         -0.241542            0.032496   \n",
       "20168      -0.271598         -0.261499            0.032496   \n",
       "20169       0.928402          0.766724            0.032496   \n",
       "20170      -0.297970         -0.270394            0.032496   \n",
       "20171      -0.235617         -0.212413            0.032496   \n",
       "20172      -0.198263         -0.242793            0.032496   \n",
       "20173      -0.190985         -0.257018            0.032496   \n",
       "20174      -0.191298         -0.288433            0.032496   \n",
       "20175       2.497956          2.661080            0.032496   \n",
       "20176      -0.271598         -0.285047            0.032496   \n",
       "20177      -0.243275         -0.272599            0.032496   \n",
       "\n",
       "       Root Mean Squared Error  \n",
       "0                     0.180267  \n",
       "1                     0.180267  \n",
       "2                     0.180267  \n",
       "3                     0.180267  \n",
       "4                     0.180267  \n",
       "5                     0.180267  \n",
       "6                     0.180267  \n",
       "7                     0.180267  \n",
       "8                     0.180267  \n",
       "9                     0.180267  \n",
       "10                    0.180267  \n",
       "11                    0.180267  \n",
       "12                    0.180267  \n",
       "13                    0.180267  \n",
       "14                    0.180267  \n",
       "15                    0.180267  \n",
       "16                    0.180267  \n",
       "17                    0.180267  \n",
       "18                    0.180267  \n",
       "19                    0.180267  \n",
       "20                    0.180267  \n",
       "21                    0.180267  \n",
       "22                    0.180267  \n",
       "23                    0.180267  \n",
       "24                    0.180267  \n",
       "25                    0.180267  \n",
       "26                    0.180267  \n",
       "27                    0.180267  \n",
       "28                    0.180267  \n",
       "29                    0.180267  \n",
       "...                        ...  \n",
       "20148                 0.180267  \n",
       "20149                 0.180267  \n",
       "20150                 0.180267  \n",
       "20151                 0.180267  \n",
       "20152                 0.180267  \n",
       "20153                 0.180267  \n",
       "20154                 0.180267  \n",
       "20155                 0.180267  \n",
       "20156                 0.180267  \n",
       "20157                 0.180267  \n",
       "20158                 0.180267  \n",
       "20159                 0.180267  \n",
       "20160                 0.180267  \n",
       "20161                 0.180267  \n",
       "20162                 0.180267  \n",
       "20163                 0.180267  \n",
       "20164                 0.180267  \n",
       "20165                 0.180267  \n",
       "20166                 0.180267  \n",
       "20167                 0.180267  \n",
       "20168                 0.180267  \n",
       "20169                 0.180267  \n",
       "20170                 0.180267  \n",
       "20171                 0.180267  \n",
       "20172                 0.180267  \n",
       "20173                 0.180267  \n",
       "20174                 0.180267  \n",
       "20175                 0.180267  \n",
       "20176                 0.180267  \n",
       "20177                 0.180267  \n",
       "\n",
       "[20178 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Predicting the values for Helpful Votes on the test data \"\"\"\n",
    "y_pred_1 = regressor_1.predict(X_test)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against predicted values \"\"\"\n",
    "y_pred_1 = y_pred_1.reshape(20178,)\n",
    "temp = {'Actual Values': y_test,'Predicted Values': y_pred}\n",
    "y_compare_1 = pd.DataFrame(temp)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_1['Mean Squared Error'] = (np.diff(y_compare_1.values) ** 2)\n",
    "y_compare_1['Mean Squared Error'] = np.mean(y_compare_1['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_1['Root Mean Squared Error'] = y_compare_1['Mean Squared Error']**0.5\n",
    "y_compare_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values(Training)</th>\n",
       "      <th>Predicted Values(Training)</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.251008</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.619072</td>\n",
       "      <td>1.629093</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.267617</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.266363</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.265049</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.333763</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.016268</td>\n",
       "      <td>0.258745</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.799391</td>\n",
       "      <td>0.820349</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.281435</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.279099</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.361024</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.271234</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.255088</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.708209</td>\n",
       "      <td>2.932035</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.246505</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.174593</td>\n",
       "      <td>-0.216196</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.298565</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.258100</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.262531</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.269410</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.333669</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.246868</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.249423</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.254101</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.960844</td>\n",
       "      <td>1.065591</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.234958</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.179498</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.248226</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.279550</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.262903</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80681</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.278533</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80682</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.258440</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80683</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.292560</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80684</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.278128</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80685</th>\n",
       "      <td>-0.235617</td>\n",
       "      <td>-0.256771</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80686</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.265905</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80687</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.261328</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80688</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.302506</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80689</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.365630</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80690</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.246396</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80691</th>\n",
       "      <td>-0.434616</td>\n",
       "      <td>-0.302949</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80692</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.231244</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80693</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.303175</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80694</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.291411</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80695</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.275103</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80696</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.475737</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80697</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.250987</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80698</th>\n",
       "      <td>5.228654</td>\n",
       "      <td>2.048773</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80699</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.302168</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80700</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.262680</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80701</th>\n",
       "      <td>-0.239534</td>\n",
       "      <td>-0.244387</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80702</th>\n",
       "      <td>-0.434616</td>\n",
       "      <td>-0.314126</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80703</th>\n",
       "      <td>-0.384433</td>\n",
       "      <td>-0.294917</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80704</th>\n",
       "      <td>-0.236879</td>\n",
       "      <td>-0.255027</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80705</th>\n",
       "      <td>6.252968</td>\n",
       "      <td>7.001740</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80706</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.193040</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80707</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.236953</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80708</th>\n",
       "      <td>-0.384433</td>\n",
       "      <td>-0.280918</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80709</th>\n",
       "      <td>1.218371</td>\n",
       "      <td>1.408500</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80710</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.251696</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80711 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Values(Training)  Predicted Values(Training)  \\\n",
       "0                    -0.271598                   -0.251008   \n",
       "1                     1.619072                    1.629093   \n",
       "2                    -0.297406                   -0.267617   \n",
       "3                    -0.237216                   -0.266363   \n",
       "4                    -0.237216                   -0.265049   \n",
       "5                    -0.198263                   -0.333763   \n",
       "6                     0.016268                    0.258745   \n",
       "7                     0.799391                    0.820349   \n",
       "8                    -0.243275                   -0.281435   \n",
       "9                    -0.298449                   -0.279099   \n",
       "10                   -0.450526                   -0.361024   \n",
       "11                   -0.191298                   -0.271234   \n",
       "12                   -0.190985                   -0.255088   \n",
       "13                    2.708209                    2.932035   \n",
       "14                   -0.237216                   -0.246505   \n",
       "15                   -0.174593                   -0.216196   \n",
       "16                   -0.298449                   -0.298565   \n",
       "17                   -0.160953                   -0.258100   \n",
       "18                   -0.191298                   -0.262531   \n",
       "19                   -0.243275                   -0.269410   \n",
       "20                   -0.450526                   -0.333669   \n",
       "21                   -0.271598                   -0.246868   \n",
       "22                   -0.271598                   -0.249423   \n",
       "23                   -0.160953                   -0.254101   \n",
       "24                    0.960844                    1.065591   \n",
       "25                   -0.198263                   -0.234958   \n",
       "26                   -0.160953                   -0.179498   \n",
       "27                   -0.271598                   -0.248226   \n",
       "28                   -0.297406                   -0.279550   \n",
       "29                   -0.271598                   -0.262903   \n",
       "...                        ...                         ...   \n",
       "80681                -0.271598                   -0.278533   \n",
       "80682                -0.160953                   -0.258440   \n",
       "80683                -0.298449                   -0.292560   \n",
       "80684                -0.237216                   -0.278128   \n",
       "80685                -0.235617                   -0.256771   \n",
       "80686                -0.190985                   -0.265905   \n",
       "80687                -0.237216                   -0.261328   \n",
       "80688                -0.298449                   -0.302506   \n",
       "80689                -0.297406                   -0.365630   \n",
       "80690                -0.160953                   -0.246396   \n",
       "80691                -0.434616                   -0.302949   \n",
       "80692                -0.271598                   -0.231244   \n",
       "80693                -0.298449                   -0.303175   \n",
       "80694                -0.271598                   -0.291411   \n",
       "80695                -0.191298                   -0.275103   \n",
       "80696                -0.297970                   -0.475737   \n",
       "80697                -0.237216                   -0.250987   \n",
       "80698                 5.228654                    2.048773   \n",
       "80699                -0.191298                   -0.302168   \n",
       "80700                -0.191298                   -0.262680   \n",
       "80701                -0.239534                   -0.244387   \n",
       "80702                -0.434616                   -0.314126   \n",
       "80703                -0.384433                   -0.294917   \n",
       "80704                -0.236879                   -0.255027   \n",
       "80705                 6.252968                    7.001740   \n",
       "80706                -0.271598                   -0.193040   \n",
       "80707                -0.198263                   -0.236953   \n",
       "80708                -0.384433                   -0.280918   \n",
       "80709                 1.218371                    1.408500   \n",
       "80710                -0.190985                   -0.251696   \n",
       "\n",
       "       Mean Squared Error  Root Mean Squared Error  \n",
       "0                0.036367                 0.190701  \n",
       "1                0.036367                 0.190701  \n",
       "2                0.036367                 0.190701  \n",
       "3                0.036367                 0.190701  \n",
       "4                0.036367                 0.190701  \n",
       "5                0.036367                 0.190701  \n",
       "6                0.036367                 0.190701  \n",
       "7                0.036367                 0.190701  \n",
       "8                0.036367                 0.190701  \n",
       "9                0.036367                 0.190701  \n",
       "10               0.036367                 0.190701  \n",
       "11               0.036367                 0.190701  \n",
       "12               0.036367                 0.190701  \n",
       "13               0.036367                 0.190701  \n",
       "14               0.036367                 0.190701  \n",
       "15               0.036367                 0.190701  \n",
       "16               0.036367                 0.190701  \n",
       "17               0.036367                 0.190701  \n",
       "18               0.036367                 0.190701  \n",
       "19               0.036367                 0.190701  \n",
       "20               0.036367                 0.190701  \n",
       "21               0.036367                 0.190701  \n",
       "22               0.036367                 0.190701  \n",
       "23               0.036367                 0.190701  \n",
       "24               0.036367                 0.190701  \n",
       "25               0.036367                 0.190701  \n",
       "26               0.036367                 0.190701  \n",
       "27               0.036367                 0.190701  \n",
       "28               0.036367                 0.190701  \n",
       "29               0.036367                 0.190701  \n",
       "...                   ...                      ...  \n",
       "80681            0.036367                 0.190701  \n",
       "80682            0.036367                 0.190701  \n",
       "80683            0.036367                 0.190701  \n",
       "80684            0.036367                 0.190701  \n",
       "80685            0.036367                 0.190701  \n",
       "80686            0.036367                 0.190701  \n",
       "80687            0.036367                 0.190701  \n",
       "80688            0.036367                 0.190701  \n",
       "80689            0.036367                 0.190701  \n",
       "80690            0.036367                 0.190701  \n",
       "80691            0.036367                 0.190701  \n",
       "80692            0.036367                 0.190701  \n",
       "80693            0.036367                 0.190701  \n",
       "80694            0.036367                 0.190701  \n",
       "80695            0.036367                 0.190701  \n",
       "80696            0.036367                 0.190701  \n",
       "80697            0.036367                 0.190701  \n",
       "80698            0.036367                 0.190701  \n",
       "80699            0.036367                 0.190701  \n",
       "80700            0.036367                 0.190701  \n",
       "80701            0.036367                 0.190701  \n",
       "80702            0.036367                 0.190701  \n",
       "80703            0.036367                 0.190701  \n",
       "80704            0.036367                 0.190701  \n",
       "80705            0.036367                 0.190701  \n",
       "80706            0.036367                 0.190701  \n",
       "80707            0.036367                 0.190701  \n",
       "80708            0.036367                 0.190701  \n",
       "80709            0.036367                 0.190701  \n",
       "80710            0.036367                 0.190701  \n",
       "\n",
       "[80711 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Now we will also predict the y values on the training set just to calculate MSE and RMSE \"\"\"\n",
    "\n",
    "y_pred_train_1 = regressor_1.predict(X_train)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against the predicted values for the training set \"\"\"\n",
    "y_pred_train_1 = y_pred_train_1.reshape(80711,)\n",
    "temp_train = {'Actual Values(Training)':y_train, 'Predicted Values(Training)': y_pred_train_1 }\n",
    "y_compare_train_1 = pd.DataFrame(temp_train)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN on TRAINING SET\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_train_1['Mean Squared Error'] = (np.diff(y_compare_train_1.values) ** 2)\n",
    "y_compare_train_1['Mean Squared Error'] = np.mean(y_compare_train_1['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_train_1['Root Mean Squared Error'] = y_compare_train_1['Mean Squared Error']**0.5\n",
    "y_compare_train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nNow, we will train an ANN with a very high number of nodes. And comparitively more layers.\\n\\n11-50-100-200-100-50-20-1\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "Now, we will train an ANN with a very high number of nodes. And comparitively more layers.\n",
    "\n",
    "11-50-100-200-100-50-20-1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80711/80711 [==============================] - 22s 277us/step - loss: 0.1729\n",
      "Epoch 2/100\n",
      "80711/80711 [==============================] - 22s 268us/step - loss: 0.1475\n",
      "Epoch 3/100\n",
      "80711/80711 [==============================] - 21s 265us/step - loss: 0.1905\n",
      "Epoch 4/100\n",
      "80711/80711 [==============================] - 22s 267us/step - loss: 0.1351\n",
      "Epoch 5/100\n",
      "80711/80711 [==============================] - 23s 284us/step - loss: 0.1340\n",
      "Epoch 6/100\n",
      "80711/80711 [==============================] - 23s 281us/step - loss: 0.1644\n",
      "Epoch 7/100\n",
      "80711/80711 [==============================] - 23s 283us/step - loss: 0.1113\n",
      "Epoch 8/100\n",
      "80711/80711 [==============================] - 23s 291us/step - loss: 0.1210\n",
      "Epoch 9/100\n",
      "80711/80711 [==============================] - 22s 271us/step - loss: 0.1381\n",
      "Epoch 10/100\n",
      "80711/80711 [==============================] - 22s 276us/step - loss: 0.1747\n",
      "Epoch 11/100\n",
      "80711/80711 [==============================] - 23s 291us/step - loss: 0.1174\n",
      "Epoch 12/100\n",
      "80711/80711 [==============================] - 24s 293us/step - loss: 0.1336\n",
      "Epoch 13/100\n",
      "80711/80711 [==============================] - 26s 316us/step - loss: 0.1406\n",
      "Epoch 14/100\n",
      "80711/80711 [==============================] - 25s 304us/step - loss: 0.1166\n",
      "Epoch 15/100\n",
      "80711/80711 [==============================] - 23s 287us/step - loss: 0.0842\n",
      "Epoch 16/100\n",
      "80711/80711 [==============================] - 24s 295us/step - loss: 0.1047\n",
      "Epoch 17/100\n",
      "80711/80711 [==============================] - 25s 308us/step - loss: 0.1102\n",
      "Epoch 18/100\n",
      "80711/80711 [==============================] - 23s 279us/step - loss: 0.1115\n",
      "Epoch 19/100\n",
      "80711/80711 [==============================] - 25s 312us/step - loss: 0.0931\n",
      "Epoch 20/100\n",
      "80711/80711 [==============================] - 23s 285us/step - loss: 0.0770\n",
      "Epoch 21/100\n",
      "80711/80711 [==============================] - 23s 287us/step - loss: 0.0710\n",
      "Epoch 22/100\n",
      "80711/80711 [==============================] - 23s 288us/step - loss: 0.0565\n",
      "Epoch 23/100\n",
      "80711/80711 [==============================] - 23s 284us/step - loss: 0.0927\n",
      "Epoch 24/100\n",
      "80711/80711 [==============================] - 23s 284us/step - loss: 0.1614\n",
      "Epoch 25/100\n",
      "80711/80711 [==============================] - 23s 287us/step - loss: 0.0812\n",
      "Epoch 26/100\n",
      "80711/80711 [==============================] - 23s 290us/step - loss: 0.0662\n",
      "Epoch 27/100\n",
      "80711/80711 [==============================] - 23s 281us/step - loss: 0.0990\n",
      "Epoch 28/100\n",
      "80711/80711 [==============================] - 22s 278us/step - loss: 0.0764\n",
      "Epoch 29/100\n",
      "80711/80711 [==============================] - 24s 299us/step - loss: 0.0782\n",
      "Epoch 30/100\n",
      "80711/80711 [==============================] - 21s 266us/step - loss: 0.0896\n",
      "Epoch 31/100\n",
      "80711/80711 [==============================] - 21s 264us/step - loss: 0.0825\n",
      "Epoch 32/100\n",
      "80711/80711 [==============================] - 21s 265us/step - loss: 0.0614\n",
      "Epoch 33/100\n",
      "80711/80711 [==============================] - 21s 264us/step - loss: 0.0634\n",
      "Epoch 34/100\n",
      "80711/80711 [==============================] - 21s 263us/step - loss: 0.0454\n",
      "Epoch 35/100\n",
      "80711/80711 [==============================] - 21s 263us/step - loss: 0.0431\n",
      "Epoch 36/100\n",
      "80711/80711 [==============================] - 21s 261us/step - loss: 0.0788\n",
      "Epoch 37/100\n",
      "80711/80711 [==============================] - 21s 261us/step - loss: 0.0610\n",
      "Epoch 38/100\n",
      "80711/80711 [==============================] - 22s 275us/step - loss: 0.0581\n",
      "Epoch 39/100\n",
      "80711/80711 [==============================] - 22s 279us/step - loss: 0.0594\n",
      "Epoch 40/100\n",
      "80711/80711 [==============================] - 23s 281us/step - loss: 0.0700\n",
      "Epoch 41/100\n",
      "80711/80711 [==============================] - 22s 270us/step - loss: 0.0468\n",
      "Epoch 42/100\n",
      "80711/80711 [==============================] - 22s 275us/step - loss: 0.8502\n",
      "Epoch 43/100\n",
      "80711/80711 [==============================] - 21s 260us/step - loss: 0.0583\n",
      "Epoch 44/100\n",
      "80711/80711 [==============================] - 22s 271us/step - loss: 0.0784\n",
      "Epoch 45/100\n",
      "80711/80711 [==============================] - 22s 275us/step - loss: 0.0709\n",
      "Epoch 46/100\n",
      "80711/80711 [==============================] - 22s 272us/step - loss: 0.0496\n",
      "Epoch 47/100\n",
      "80711/80711 [==============================] - 22s 272us/step - loss: 0.0454\n",
      "Epoch 48/100\n",
      "80711/80711 [==============================] - 22s 275us/step - loss: 0.0622\n",
      "Epoch 49/100\n",
      "80711/80711 [==============================] - 22s 270us/step - loss: 0.2063\n",
      "Epoch 50/100\n",
      "80711/80711 [==============================] - 22s 278us/step - loss: 0.0689\n",
      "Epoch 51/100\n",
      "80711/80711 [==============================] - 22s 270us/step - loss: 0.0500\n",
      "Epoch 52/100\n",
      "80711/80711 [==============================] - 23s 280us/step - loss: 0.0565\n",
      "Epoch 53/100\n",
      "80711/80711 [==============================] - 22s 271us/step - loss: 0.0513\n",
      "Epoch 54/100\n",
      "80711/80711 [==============================] - 22s 273us/step - loss: 0.0446\n",
      "Epoch 55/100\n",
      "80711/80711 [==============================] - 22s 276us/step - loss: 0.0762\n",
      "Epoch 56/100\n",
      "80711/80711 [==============================] - 22s 273us/step - loss: 0.0676\n",
      "Epoch 57/100\n",
      "80711/80711 [==============================] - 22s 271us/step - loss: 0.0475\n",
      "Epoch 58/100\n",
      "80711/80711 [==============================] - 22s 273us/step - loss: 0.0524\n",
      "Epoch 59/100\n",
      "80711/80711 [==============================] - 22s 273us/step - loss: 0.0522\n",
      "Epoch 60/100\n",
      "80711/80711 [==============================] - 22s 274us/step - loss: 0.0592\n",
      "Epoch 61/100\n",
      "80711/80711 [==============================] - 22s 269us/step - loss: 0.0417\n",
      "Epoch 62/100\n",
      "80711/80711 [==============================] - 21s 265us/step - loss: 0.0520\n",
      "Epoch 63/100\n",
      "80711/80711 [==============================] - 21s 265us/step - loss: 0.0857\n",
      "Epoch 64/100\n",
      "80711/80711 [==============================] - 22s 276us/step - loss: 0.1626\n",
      "Epoch 65/100\n",
      "80711/80711 [==============================] - 22s 274us/step - loss: 0.0957\n",
      "Epoch 66/100\n",
      "80711/80711 [==============================] - 21s 265us/step - loss: 0.0839\n",
      "Epoch 67/100\n",
      "80711/80711 [==============================] - 22s 274us/step - loss: 0.0599\n",
      "Epoch 68/100\n",
      "80711/80711 [==============================] - 21s 263us/step - loss: 0.1111\n",
      "Epoch 69/100\n",
      "80711/80711 [==============================] - 23s 281us/step - loss: 0.0576\n",
      "Epoch 70/100\n",
      "80711/80711 [==============================] - 22s 271us/step - loss: 23.9451\n",
      "Epoch 71/100\n",
      "80711/80711 [==============================] - 23s 288us/step - loss: 0.0901\n",
      "Epoch 72/100\n",
      "80711/80711 [==============================] - 24s 297us/step - loss: 0.0633\n",
      "Epoch 73/100\n",
      "80711/80711 [==============================] - 23s 284us/step - loss: 0.0534\n",
      "Epoch 74/100\n",
      "80711/80711 [==============================] - 22s 271us/step - loss: 0.5026\n",
      "Epoch 75/100\n",
      "80711/80711 [==============================] - 24s 293us/step - loss: 0.1127\n",
      "Epoch 76/100\n",
      "80711/80711 [==============================] - 22s 277us/step - loss: 0.0869\n",
      "Epoch 77/100\n",
      "80711/80711 [==============================] - 22s 277us/step - loss: 0.1001\n",
      "Epoch 78/100\n",
      "80711/80711 [==============================] - 24s 300us/step - loss: 0.1462\n",
      "Epoch 79/100\n",
      "80711/80711 [==============================] - 23s 281us/step - loss: 12.1910\n",
      "Epoch 80/100\n",
      "80711/80711 [==============================] - 23s 287us/step - loss: 0.0563\n",
      "Epoch 81/100\n",
      "80711/80711 [==============================] - 23s 288us/step - loss: 0.0603\n",
      "Epoch 82/100\n",
      "80711/80711 [==============================] - 23s 284us/step - loss: 0.1151\n",
      "Epoch 83/100\n",
      "80711/80711 [==============================] - 22s 266us/step - loss: 0.2490\n",
      "Epoch 84/100\n",
      "80711/80711 [==============================] - 24s 295us/step - loss: 0.0738\n",
      "Epoch 85/100\n",
      "80711/80711 [==============================] - 22s 268us/step - loss: 0.0931\n",
      "Epoch 86/100\n",
      "80711/80711 [==============================] - 23s 288us/step - loss: 0.0572\n",
      "Epoch 87/100\n",
      "80711/80711 [==============================] - 23s 290us/step - loss: 8.1018\n",
      "Epoch 88/100\n",
      "80711/80711 [==============================] - 22s 274us/step - loss: 0.2711\n",
      "Epoch 89/100\n",
      "80711/80711 [==============================] - 22s 271us/step - loss: 0.0599\n",
      "Epoch 90/100\n",
      "80711/80711 [==============================] - 22s 267us/step - loss: 0.0761\n",
      "Epoch 91/100\n",
      "80711/80711 [==============================] - 22s 278us/step - loss: 0.1876\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80711/80711 [==============================] - 22s 267us/step - loss: 0.0567\n",
      "Epoch 93/100\n",
      "80711/80711 [==============================] - 23s 283us/step - loss: 0.0707\n",
      "Epoch 94/100\n",
      "80711/80711 [==============================] - 22s 271us/step - loss: 4.7014\n",
      "Epoch 95/100\n",
      "80711/80711 [==============================] - 21s 263us/step - loss: 0.0499\n",
      "Epoch 96/100\n",
      "80711/80711 [==============================] - 23s 283us/step - loss: 0.0892\n",
      "Epoch 97/100\n",
      "80711/80711 [==============================] - 22s 270us/step - loss: 0.0902\n",
      "Epoch 98/100\n",
      "80711/80711 [==============================] - 22s 272us/step - loss: 0.0552\n",
      "Epoch 99/100\n",
      "80711/80711 [==============================] - 21s 266us/step - loss: 0.0849\n",
      "Epoch 100/100\n",
      "80711/80711 [==============================] - 21s 260us/step - loss: 0.0846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x139a4d6d8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Building a deep and wide ANN with high number of nodes \"\"\"\n",
    "\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "regressor_2 = Sequential()\n",
    "regressor_2.add(Dense(50, kernel_initializer = 'normal',input_dim = 11))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(100, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(200, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(100, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(50, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(20, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(1, kernel_initializer = 'normal'))\n",
    "\n",
    "\"\"\" Compiling the regressor \"\"\"\n",
    "regressor_2.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "\"\"\" Fitting the Artifilial Neural Network to our training data \"\"\"\n",
    "regressor_2.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.329127</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.508167</td>\n",
       "      <td>1.547551</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.269460</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.291020</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.610709</td>\n",
       "      <td>1.602758</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.289259</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.301447</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.264721</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.202110</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.266023</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.313420</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.289948</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.374431</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.255625</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.174593</td>\n",
       "      <td>-0.189395</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.225926</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.252697</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.235493</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.384433</td>\n",
       "      <td>-0.388120</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.315835</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.269024</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.316397</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.236879</td>\n",
       "      <td>-0.246073</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.304856</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.016268</td>\n",
       "      <td>-0.042377</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.434616</td>\n",
       "      <td>-0.380707</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.276689</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.294735</td>\n",
       "      <td>1.410519</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.274164</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.336332</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20148</th>\n",
       "      <td>0.400342</td>\n",
       "      <td>0.389538</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20149</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.234172</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20150</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.293671</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20151</th>\n",
       "      <td>0.400342</td>\n",
       "      <td>0.418619</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20152</th>\n",
       "      <td>-0.235617</td>\n",
       "      <td>-0.194965</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20153</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.248448</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20154</th>\n",
       "      <td>0.295361</td>\n",
       "      <td>0.263904</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20155</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.305636</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20156</th>\n",
       "      <td>-0.235617</td>\n",
       "      <td>-0.292315</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20157</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.282207</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20158</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.276088</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20159</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.311289</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160</th>\n",
       "      <td>-0.384433</td>\n",
       "      <td>-0.379367</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20161</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.332112</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20162</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.370557</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20163</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.211033</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20164</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.475373</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20165</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.229429</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20166</th>\n",
       "      <td>1.881052</td>\n",
       "      <td>1.656590</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20167</th>\n",
       "      <td>-0.174593</td>\n",
       "      <td>-0.241542</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20168</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.261499</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20169</th>\n",
       "      <td>0.928402</td>\n",
       "      <td>0.766724</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20170</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.270394</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20171</th>\n",
       "      <td>-0.235617</td>\n",
       "      <td>-0.212413</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20172</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.242793</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20173</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.257018</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20174</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.288433</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20175</th>\n",
       "      <td>2.497956</td>\n",
       "      <td>2.661080</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20176</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.285047</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20177</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.180267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20178 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Values  Predicted Values  Mean Squared Error  \\\n",
       "0          -0.297970         -0.329127            0.032496   \n",
       "1           1.508167          1.547551            0.032496   \n",
       "2          -0.271598         -0.269460            0.032496   \n",
       "3          -0.243275         -0.291020            0.032496   \n",
       "4           1.610709          1.602758            0.032496   \n",
       "5          -0.243275         -0.289259            0.032496   \n",
       "6          -0.298449         -0.301447            0.032496   \n",
       "7          -0.271598         -0.264721            0.032496   \n",
       "8          -0.198263         -0.202110            0.032496   \n",
       "9          -0.271598         -0.266023            0.032496   \n",
       "10         -0.297406         -0.313420            0.032496   \n",
       "11         -0.243275         -0.289948            0.032496   \n",
       "12         -0.450526         -0.374431            0.032496   \n",
       "13         -0.243275         -0.255625            0.032496   \n",
       "14         -0.174593         -0.189395            0.032496   \n",
       "15         -0.160953         -0.225926            0.032496   \n",
       "16         -0.271598         -0.252697            0.032496   \n",
       "17         -0.237216         -0.235493            0.032496   \n",
       "18         -0.384433         -0.388120            0.032496   \n",
       "19         -0.298449         -0.315835            0.032496   \n",
       "20         -0.271598         -0.269024            0.032496   \n",
       "21         -0.298449         -0.316397            0.032496   \n",
       "22         -0.236879         -0.246073            0.032496   \n",
       "23         -0.298449         -0.304856            0.032496   \n",
       "24          0.016268         -0.042377            0.032496   \n",
       "25         -0.434616         -0.380707            0.032496   \n",
       "26         -0.271598         -0.276689            0.032496   \n",
       "27          1.294735          1.410519            0.032496   \n",
       "28         -0.297406         -0.274164            0.032496   \n",
       "29         -0.297970         -0.336332            0.032496   \n",
       "...              ...               ...                 ...   \n",
       "20148       0.400342          0.389538            0.032496   \n",
       "20149      -0.243275         -0.234172            0.032496   \n",
       "20150      -0.243275         -0.293671            0.032496   \n",
       "20151       0.400342          0.418619            0.032496   \n",
       "20152      -0.235617         -0.194965            0.032496   \n",
       "20153      -0.271598         -0.248448            0.032496   \n",
       "20154       0.295361          0.263904            0.032496   \n",
       "20155      -0.298449         -0.305636            0.032496   \n",
       "20156      -0.235617         -0.292315            0.032496   \n",
       "20157      -0.271598         -0.282207            0.032496   \n",
       "20158      -0.298449         -0.276088            0.032496   \n",
       "20159      -0.298449         -0.311289            0.032496   \n",
       "20160      -0.384433         -0.379367            0.032496   \n",
       "20161      -0.297970         -0.332112            0.032496   \n",
       "20162      -0.450526         -0.370557            0.032496   \n",
       "20163      -0.237216         -0.211033            0.032496   \n",
       "20164      -0.450526         -0.475373            0.032496   \n",
       "20165      -0.190985         -0.229429            0.032496   \n",
       "20166       1.881052          1.656590            0.032496   \n",
       "20167      -0.174593         -0.241542            0.032496   \n",
       "20168      -0.271598         -0.261499            0.032496   \n",
       "20169       0.928402          0.766724            0.032496   \n",
       "20170      -0.297970         -0.270394            0.032496   \n",
       "20171      -0.235617         -0.212413            0.032496   \n",
       "20172      -0.198263         -0.242793            0.032496   \n",
       "20173      -0.190985         -0.257018            0.032496   \n",
       "20174      -0.191298         -0.288433            0.032496   \n",
       "20175       2.497956          2.661080            0.032496   \n",
       "20176      -0.271598         -0.285047            0.032496   \n",
       "20177      -0.243275         -0.272599            0.032496   \n",
       "\n",
       "       Root Mean Squared Error  \n",
       "0                     0.180267  \n",
       "1                     0.180267  \n",
       "2                     0.180267  \n",
       "3                     0.180267  \n",
       "4                     0.180267  \n",
       "5                     0.180267  \n",
       "6                     0.180267  \n",
       "7                     0.180267  \n",
       "8                     0.180267  \n",
       "9                     0.180267  \n",
       "10                    0.180267  \n",
       "11                    0.180267  \n",
       "12                    0.180267  \n",
       "13                    0.180267  \n",
       "14                    0.180267  \n",
       "15                    0.180267  \n",
       "16                    0.180267  \n",
       "17                    0.180267  \n",
       "18                    0.180267  \n",
       "19                    0.180267  \n",
       "20                    0.180267  \n",
       "21                    0.180267  \n",
       "22                    0.180267  \n",
       "23                    0.180267  \n",
       "24                    0.180267  \n",
       "25                    0.180267  \n",
       "26                    0.180267  \n",
       "27                    0.180267  \n",
       "28                    0.180267  \n",
       "29                    0.180267  \n",
       "...                        ...  \n",
       "20148                 0.180267  \n",
       "20149                 0.180267  \n",
       "20150                 0.180267  \n",
       "20151                 0.180267  \n",
       "20152                 0.180267  \n",
       "20153                 0.180267  \n",
       "20154                 0.180267  \n",
       "20155                 0.180267  \n",
       "20156                 0.180267  \n",
       "20157                 0.180267  \n",
       "20158                 0.180267  \n",
       "20159                 0.180267  \n",
       "20160                 0.180267  \n",
       "20161                 0.180267  \n",
       "20162                 0.180267  \n",
       "20163                 0.180267  \n",
       "20164                 0.180267  \n",
       "20165                 0.180267  \n",
       "20166                 0.180267  \n",
       "20167                 0.180267  \n",
       "20168                 0.180267  \n",
       "20169                 0.180267  \n",
       "20170                 0.180267  \n",
       "20171                 0.180267  \n",
       "20172                 0.180267  \n",
       "20173                 0.180267  \n",
       "20174                 0.180267  \n",
       "20175                 0.180267  \n",
       "20176                 0.180267  \n",
       "20177                 0.180267  \n",
       "\n",
       "[20178 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Predicting the values for Helpful Votes on the test data \"\"\"\n",
    "y_pred_2 = regressor_2.predict(X_test)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against predicted values \"\"\"\n",
    "y_pred_2 = y_pred_2.reshape(20178,)\n",
    "temp = {'Actual Values': y_test,'Predicted Values': y_pred}\n",
    "y_compare_2 = pd.DataFrame(temp)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_2['Mean Squared Error'] = (np.diff(y_compare_2.values) ** 2)\n",
    "y_compare_2['Mean Squared Error'] = np.mean(y_compare_2['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_2['Root Mean Squared Error'] = y_compare_2['Mean Squared Error']**0.5\n",
    "y_compare_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values(Training)</th>\n",
       "      <th>Predicted Values(Training)</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.263783</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.619072</td>\n",
       "      <td>1.769370</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.323580</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.288533</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.258423</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.248015</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.016268</td>\n",
       "      <td>0.338065</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.799391</td>\n",
       "      <td>0.806285</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.298027</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.277707</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.380127</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.289744</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.232697</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.708209</td>\n",
       "      <td>2.504534</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.268396</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.174593</td>\n",
       "      <td>-0.208575</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.260442</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.259216</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.329063</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.243275</td>\n",
       "      <td>-0.289486</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.450526</td>\n",
       "      <td>-0.328249</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.292986</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.267400</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.182674</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.960844</td>\n",
       "      <td>0.896365</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.227259</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.249397</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.267651</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.369411</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.282434</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80681</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.297534</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80682</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.228596</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80683</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.313577</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80684</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.317448</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80685</th>\n",
       "      <td>-0.235617</td>\n",
       "      <td>-0.275049</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80686</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.247669</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80687</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.246514</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80688</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.325973</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80689</th>\n",
       "      <td>-0.297406</td>\n",
       "      <td>-0.336681</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80690</th>\n",
       "      <td>-0.160953</td>\n",
       "      <td>-0.237132</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80691</th>\n",
       "      <td>-0.434616</td>\n",
       "      <td>-0.441433</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80692</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.294826</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80693</th>\n",
       "      <td>-0.298449</td>\n",
       "      <td>-0.321388</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80694</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.301335</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80695</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.344287</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80696</th>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.299995</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80697</th>\n",
       "      <td>-0.237216</td>\n",
       "      <td>-0.392467</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80698</th>\n",
       "      <td>5.228654</td>\n",
       "      <td>2.874817</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80699</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.314796</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80700</th>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-0.280195</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80701</th>\n",
       "      <td>-0.239534</td>\n",
       "      <td>-0.236082</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80702</th>\n",
       "      <td>-0.434616</td>\n",
       "      <td>-0.456225</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80703</th>\n",
       "      <td>-0.384433</td>\n",
       "      <td>-0.423973</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80704</th>\n",
       "      <td>-0.236879</td>\n",
       "      <td>-0.327510</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80705</th>\n",
       "      <td>6.252968</td>\n",
       "      <td>6.084898</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80706</th>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.355960</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80707</th>\n",
       "      <td>-0.198263</td>\n",
       "      <td>-0.193512</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80708</th>\n",
       "      <td>-0.384433</td>\n",
       "      <td>-0.427804</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80709</th>\n",
       "      <td>1.218371</td>\n",
       "      <td>1.374102</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80710</th>\n",
       "      <td>-0.190985</td>\n",
       "      <td>-0.232121</td>\n",
       "      <td>0.12884</td>\n",
       "      <td>0.190701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80711 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Values(Training)  Predicted Values(Training)  \\\n",
       "0                    -0.271598                   -0.263783   \n",
       "1                     1.619072                    1.769370   \n",
       "2                    -0.297406                   -0.323580   \n",
       "3                    -0.237216                   -0.288533   \n",
       "4                    -0.237216                   -0.258423   \n",
       "5                    -0.198263                   -0.248015   \n",
       "6                     0.016268                    0.338065   \n",
       "7                     0.799391                    0.806285   \n",
       "8                    -0.243275                   -0.298027   \n",
       "9                    -0.298449                   -0.277707   \n",
       "10                   -0.450526                   -0.380127   \n",
       "11                   -0.191298                   -0.289744   \n",
       "12                   -0.190985                   -0.232697   \n",
       "13                    2.708209                    2.504534   \n",
       "14                   -0.237216                   -0.268396   \n",
       "15                   -0.174593                   -0.208575   \n",
       "16                   -0.298449                   -0.260442   \n",
       "17                   -0.160953                   -0.259216   \n",
       "18                   -0.191298                   -0.329063   \n",
       "19                   -0.243275                   -0.289486   \n",
       "20                   -0.450526                   -0.328249   \n",
       "21                   -0.271598                   -0.292986   \n",
       "22                   -0.271598                   -0.267400   \n",
       "23                   -0.160953                   -0.182674   \n",
       "24                    0.960844                    0.896365   \n",
       "25                   -0.198263                   -0.227259   \n",
       "26                   -0.160953                   -0.249397   \n",
       "27                   -0.271598                   -0.267651   \n",
       "28                   -0.297406                   -0.369411   \n",
       "29                   -0.271598                   -0.282434   \n",
       "...                        ...                         ...   \n",
       "80681                -0.271598                   -0.297534   \n",
       "80682                -0.160953                   -0.228596   \n",
       "80683                -0.298449                   -0.313577   \n",
       "80684                -0.237216                   -0.317448   \n",
       "80685                -0.235617                   -0.275049   \n",
       "80686                -0.190985                   -0.247669   \n",
       "80687                -0.237216                   -0.246514   \n",
       "80688                -0.298449                   -0.325973   \n",
       "80689                -0.297406                   -0.336681   \n",
       "80690                -0.160953                   -0.237132   \n",
       "80691                -0.434616                   -0.441433   \n",
       "80692                -0.271598                   -0.294826   \n",
       "80693                -0.298449                   -0.321388   \n",
       "80694                -0.271598                   -0.301335   \n",
       "80695                -0.191298                   -0.344287   \n",
       "80696                -0.297970                   -0.299995   \n",
       "80697                -0.237216                   -0.392467   \n",
       "80698                 5.228654                    2.874817   \n",
       "80699                -0.191298                   -0.314796   \n",
       "80700                -0.191298                   -0.280195   \n",
       "80701                -0.239534                   -0.236082   \n",
       "80702                -0.434616                   -0.456225   \n",
       "80703                -0.384433                   -0.423973   \n",
       "80704                -0.236879                   -0.327510   \n",
       "80705                 6.252968                    6.084898   \n",
       "80706                -0.271598                   -0.355960   \n",
       "80707                -0.198263                   -0.193512   \n",
       "80708                -0.384433                   -0.427804   \n",
       "80709                 1.218371                    1.374102   \n",
       "80710                -0.190985                   -0.232121   \n",
       "\n",
       "       Mean Squared Error  Root Mean Squared Error  \n",
       "0                 0.12884                 0.190701  \n",
       "1                 0.12884                 0.190701  \n",
       "2                 0.12884                 0.190701  \n",
       "3                 0.12884                 0.190701  \n",
       "4                 0.12884                 0.190701  \n",
       "5                 0.12884                 0.190701  \n",
       "6                 0.12884                 0.190701  \n",
       "7                 0.12884                 0.190701  \n",
       "8                 0.12884                 0.190701  \n",
       "9                 0.12884                 0.190701  \n",
       "10                0.12884                 0.190701  \n",
       "11                0.12884                 0.190701  \n",
       "12                0.12884                 0.190701  \n",
       "13                0.12884                 0.190701  \n",
       "14                0.12884                 0.190701  \n",
       "15                0.12884                 0.190701  \n",
       "16                0.12884                 0.190701  \n",
       "17                0.12884                 0.190701  \n",
       "18                0.12884                 0.190701  \n",
       "19                0.12884                 0.190701  \n",
       "20                0.12884                 0.190701  \n",
       "21                0.12884                 0.190701  \n",
       "22                0.12884                 0.190701  \n",
       "23                0.12884                 0.190701  \n",
       "24                0.12884                 0.190701  \n",
       "25                0.12884                 0.190701  \n",
       "26                0.12884                 0.190701  \n",
       "27                0.12884                 0.190701  \n",
       "28                0.12884                 0.190701  \n",
       "29                0.12884                 0.190701  \n",
       "...                   ...                      ...  \n",
       "80681             0.12884                 0.190701  \n",
       "80682             0.12884                 0.190701  \n",
       "80683             0.12884                 0.190701  \n",
       "80684             0.12884                 0.190701  \n",
       "80685             0.12884                 0.190701  \n",
       "80686             0.12884                 0.190701  \n",
       "80687             0.12884                 0.190701  \n",
       "80688             0.12884                 0.190701  \n",
       "80689             0.12884                 0.190701  \n",
       "80690             0.12884                 0.190701  \n",
       "80691             0.12884                 0.190701  \n",
       "80692             0.12884                 0.190701  \n",
       "80693             0.12884                 0.190701  \n",
       "80694             0.12884                 0.190701  \n",
       "80695             0.12884                 0.190701  \n",
       "80696             0.12884                 0.190701  \n",
       "80697             0.12884                 0.190701  \n",
       "80698             0.12884                 0.190701  \n",
       "80699             0.12884                 0.190701  \n",
       "80700             0.12884                 0.190701  \n",
       "80701             0.12884                 0.190701  \n",
       "80702             0.12884                 0.190701  \n",
       "80703             0.12884                 0.190701  \n",
       "80704             0.12884                 0.190701  \n",
       "80705             0.12884                 0.190701  \n",
       "80706             0.12884                 0.190701  \n",
       "80707             0.12884                 0.190701  \n",
       "80708             0.12884                 0.190701  \n",
       "80709             0.12884                 0.190701  \n",
       "80710             0.12884                 0.190701  \n",
       "\n",
       "[80711 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Now we will also predict the y values on the training set just to calculate MSE and RMSE \"\"\"\n",
    "\n",
    "y_pred_train_2 = regressor_2.predict(X_train)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against the predicted values for the training set \"\"\"\n",
    "y_pred_train_2 = y_pred_train_2.reshape(80711,)\n",
    "temp_train = {'Actual Values(Training)':y_train, 'Predicted Values(Training)': y_pred_train_2 }\n",
    "y_compare_train_2 = pd.DataFrame(temp_train)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN on TRAINING SET\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_train_2['Mean Squared Error'] = (np.diff(y_compare_train_2.values) ** 2)\n",
    "y_compare_train_2['Mean Squared Error'] = np.mean(y_compare_train_2['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_train_2['Root Mean Squared Error'] = y_compare_train_1['Mean Squared Error']**0.5\n",
    "y_compare_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
