{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will use Linear Regression to predict the Z_Score_HelpfulVotes\n",
    "\n",
    "    ML MODEL: Polynomial Regression\n",
    "    TARGET: Z_Score_HelpfulVotes\n",
    "    SCALER: Standard Scaler\n",
    "    DATASET: Data with titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r'/Users/t_velpac/mission/WorkingCopy/Final_Features_With_Titles')\n",
    "\n",
    "# The below line of code is to keep the z-scores of helpful votes and words and remove the actual values.\n",
    "\n",
    "print(dataset.columns)\n",
    "dataset = dataset[['Stars','Z_Score_Words', 'Paragraphs','No.break tags','Percentage_Upper_Case','Percentage_Lower_Case','Avg_len_paragraph_per_review'\n",
    "                  ,'Words_Title', 'Chars_Title', 'Upper_percentage', 'Lower_percentage','Z_Score_HelpfulVotes']]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating the independant variables from the dependant variable which is \"Helpful Votes\" in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,0:-1].values\n",
    "y = dataset.iloc[:,-1].values\n",
    "\n",
    "\"\"\" We will transform the data into Polynomial Features using PolynomialFeatures from sklearn\"\"\"\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_reg = PolynomialFeatures()\n",
    "X_poly = poly_reg.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Splitting the data into training data and testing data\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_poly,y, test_size=0.2,random_state=0)\n",
    "\n",
    "\"\"\"Scaling the data using StandardScaler from sklearn package\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Fitting Polynomial Regression to the training dataset\"\"\"\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Predicting the values for the TEST DATA\"\"\"\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "y_compare = pd.DataFrame()\n",
    "y_compare['Actual Values'] = y_test\n",
    "y_compare['Predicted Values'] = y_pred\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare['Mean Squared Error'] = (np.diff(y_compare.values) ** 2)\n",
    "y_compare['Mean Squared Error'] = np.mean(y_compare['Mean Squared Error'])\n",
    "\n",
    "\"\"\" Now calculating the Root Mean Squared Error(RMSE) \"\"\"\n",
    "y_compare['Root Mean Squared Error'] = y_compare['Mean Squared Error']**0.5\n",
    "\n",
    "# Calculating Mean Absolute Error\n",
    "y_compare['Mean Abs. Error'] = np.mean(abs(y_compare['Actual Values'] - y_compare['Predicted Values']))\n",
    "\n",
    "y_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Now we will also predict the y values on the training set just to calculate MSE and RMSE \"\"\"\n",
    "\n",
    "y_pred_train = lin_reg.predict(X_train)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against the predicted values for the training set \"\"\"\n",
    "temp_train = {'Actual Values(Training)':y_train, 'Predicted Values(Training)': y_pred_train }\n",
    "y_compare_train = pd.DataFrame(temp_train)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN on TRAINING SET\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_train['Mean Squared Error'] = (np.diff(y_compare_train.values) ** 2)\n",
    "y_compare_train['Mean Squared Error'] = np.mean(y_compare_train['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_train['Root Mean Squared Error'] = y_compare_train['Mean Squared Error']**0.5\n",
    "\n",
    "# Calculating Mean Absolute Error\n",
    "y_compare_train['Mean Abs. Error'] = np.mean(abs(y_compare_train['Actual Values(Training)'] - y_compare_train['Predicted Values(Training)']))\n",
    "\n",
    "y_compare_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
