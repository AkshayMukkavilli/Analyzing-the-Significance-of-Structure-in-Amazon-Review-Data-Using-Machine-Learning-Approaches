{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will use the same Artificial Neural Networks as in ANN(Deep and Wide with High Nodes Vs Low Nodes) but we will scale the dataset using StandardScaler from sklearn and also use the dataset with Z_Scores of Words and Helpful Votes\n",
    "\n",
    "TARGET LABEL: Z_Score_HelpfulVotes\n",
    "\n",
    "SCALER: STANDARD SCALER\n",
    "\n",
    "ANN'S : Combination 1:  7-100-100-1\n",
    "\n",
    "        Combination 2:  7-4-4-1\n",
    "        \n",
    "        Combination 3:  7-50-100-200-100-50-20-1\n",
    "        \n",
    "        Combination 4: 7-50-50-11\n",
    "        \n",
    "        Combination 5: 7-20-20-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Stars', 'Helpful Votes', 'Z_Score_HelpfulVotes', 'Words',\n",
      "       'Z_Score_Words', 'Paragraphs', 'No.break tags', 'Percentage_Upper_Case',\n",
      "       'Percentage_Lower_Case', 'Avg_len_paragraph_per_review'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Z_Score_Words</th>\n",
       "      <th>Paragraphs</th>\n",
       "      <th>No.break tags</th>\n",
       "      <th>Percentage_Upper_Case</th>\n",
       "      <th>Percentage_Lower_Case</th>\n",
       "      <th>Avg_len_paragraph_per_review</th>\n",
       "      <th>Z_Score_HelpfulVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>6.453577</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "      <td>3087.000000</td>\n",
       "      <td>-0.235881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1.394079</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.915696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3.666459</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>468.500000</td>\n",
       "      <td>1.491485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8.525083</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>394.272727</td>\n",
       "      <td>5.522007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.795826</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>91</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>0.339908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stars  Z_Score_Words  Paragraphs  No.break tags  Percentage_Upper_Case  \\\n",
       "0      3       6.453577           1              0                      3   \n",
       "1      5       1.394079           3              4                      3   \n",
       "2      4       3.666459           4              6                      4   \n",
       "3      4       8.525083          11             20                      3   \n",
       "4      5       1.795826           2              1                      6   \n",
       "\n",
       "   Percentage_Lower_Case  Avg_len_paragraph_per_review  Z_Score_HelpfulVotes  \n",
       "0                     93                   3087.000000             -0.235881  \n",
       "1                     91                    300.000000              0.915696  \n",
       "2                     90                    468.500000              1.491485  \n",
       "3                     91                    394.272727              5.522007  \n",
       "4                     91                    492.000000              0.339908  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(r'/Users/t_velpac/mission/WorkingCopy/FinalFeatures.csv')\n",
    "\n",
    "# The below line of code is to keep the z-scores of helpful votes and words and remove the actual values.\n",
    "\n",
    "print(dataset.columns)\n",
    "dataset = dataset[['Stars','Z_Score_Words', 'Paragraphs','No.break tags','Percentage_Upper_Case','Percentage_Lower_Case','Avg_len_paragraph_per_review','Z_Score_HelpfulVotes']]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating the independant variables from the dependant variable which is \"Helpful Votes\" in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,0:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Splitting the data into training data and testing data\"\"\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2,random_state=0)\n",
    "\n",
    "\"\"\"Scaling the data using StandardScaler from sklearn package\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing keras and other required functions\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/WorkingCopy/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/envs/WorkingCopy/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "24362/24362 [==============================] - 4s 172us/step - loss: 0.1409\n",
      "Epoch 2/100\n",
      "24362/24362 [==============================] - 4s 166us/step - loss: 0.0825\n",
      "Epoch 3/100\n",
      "24362/24362 [==============================] - 4s 169us/step - loss: 0.1000\n",
      "Epoch 4/100\n",
      "24362/24362 [==============================] - 4s 167us/step - loss: 0.1065\n",
      "Epoch 5/100\n",
      "24362/24362 [==============================] - 4s 168us/step - loss: 0.0884\n",
      "Epoch 6/100\n",
      "24362/24362 [==============================] - 4s 166us/step - loss: 0.1137 0s - loss: 0.113\n",
      "Epoch 7/100\n",
      "24362/24362 [==============================] - 4s 169us/step - loss: 0.0925\n",
      "Epoch 8/100\n",
      "24362/24362 [==============================] - 5s 197us/step - loss: 0.0751\n",
      "Epoch 9/100\n",
      "24362/24362 [==============================] - 4s 165us/step - loss: 0.0699\n",
      "Epoch 10/100\n",
      "24362/24362 [==============================] - 4s 164us/step - loss: 0.0712\n",
      "Epoch 11/100\n",
      "24362/24362 [==============================] - 4s 178us/step - loss: 0.0565 0s - loss\n",
      "Epoch 12/100\n",
      "24362/24362 [==============================] - 5s 191us/step - loss: 0.0750\n",
      "Epoch 13/100\n",
      "24362/24362 [==============================] - 4s 183us/step - loss: 0.0624\n",
      "Epoch 14/100\n",
      "24362/24362 [==============================] - 4s 167us/step - loss: 0.0785\n",
      "Epoch 15/100\n",
      "24362/24362 [==============================] - 4s 177us/step - loss: 0.0450\n",
      "Epoch 16/100\n",
      "24362/24362 [==============================] - 4s 174us/step - loss: 0.0620\n",
      "Epoch 17/100\n",
      "24362/24362 [==============================] - 4s 176us/step - loss: 0.0498\n",
      "Epoch 18/100\n",
      "24362/24362 [==============================] - 4s 168us/step - loss: 0.0711\n",
      "Epoch 19/100\n",
      "24362/24362 [==============================] - 4s 170us/step - loss: 0.0583\n",
      "Epoch 20/100\n",
      "24362/24362 [==============================] - 4s 167us/step - loss: 0.0460\n",
      "Epoch 21/100\n",
      "24362/24362 [==============================] - 4s 161us/step - loss: 0.0476\n",
      "Epoch 22/100\n",
      "24362/24362 [==============================] - 4s 169us/step - loss: 0.0745\n",
      "Epoch 23/100\n",
      "24362/24362 [==============================] - 4s 170us/step - loss: 0.0358\n",
      "Epoch 24/100\n",
      "24362/24362 [==============================] - 4s 166us/step - loss: 0.0476\n",
      "Epoch 25/100\n",
      "24362/24362 [==============================] - 4s 173us/step - loss: 0.0552\n",
      "Epoch 26/100\n",
      "24362/24362 [==============================] - 4s 176us/step - loss: 0.0824\n",
      "Epoch 27/100\n",
      "24362/24362 [==============================] - 4s 162us/step - loss: 0.0400\n",
      "Epoch 28/100\n",
      "24362/24362 [==============================] - 4s 164us/step - loss: 0.0438\n",
      "Epoch 29/100\n",
      "24362/24362 [==============================] - 4s 160us/step - loss: 0.0408\n",
      "Epoch 30/100\n",
      "24362/24362 [==============================] - 4s 160us/step - loss: 0.0239\n",
      "Epoch 31/100\n",
      "24362/24362 [==============================] - 4s 158us/step - loss: 0.0449\n",
      "Epoch 32/100\n",
      "24362/24362 [==============================] - 4s 158us/step - loss: 0.0454\n",
      "Epoch 33/100\n",
      "24362/24362 [==============================] - 4s 157us/step - loss: 0.0468\n",
      "Epoch 34/100\n",
      "24362/24362 [==============================] - 4s 159us/step - loss: 0.0333\n",
      "Epoch 35/100\n",
      "24362/24362 [==============================] - 4s 158us/step - loss: 0.1221\n",
      "Epoch 36/100\n",
      "24362/24362 [==============================] - 4s 158us/step - loss: 0.0291\n",
      "Epoch 37/100\n",
      "24362/24362 [==============================] - 4s 159us/step - loss: 0.0299\n",
      "Epoch 38/100\n",
      "24362/24362 [==============================] - 4s 164us/step - loss: 0.0338\n",
      "Epoch 39/100\n",
      "24362/24362 [==============================] - 4s 173us/step - loss: 0.0220 0s - loss: 0. - ETA: 0s - l\n",
      "Epoch 40/100\n",
      "24362/24362 [==============================] - 4s 175us/step - loss: 0.0202\n",
      "Epoch 41/100\n",
      "24362/24362 [==============================] - 4s 164us/step - loss: 0.0465\n",
      "Epoch 42/100\n",
      "24362/24362 [==============================] - 4s 161us/step - loss: 0.0508\n",
      "Epoch 43/100\n",
      "24362/24362 [==============================] - 4s 168us/step - loss: 0.0290\n",
      "Epoch 44/100\n",
      "24362/24362 [==============================] - 4s 170us/step - loss: 0.0305\n",
      "Epoch 45/100\n",
      "24362/24362 [==============================] - 5s 192us/step - loss: 0.0198\n",
      "Epoch 46/100\n",
      "24362/24362 [==============================] - 4s 159us/step - loss: 0.0361\n",
      "Epoch 47/100\n",
      "24362/24362 [==============================] - 4s 172us/step - loss: 0.0520\n",
      "Epoch 48/100\n",
      "24362/24362 [==============================] - 4s 176us/step - loss: 0.0263\n",
      "Epoch 49/100\n",
      "24362/24362 [==============================] - 4s 170us/step - loss: 0.0224\n",
      "Epoch 50/100\n",
      "24362/24362 [==============================] - 4s 163us/step - loss: 0.0325\n",
      "Epoch 51/100\n",
      "24362/24362 [==============================] - 4s 173us/step - loss: 0.0226\n",
      "Epoch 52/100\n",
      "24362/24362 [==============================] - 7s 276us/step - loss: 0.0297\n",
      "Epoch 53/100\n",
      "24362/24362 [==============================] - 5s 210us/step - loss: 0.0212\n",
      "Epoch 54/100\n",
      "24362/24362 [==============================] - 4s 183us/step - loss: 0.0181\n",
      "Epoch 55/100\n",
      "24362/24362 [==============================] - 4s 182us/step - loss: 0.0409\n",
      "Epoch 56/100\n",
      "24362/24362 [==============================] - 4s 181us/step - loss: 0.0163\n",
      "Epoch 57/100\n",
      "24362/24362 [==============================] - 4s 177us/step - loss: 0.0356\n",
      "Epoch 58/100\n",
      "24362/24362 [==============================] - 5s 188us/step - loss: 0.0149\n",
      "Epoch 59/100\n",
      "24362/24362 [==============================] - 5s 194us/step - loss: 0.0462 0\n",
      "Epoch 60/100\n",
      "24362/24362 [==============================] - 5s 188us/step - loss: 0.0181\n",
      "Epoch 61/100\n",
      "24362/24362 [==============================] - 4s 184us/step - loss: 0.0103\n",
      "Epoch 62/100\n",
      "24362/24362 [==============================] - 4s 180us/step - loss: 0.0264\n",
      "Epoch 63/100\n",
      "24362/24362 [==============================] - 4s 181us/step - loss: 0.0309\n",
      "Epoch 64/100\n",
      "24362/24362 [==============================] - 5s 193us/step - loss: 0.0256\n",
      "Epoch 65/100\n",
      "24362/24362 [==============================] - 4s 179us/step - loss: 0.0186\n",
      "Epoch 66/100\n",
      "24362/24362 [==============================] - 4s 169us/step - loss: 0.0451\n",
      "Epoch 67/100\n",
      "24362/24362 [==============================] - 4s 172us/step - loss: 0.0140\n",
      "Epoch 68/100\n",
      "24362/24362 [==============================] - 4s 174us/step - loss: 0.0212\n",
      "Epoch 69/100\n",
      "24362/24362 [==============================] - 4s 172us/step - loss: 0.0206\n",
      "Epoch 70/100\n",
      "24362/24362 [==============================] - 4s 169us/step - loss: 0.0164\n",
      "Epoch 71/100\n",
      "24362/24362 [==============================] - 4s 174us/step - loss: 0.0375\n",
      "Epoch 72/100\n",
      "24362/24362 [==============================] - 4s 180us/step - loss: 0.0268\n",
      "Epoch 73/100\n",
      "24362/24362 [==============================] - 4s 174us/step - loss: 0.0100\n",
      "Epoch 74/100\n",
      "24362/24362 [==============================] - 4s 172us/step - loss: 0.0236\n",
      "Epoch 75/100\n",
      "24362/24362 [==============================] - 4s 170us/step - loss: 0.0290\n",
      "Epoch 76/100\n",
      "24362/24362 [==============================] - 4s 175us/step - loss: 0.0788\n",
      "Epoch 77/100\n",
      "24362/24362 [==============================] - 4s 168us/step - loss: 0.0177\n",
      "Epoch 78/100\n",
      "24362/24362 [==============================] - 4s 174us/step - loss: 0.0113\n",
      "Epoch 79/100\n",
      "24362/24362 [==============================] - 5s 189us/step - loss: 0.0230 0s - loss:\n",
      "Epoch 80/100\n",
      "24362/24362 [==============================] - 4s 175us/step - loss: 0.0470\n",
      "Epoch 81/100\n",
      "24362/24362 [==============================] - 4s 170us/step - loss: 0.0199\n",
      "Epoch 82/100\n",
      "24362/24362 [==============================] - 4s 172us/step - loss: 0.0441\n",
      "Epoch 83/100\n",
      "24362/24362 [==============================] - 4s 173us/step - loss: 0.0165\n",
      "Epoch 84/100\n",
      "24362/24362 [==============================] - 4s 170us/step - loss: 0.0327 0s - l\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24362/24362 [==============================] - 4s 173us/step - loss: 0.0191 0s - \n",
      "Epoch 86/100\n",
      "24362/24362 [==============================] - 4s 168us/step - loss: 0.0154\n",
      "Epoch 87/100\n",
      "24362/24362 [==============================] - 4s 182us/step - loss: 0.0361\n",
      "Epoch 88/100\n",
      "24362/24362 [==============================] - 4s 173us/step - loss: 0.0187\n",
      "Epoch 89/100\n",
      "24362/24362 [==============================] - 4s 170us/step - loss: 0.0182\n",
      "Epoch 90/100\n",
      "24362/24362 [==============================] - 4s 174us/step - loss: 0.0221 0s\n",
      "Epoch 91/100\n",
      "24362/24362 [==============================] - 4s 169us/step - loss: 0.0398\n",
      "Epoch 92/100\n",
      "24362/24362 [==============================] - 4s 171us/step - loss: 0.0131\n",
      "Epoch 93/100\n",
      "24362/24362 [==============================] - 4s 174us/step - loss: 0.0221\n",
      "Epoch 94/100\n",
      "24362/24362 [==============================] - 5s 186us/step - loss: 0.0167\n",
      "Epoch 95/100\n",
      "24362/24362 [==============================] - 4s 174us/step - loss: 0.0340\n",
      "Epoch 96/100\n",
      "24362/24362 [==============================] - 4s 184us/step - loss: 0.0171\n",
      "Epoch 97/100\n",
      "24362/24362 [==============================] - 5s 199us/step - loss: 0.0603\n",
      "Epoch 98/100\n",
      "24362/24362 [==============================] - 5s 192us/step - loss: 0.0181\n",
      "Epoch 99/100\n",
      "24362/24362 [==============================] - 4s 184us/step - loss: 0.0337\n",
      "Epoch 100/100\n",
      "24362/24362 [==============================] - 5s 194us/step - loss: 0.0157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12fb149b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Building a 3 layer ANN with high number of nodes \"\"\"\n",
    "\n",
    "regressor = Sequential()\n",
    "regressor.add(Dense(100, kernel_initializer = 'normal',activation = 'relu',input_dim = 7))\n",
    "regressor.add(Dense(100, kernel_initializer = 'normal', activation = 'relu'))\n",
    "regressor.add(Dense(1, kernel_initializer = 'normal'))\n",
    "\n",
    "\"\"\" Compiling the regressor \"\"\"\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "\"\"\" Fitting the Artifilial Neural Network to our training data \"\"\"\n",
    "regressor.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.155478</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.213014</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.250524</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.196210</td>\n",
       "      <td>-0.188435</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.212252</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.425145</td>\n",
       "      <td>1.196261</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.223287</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.235881</td>\n",
       "      <td>-0.211013</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.221579</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.242970</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.206858</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.879658</td>\n",
       "      <td>2.294586</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.211719</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.201529</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.245226</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.219203</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.208108</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.243316</td>\n",
       "      <td>1.536381</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.194099</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.221419</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.248943</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.243316</td>\n",
       "      <td>1.735964</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.243651</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.225356</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.204941</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.219703</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.219201</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.821420</td>\n",
       "      <td>0.681507</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.115283</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.237438</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6061</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.203524</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.210128</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>16.152226</td>\n",
       "      <td>13.119769</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.197415</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>0.461583</td>\n",
       "      <td>0.330476</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.246673</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6067</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.206383</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6068</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.242075</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6069</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.240917</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6070</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.213129</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6071</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.247278</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6072</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.203171</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.207224</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.204393</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6075</th>\n",
       "      <td>3.061487</td>\n",
       "      <td>1.966572</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.222150</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.198375</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.092810</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6079</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.241940</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6080</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.248485</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6081</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.249236</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6082</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.206387</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6083</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.195922</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6084</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.207447</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6085</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.201283</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6086</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.242072</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.206992</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6088</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.202961</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6089</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.252824</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6090</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.203409</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.304983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6091 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual Values  Predicted Values  Mean Squared Error  \\\n",
       "0          0.101746          0.155478            0.093015   \n",
       "1         -0.211198         -0.213014            0.093015   \n",
       "2         -0.258092         -0.250524            0.093015   \n",
       "3         -0.196210         -0.188435            0.093015   \n",
       "4         -0.211198         -0.212252            0.093015   \n",
       "5          1.425145          1.196261            0.093015   \n",
       "6         -0.211198         -0.223287            0.093015   \n",
       "7         -0.235881         -0.211013            0.093015   \n",
       "8         -0.211198         -0.221579            0.093015   \n",
       "9         -0.258092         -0.242970            0.093015   \n",
       "10        -0.211198         -0.206858            0.093015   \n",
       "11         3.879658          2.294586            0.093015   \n",
       "12        -0.211198         -0.211719            0.093015   \n",
       "13        -0.211198         -0.201529            0.093015   \n",
       "14        -0.258092         -0.245226            0.093015   \n",
       "15        -0.211198         -0.219203            0.093015   \n",
       "16        -0.211198         -0.208108            0.093015   \n",
       "17         2.243316          1.536381            0.093015   \n",
       "18        -0.211198         -0.194099            0.093015   \n",
       "19        -0.211198         -0.221419            0.093015   \n",
       "20        -0.258092         -0.248943            0.093015   \n",
       "21         2.243316          1.735964            0.093015   \n",
       "22        -0.258092         -0.243651            0.093015   \n",
       "23        -0.211198         -0.225356            0.093015   \n",
       "24        -0.211198         -0.204941            0.093015   \n",
       "25        -0.211198         -0.219703            0.093015   \n",
       "26        -0.211198         -0.219201            0.093015   \n",
       "27         0.821420          0.681507            0.093015   \n",
       "28         0.101746          0.115283            0.093015   \n",
       "29        -0.258092         -0.237438            0.093015   \n",
       "...             ...               ...                 ...   \n",
       "6061      -0.211198         -0.203524            0.093015   \n",
       "6062      -0.258092         -0.210128            0.093015   \n",
       "6063      16.152226         13.119769            0.093015   \n",
       "6064      -0.211198         -0.197415            0.093015   \n",
       "6065       0.461583          0.330476            0.093015   \n",
       "6066      -0.258092         -0.246673            0.093015   \n",
       "6067      -0.211198         -0.206383            0.093015   \n",
       "6068      -0.258092         -0.242075            0.093015   \n",
       "6069      -0.258092         -0.240917            0.093015   \n",
       "6070      -0.211198         -0.213129            0.093015   \n",
       "6071      -0.258092         -0.247278            0.093015   \n",
       "6072      -0.211198         -0.203171            0.093015   \n",
       "6073      -0.211198         -0.207224            0.093015   \n",
       "6074      -0.211198         -0.204393            0.093015   \n",
       "6075       3.061487          1.966572            0.093015   \n",
       "6076      -0.211198         -0.222150            0.093015   \n",
       "6077      -0.211198         -0.198375            0.093015   \n",
       "6078       0.101746          0.092810            0.093015   \n",
       "6079      -0.258092         -0.241940            0.093015   \n",
       "6080      -0.258092         -0.248485            0.093015   \n",
       "6081      -0.258092         -0.249236            0.093015   \n",
       "6082      -0.211198         -0.206387            0.093015   \n",
       "6083      -0.211198         -0.195922            0.093015   \n",
       "6084      -0.211198         -0.207447            0.093015   \n",
       "6085      -0.211198         -0.201283            0.093015   \n",
       "6086      -0.258092         -0.242072            0.093015   \n",
       "6087      -0.211198         -0.206992            0.093015   \n",
       "6088      -0.211198         -0.202961            0.093015   \n",
       "6089      -0.258092         -0.252824            0.093015   \n",
       "6090      -0.211198         -0.203409            0.093015   \n",
       "\n",
       "      Root Mean Squared Error  \n",
       "0                    0.304983  \n",
       "1                    0.304983  \n",
       "2                    0.304983  \n",
       "3                    0.304983  \n",
       "4                    0.304983  \n",
       "5                    0.304983  \n",
       "6                    0.304983  \n",
       "7                    0.304983  \n",
       "8                    0.304983  \n",
       "9                    0.304983  \n",
       "10                   0.304983  \n",
       "11                   0.304983  \n",
       "12                   0.304983  \n",
       "13                   0.304983  \n",
       "14                   0.304983  \n",
       "15                   0.304983  \n",
       "16                   0.304983  \n",
       "17                   0.304983  \n",
       "18                   0.304983  \n",
       "19                   0.304983  \n",
       "20                   0.304983  \n",
       "21                   0.304983  \n",
       "22                   0.304983  \n",
       "23                   0.304983  \n",
       "24                   0.304983  \n",
       "25                   0.304983  \n",
       "26                   0.304983  \n",
       "27                   0.304983  \n",
       "28                   0.304983  \n",
       "29                   0.304983  \n",
       "...                       ...  \n",
       "6061                 0.304983  \n",
       "6062                 0.304983  \n",
       "6063                 0.304983  \n",
       "6064                 0.304983  \n",
       "6065                 0.304983  \n",
       "6066                 0.304983  \n",
       "6067                 0.304983  \n",
       "6068                 0.304983  \n",
       "6069                 0.304983  \n",
       "6070                 0.304983  \n",
       "6071                 0.304983  \n",
       "6072                 0.304983  \n",
       "6073                 0.304983  \n",
       "6074                 0.304983  \n",
       "6075                 0.304983  \n",
       "6076                 0.304983  \n",
       "6077                 0.304983  \n",
       "6078                 0.304983  \n",
       "6079                 0.304983  \n",
       "6080                 0.304983  \n",
       "6081                 0.304983  \n",
       "6082                 0.304983  \n",
       "6083                 0.304983  \n",
       "6084                 0.304983  \n",
       "6085                 0.304983  \n",
       "6086                 0.304983  \n",
       "6087                 0.304983  \n",
       "6088                 0.304983  \n",
       "6089                 0.304983  \n",
       "6090                 0.304983  \n",
       "\n",
       "[6091 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Predicting the values for Helpful Votes on the test data \"\"\"\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against predicted values \"\"\"\n",
    "y_pred = y_pred.reshape(6091,)\n",
    "temp = {'Actual Values': y_test,'Predicted Values': y_pred}\n",
    "y_compare = pd.DataFrame(temp)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare['Mean Squared Error'] = (np.diff(y_compare.values) ** 2)\n",
    "y_compare['Mean Squared Error'] = np.mean(y_compare['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare['Root Mean Squared Error'] = y_compare['Mean Squared Error']**0.5\n",
    "y_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values(Training)</th>\n",
       "      <th>Predicted Values(Training)</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.210526</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.216987</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.254790</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.228131</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.231403</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.262958</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.227387</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.262717</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.260339</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.267981</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.267669</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.209963</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.158216</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.210549</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.254800</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.231572</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.223924</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.212841</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.257047</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.215563</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.218415</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.231046</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.230851</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.257381</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.244940</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.256330</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.211680</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.202148</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.222161</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.207710</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24332</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.254037</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24333</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.269557</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24334</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.265231</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24335</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.214085</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24336</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.221602</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24337</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.214114</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24338</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.173318</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24339</th>\n",
       "      <td>0.606973</td>\n",
       "      <td>0.688166</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24340</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.201717</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24341</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.261902</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24342</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.211475</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24343</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.198589</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24344</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.270284</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24345</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.218182</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24346</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.242462</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24347</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.219324</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24348</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.209705</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24349</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.265276</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24350</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.242908</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24351</th>\n",
       "      <td>3.061487</td>\n",
       "      <td>3.223102</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24352</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.208002</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24353</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.217605</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24354</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.265018</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24355</th>\n",
       "      <td>-0.196210</td>\n",
       "      <td>-0.193512</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24356</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.215354</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24357</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.247727</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24358</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.228310</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24359</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.260934</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24360</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.251401</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24361</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.254896</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.204309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24362 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Values(Training)  Predicted Values(Training)  \\\n",
       "0                    -0.211198                   -0.210526   \n",
       "1                    -0.211198                   -0.216987   \n",
       "2                    -0.258092                   -0.254790   \n",
       "3                    -0.211198                   -0.228131   \n",
       "4                    -0.258092                   -0.231403   \n",
       "5                    -0.258092                   -0.262958   \n",
       "6                    -0.211198                   -0.227387   \n",
       "7                    -0.258092                   -0.262717   \n",
       "8                    -0.258092                   -0.260339   \n",
       "9                    -0.258092                   -0.267981   \n",
       "10                   -0.258092                   -0.267669   \n",
       "11                   -0.211198                   -0.209963   \n",
       "12                    0.101746                    0.158216   \n",
       "13                   -0.211198                   -0.210549   \n",
       "14                   -0.258092                   -0.254800   \n",
       "15                   -0.211198                   -0.231572   \n",
       "16                   -0.258092                   -0.223924   \n",
       "17                   -0.211198                   -0.212841   \n",
       "18                   -0.258092                   -0.257047   \n",
       "19                   -0.211198                   -0.215563   \n",
       "20                   -0.211198                   -0.218415   \n",
       "21                   -0.211198                   -0.231046   \n",
       "22                   -0.211198                   -0.230851   \n",
       "23                   -0.258092                   -0.257381   \n",
       "24                   -0.258092                   -0.244940   \n",
       "25                   -0.258092                   -0.256330   \n",
       "26                   -0.211198                   -0.211680   \n",
       "27                   -0.211198                   -0.202148   \n",
       "28                   -0.211198                   -0.222161   \n",
       "29                   -0.211198                   -0.207710   \n",
       "...                        ...                         ...   \n",
       "24332                -0.258092                   -0.254037   \n",
       "24333                -0.258092                   -0.269557   \n",
       "24334                -0.258092                   -0.265231   \n",
       "24335                -0.211198                   -0.214085   \n",
       "24336                -0.211198                   -0.221602   \n",
       "24337                -0.211198                   -0.214114   \n",
       "24338                 0.101746                    0.173318   \n",
       "24339                 0.606973                    0.688166   \n",
       "24340                -0.211198                   -0.201717   \n",
       "24341                -0.258092                   -0.261902   \n",
       "24342                -0.211198                   -0.211475   \n",
       "24343                -0.211198                   -0.198589   \n",
       "24344                -0.258092                   -0.270284   \n",
       "24345                -0.211198                   -0.218182   \n",
       "24346                -0.258092                   -0.242462   \n",
       "24347                -0.211198                   -0.219324   \n",
       "24348                -0.211198                   -0.209705   \n",
       "24349                -0.258092                   -0.265276   \n",
       "24350                -0.258092                   -0.242908   \n",
       "24351                 3.061487                    3.223102   \n",
       "24352                -0.211198                   -0.208002   \n",
       "24353                -0.211198                   -0.217605   \n",
       "24354                -0.258092                   -0.265018   \n",
       "24355                -0.196210                   -0.193512   \n",
       "24356                -0.211198                   -0.215354   \n",
       "24357                -0.258092                   -0.247727   \n",
       "24358                -0.211198                   -0.228310   \n",
       "24359                -0.258092                   -0.260934   \n",
       "24360                -0.258092                   -0.251401   \n",
       "24361                -0.258092                   -0.254896   \n",
       "\n",
       "       Mean Squared Error  Root Mean Squared Error  \n",
       "0                0.041742                 0.204309  \n",
       "1                0.041742                 0.204309  \n",
       "2                0.041742                 0.204309  \n",
       "3                0.041742                 0.204309  \n",
       "4                0.041742                 0.204309  \n",
       "5                0.041742                 0.204309  \n",
       "6                0.041742                 0.204309  \n",
       "7                0.041742                 0.204309  \n",
       "8                0.041742                 0.204309  \n",
       "9                0.041742                 0.204309  \n",
       "10               0.041742                 0.204309  \n",
       "11               0.041742                 0.204309  \n",
       "12               0.041742                 0.204309  \n",
       "13               0.041742                 0.204309  \n",
       "14               0.041742                 0.204309  \n",
       "15               0.041742                 0.204309  \n",
       "16               0.041742                 0.204309  \n",
       "17               0.041742                 0.204309  \n",
       "18               0.041742                 0.204309  \n",
       "19               0.041742                 0.204309  \n",
       "20               0.041742                 0.204309  \n",
       "21               0.041742                 0.204309  \n",
       "22               0.041742                 0.204309  \n",
       "23               0.041742                 0.204309  \n",
       "24               0.041742                 0.204309  \n",
       "25               0.041742                 0.204309  \n",
       "26               0.041742                 0.204309  \n",
       "27               0.041742                 0.204309  \n",
       "28               0.041742                 0.204309  \n",
       "29               0.041742                 0.204309  \n",
       "...                   ...                      ...  \n",
       "24332            0.041742                 0.204309  \n",
       "24333            0.041742                 0.204309  \n",
       "24334            0.041742                 0.204309  \n",
       "24335            0.041742                 0.204309  \n",
       "24336            0.041742                 0.204309  \n",
       "24337            0.041742                 0.204309  \n",
       "24338            0.041742                 0.204309  \n",
       "24339            0.041742                 0.204309  \n",
       "24340            0.041742                 0.204309  \n",
       "24341            0.041742                 0.204309  \n",
       "24342            0.041742                 0.204309  \n",
       "24343            0.041742                 0.204309  \n",
       "24344            0.041742                 0.204309  \n",
       "24345            0.041742                 0.204309  \n",
       "24346            0.041742                 0.204309  \n",
       "24347            0.041742                 0.204309  \n",
       "24348            0.041742                 0.204309  \n",
       "24349            0.041742                 0.204309  \n",
       "24350            0.041742                 0.204309  \n",
       "24351            0.041742                 0.204309  \n",
       "24352            0.041742                 0.204309  \n",
       "24353            0.041742                 0.204309  \n",
       "24354            0.041742                 0.204309  \n",
       "24355            0.041742                 0.204309  \n",
       "24356            0.041742                 0.204309  \n",
       "24357            0.041742                 0.204309  \n",
       "24358            0.041742                 0.204309  \n",
       "24359            0.041742                 0.204309  \n",
       "24360            0.041742                 0.204309  \n",
       "24361            0.041742                 0.204309  \n",
       "\n",
       "[24362 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Now we will also predict the y values on the training set just to calculate MSE and RMSE \"\"\"\n",
    "\n",
    "y_pred_train = regressor.predict(X_train)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against the predicted values for the training set \"\"\"\n",
    "y_pred_train = y_pred_train.reshape(24362,)\n",
    "temp_train = {'Actual Values(Training)':y_train, 'Predicted Values(Training)': y_pred_train }\n",
    "y_compare_train = pd.DataFrame(temp_train)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN on TRAINING SET\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_train['Mean Squared Error'] = (np.diff(y_compare_train.values) ** 2)\n",
    "y_compare_train['Mean Squared Error'] = np.mean(y_compare_train['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_train['Root Mean Squared Error'] = y_compare_train['Mean Squared Error']**0.5\n",
    "y_compare_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the best result that we have obtained so far. This ANN might potentially be the solution for our problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nNow we will be training a different ANN with lower number of nodes\\n\\n7-4-4-1\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "Now we will be training a different ANN with lower number of nodes\n",
    "\n",
    "7-4-4-1\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24362/24362 [==============================] - 5s 186us/step - loss: 0.2127\n",
      "Epoch 2/100\n",
      "24362/24362 [==============================] - 5s 199us/step - loss: 0.1027\n",
      "Epoch 3/100\n",
      "24362/24362 [==============================] - 5s 210us/step - loss: 0.0961\n",
      "Epoch 4/100\n",
      "24362/24362 [==============================] - 5s 188us/step - loss: 0.0882\n",
      "Epoch 5/100\n",
      "24362/24362 [==============================] - 5s 198us/step - loss: 0.0817\n",
      "Epoch 6/100\n",
      "24362/24362 [==============================] - 5s 210us/step - loss: 0.0776\n",
      "Epoch 7/100\n",
      "24362/24362 [==============================] - 7s 270us/step - loss: 0.0769\n",
      "Epoch 8/100\n",
      "24362/24362 [==============================] - 6s 237us/step - loss: 0.0706\n",
      "Epoch 9/100\n",
      "24362/24362 [==============================] - 5s 186us/step - loss: 0.0682\n",
      "Epoch 10/100\n",
      "24362/24362 [==============================] - 5s 190us/step - loss: 0.0654\n",
      "Epoch 11/100\n",
      "24362/24362 [==============================] - 4s 173us/step - loss: 0.0659\n",
      "Epoch 12/100\n",
      "24362/24362 [==============================] - 5s 199us/step - loss: 0.0622\n",
      "Epoch 13/100\n",
      "24362/24362 [==============================] - 4s 170us/step - loss: 0.0637\n",
      "Epoch 14/100\n",
      "24362/24362 [==============================] - 4s 169us/step - loss: 0.0640\n",
      "Epoch 15/100\n",
      "24362/24362 [==============================] - 4s 167us/step - loss: 0.0607\n",
      "Epoch 16/100\n",
      "24362/24362 [==============================] - 4s 167us/step - loss: 0.0571\n",
      "Epoch 17/100\n",
      "24362/24362 [==============================] - 4s 166us/step - loss: 0.0631\n",
      "Epoch 18/100\n",
      "24362/24362 [==============================] - 4s 168us/step - loss: 0.0601\n",
      "Epoch 19/100\n",
      "24362/24362 [==============================] - 4s 166us/step - loss: 0.0585\n",
      "Epoch 20/100\n",
      "24362/24362 [==============================] - 4s 168us/step - loss: 0.0616\n",
      "Epoch 21/100\n",
      "24362/24362 [==============================] - 4s 168us/step - loss: 0.0604\n",
      "Epoch 22/100\n",
      "24362/24362 [==============================] - 4s 167us/step - loss: 0.0567\n",
      "Epoch 23/100\n",
      "24362/24362 [==============================] - 4s 165us/step - loss: 0.0555\n",
      "Epoch 24/100\n",
      "24362/24362 [==============================] - 4s 167us/step - loss: 0.0525\n",
      "Epoch 25/100\n",
      "24362/24362 [==============================] - 4s 167us/step - loss: 0.0582\n",
      "Epoch 26/100\n",
      "24362/24362 [==============================] - 4s 165us/step - loss: 0.0551\n",
      "Epoch 27/100\n",
      "24362/24362 [==============================] - 4s 166us/step - loss: 0.0568\n",
      "Epoch 28/100\n",
      "24362/24362 [==============================] - 4s 164us/step - loss: 0.0572\n",
      "Epoch 29/100\n",
      "24362/24362 [==============================] - 4s 166us/step - loss: 0.0566\n",
      "Epoch 30/100\n",
      "24362/24362 [==============================] - 4s 163us/step - loss: 0.0545\n",
      "Epoch 31/100\n",
      "24362/24362 [==============================] - 4s 163us/step - loss: 0.0534\n",
      "Epoch 32/100\n",
      "24362/24362 [==============================] - 4s 163us/step - loss: 0.0582\n",
      "Epoch 33/100\n",
      "24362/24362 [==============================] - 4s 166us/step - loss: 0.0438\n",
      "Epoch 34/100\n",
      "24362/24362 [==============================] - 4s 165us/step - loss: 0.0559\n",
      "Epoch 35/100\n",
      "24362/24362 [==============================] - 4s 165us/step - loss: 0.0562\n",
      "Epoch 36/100\n",
      "24362/24362 [==============================] - 4s 167us/step - loss: 0.0499\n",
      "Epoch 37/100\n",
      "24362/24362 [==============================] - 4s 167us/step - loss: 0.0562\n",
      "Epoch 38/100\n",
      "24362/24362 [==============================] - 4s 165us/step - loss: 0.0454\n",
      "Epoch 39/100\n",
      "24362/24362 [==============================] - 4s 164us/step - loss: 0.0491\n",
      "Epoch 40/100\n",
      "24362/24362 [==============================] - 4s 163us/step - loss: 0.0538\n",
      "Epoch 41/100\n",
      "24362/24362 [==============================] - 4s 166us/step - loss: 0.0539\n",
      "Epoch 42/100\n",
      "24362/24362 [==============================] - 4s 163us/step - loss: 0.0512\n",
      "Epoch 43/100\n",
      "24362/24362 [==============================] - 4s 165us/step - loss: 0.0523\n",
      "Epoch 44/100\n",
      "24362/24362 [==============================] - 4s 166us/step - loss: 0.0504\n",
      "Epoch 45/100\n",
      "24362/24362 [==============================] - 4s 168us/step - loss: 0.0487\n",
      "Epoch 46/100\n",
      "24362/24362 [==============================] - 4s 167us/step - loss: 0.0551\n",
      "Epoch 47/100\n",
      "24362/24362 [==============================] - 4s 168us/step - loss: 0.0441\n",
      "Epoch 48/100\n",
      "24362/24362 [==============================] - 4s 164us/step - loss: 0.0515\n",
      "Epoch 49/100\n",
      "24362/24362 [==============================] - 5s 187us/step - loss: 0.0537\n",
      "Epoch 50/100\n",
      "24362/24362 [==============================] - 5s 212us/step - loss: 0.0539\n",
      "Epoch 51/100\n",
      "24362/24362 [==============================] - 4s 172us/step - loss: 0.0457\n",
      "Epoch 52/100\n",
      "24362/24362 [==============================] - 4s 169us/step - loss: 0.0518\n",
      "Epoch 53/100\n",
      "24362/24362 [==============================] - 4s 177us/step - loss: 0.0551\n",
      "Epoch 54/100\n",
      "24362/24362 [==============================] - 5s 192us/step - loss: 0.0548\n",
      "Epoch 55/100\n",
      "24362/24362 [==============================] - 4s 169us/step - loss: 0.0482\n",
      "Epoch 56/100\n",
      "24362/24362 [==============================] - 4s 163us/step - loss: 0.0526\n",
      "Epoch 57/100\n",
      "24362/24362 [==============================] - 4s 162us/step - loss: 0.0524\n",
      "Epoch 58/100\n",
      "24362/24362 [==============================] - 4s 163us/step - loss: 0.0520\n",
      "Epoch 59/100\n",
      "24362/24362 [==============================] - 4s 163us/step - loss: 0.0508\n",
      "Epoch 60/100\n",
      "24362/24362 [==============================] - 4s 163us/step - loss: 0.0488\n",
      "Epoch 61/100\n",
      "24362/24362 [==============================] - 4s 163us/step - loss: 0.0584\n",
      "Epoch 62/100\n",
      "24362/24362 [==============================] - 4s 163us/step - loss: 0.0491\n",
      "Epoch 63/100\n",
      "24362/24362 [==============================] - 4s 163us/step - loss: 0.0529\n",
      "Epoch 64/100\n",
      "24362/24362 [==============================] - 4s 163us/step - loss: 0.0505\n",
      "Epoch 65/100\n",
      "24362/24362 [==============================] - 4s 162us/step - loss: 0.0461\n",
      "Epoch 66/100\n",
      "24362/24362 [==============================] - 4s 163us/step - loss: 0.0528\n",
      "Epoch 67/100\n",
      "24362/24362 [==============================] - 4s 162us/step - loss: 0.0479\n",
      "Epoch 68/100\n",
      "24362/24362 [==============================] - 4s 162us/step - loss: 0.0487\n",
      "Epoch 69/100\n",
      "24362/24362 [==============================] - 4s 162us/step - loss: 0.0459\n",
      "Epoch 70/100\n",
      "24362/24362 [==============================] - 4s 162us/step - loss: 0.0500\n",
      "Epoch 71/100\n",
      "24362/24362 [==============================] - 4s 162us/step - loss: 0.0462\n",
      "Epoch 72/100\n",
      "24362/24362 [==============================] - 4s 163us/step - loss: 0.0417\n",
      "Epoch 73/100\n",
      "24362/24362 [==============================] - 4s 164us/step - loss: 0.0562\n",
      "Epoch 74/100\n",
      "24362/24362 [==============================] - 4s 164us/step - loss: 0.0462\n",
      "Epoch 75/100\n",
      "24362/24362 [==============================] - 4s 162us/step - loss: 0.0496\n",
      "Epoch 76/100\n",
      "24362/24362 [==============================] - 4s 163us/step - loss: 0.0454\n",
      "Epoch 77/100\n",
      "24362/24362 [==============================] - 4s 162us/step - loss: 0.0477\n",
      "Epoch 78/100\n",
      "24362/24362 [==============================] - 4s 169us/step - loss: 0.0483\n",
      "Epoch 79/100\n",
      "24362/24362 [==============================] - 4s 173us/step - loss: 0.0480\n",
      "Epoch 80/100\n",
      "24362/24362 [==============================] - 4s 169us/step - loss: 0.0428\n",
      "Epoch 81/100\n",
      "24362/24362 [==============================] - 4s 170us/step - loss: 0.0495\n",
      "Epoch 82/100\n",
      "24362/24362 [==============================] - 4s 163us/step - loss: 0.0456\n",
      "Epoch 83/100\n",
      "24362/24362 [==============================] - 4s 164us/step - loss: 0.0455\n",
      "Epoch 84/100\n",
      "24362/24362 [==============================] - 4s 165us/step - loss: 0.0432\n",
      "Epoch 85/100\n",
      "24362/24362 [==============================] - 4s 163us/step - loss: 0.0408\n",
      "Epoch 86/100\n",
      "24362/24362 [==============================] - 4s 177us/step - loss: 0.0463\n",
      "Epoch 87/100\n",
      "24362/24362 [==============================] - 4s 173us/step - loss: 0.0426\n",
      "Epoch 88/100\n",
      "24362/24362 [==============================] - 4s 169us/step - loss: 0.0489\n",
      "Epoch 89/100\n",
      "24362/24362 [==============================] - 4s 168us/step - loss: 0.0450\n",
      "Epoch 90/100\n",
      "24362/24362 [==============================] - 4s 170us/step - loss: 0.0471\n",
      "Epoch 91/100\n",
      "24362/24362 [==============================] - 4s 162us/step - loss: 0.0462\n",
      "Epoch 92/100\n",
      "24362/24362 [==============================] - 4s 178us/step - loss: 0.0462\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24362/24362 [==============================] - 4s 167us/step - loss: 0.0420\n",
      "Epoch 94/100\n",
      "24362/24362 [==============================] - 4s 166us/step - loss: 0.0413\n",
      "Epoch 95/100\n",
      "24362/24362 [==============================] - 4s 168us/step - loss: 0.0428\n",
      "Epoch 96/100\n",
      "24362/24362 [==============================] - 4s 167us/step - loss: 0.0484\n",
      "Epoch 97/100\n",
      "24362/24362 [==============================] - 4s 165us/step - loss: 0.0422\n",
      "Epoch 98/100\n",
      "24362/24362 [==============================] - 4s 166us/step - loss: 0.0464\n",
      "Epoch 99/100\n",
      "24362/24362 [==============================] - 4s 180us/step - loss: 0.0472\n",
      "Epoch 100/100\n",
      "24362/24362 [==============================] - 4s 163us/step - loss: 0.0428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12fef3358>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Building a 3 layer ANN with less number of nodes \"\"\"\n",
    "\n",
    "regressor_1 = Sequential()\n",
    "regressor_1.add(Dense(4, kernel_initializer = 'normal',activation = 'relu',input_dim = 7))\n",
    "regressor_1.add(Dense(4, kernel_initializer = 'normal', activation = 'relu'))\n",
    "regressor_1.add(Dense(1, kernel_initializer = 'normal'))\n",
    "\n",
    "\"\"\" Compiling the regressor \"\"\"\n",
    "regressor_1.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "\"\"\" Fitting the Artifilial Neural Network to our training data \"\"\"\n",
    "regressor_1.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.053374</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.158912</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.228624</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.196210</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.219295</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.425145</td>\n",
       "      <td>1.319555</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.128724</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.235881</td>\n",
       "      <td>-0.234551</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.193947</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.238192</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.199631</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.879658</td>\n",
       "      <td>2.187994</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.196858</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.178084</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.250194</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.174051</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.210007</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.243316</td>\n",
       "      <td>1.740571</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.188479</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.280874</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.243316</td>\n",
       "      <td>1.805429</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.256047</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.195563</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.137505</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.177578</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.173227</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.821420</td>\n",
       "      <td>0.681434</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.007470</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.251207</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6061</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.185232</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.209110</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>16.152226</td>\n",
       "      <td>15.508955</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.158892</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>0.461583</td>\n",
       "      <td>0.270131</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.254513</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6067</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.201364</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6068</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.242365</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6069</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.256526</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6070</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.209845</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6071</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.266671</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6072</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.230163</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.185201</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.189900</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6075</th>\n",
       "      <td>3.061487</td>\n",
       "      <td>2.343393</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.194834</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.176968</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>-0.126516</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6079</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.257571</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6080</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.257904</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6081</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.221400</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6082</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.181234</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6083</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.169314</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6084</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.198384</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6085</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.221400</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6086</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.221400</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.154720</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6088</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.173175</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6089</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.288190</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6090</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.197379</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.188133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6091 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual Values  Predicted Values  Mean Squared Error  \\\n",
       "0          0.101746          0.053374            0.035394   \n",
       "1         -0.211198         -0.158912            0.035394   \n",
       "2         -0.258092         -0.228624            0.035394   \n",
       "3         -0.196210          0.010753            0.035394   \n",
       "4         -0.211198         -0.219295            0.035394   \n",
       "5          1.425145          1.319555            0.035394   \n",
       "6         -0.211198         -0.128724            0.035394   \n",
       "7         -0.235881         -0.234551            0.035394   \n",
       "8         -0.211198         -0.193947            0.035394   \n",
       "9         -0.258092         -0.238192            0.035394   \n",
       "10        -0.211198         -0.199631            0.035394   \n",
       "11         3.879658          2.187994            0.035394   \n",
       "12        -0.211198         -0.196858            0.035394   \n",
       "13        -0.211198         -0.178084            0.035394   \n",
       "14        -0.258092         -0.250194            0.035394   \n",
       "15        -0.211198         -0.174051            0.035394   \n",
       "16        -0.211198         -0.210007            0.035394   \n",
       "17         2.243316          1.740571            0.035394   \n",
       "18        -0.211198          0.005495            0.035394   \n",
       "19        -0.211198         -0.188479            0.035394   \n",
       "20        -0.258092         -0.280874            0.035394   \n",
       "21         2.243316          1.805429            0.035394   \n",
       "22        -0.258092         -0.256047            0.035394   \n",
       "23        -0.211198         -0.195563            0.035394   \n",
       "24        -0.211198         -0.137505            0.035394   \n",
       "25        -0.211198         -0.177578            0.035394   \n",
       "26        -0.211198         -0.173227            0.035394   \n",
       "27         0.821420          0.681434            0.035394   \n",
       "28         0.101746          0.007470            0.035394   \n",
       "29        -0.258092         -0.251207            0.035394   \n",
       "...             ...               ...                 ...   \n",
       "6061      -0.211198         -0.185232            0.035394   \n",
       "6062      -0.258092         -0.209110            0.035394   \n",
       "6063      16.152226         15.508955            0.035394   \n",
       "6064      -0.211198         -0.158892            0.035394   \n",
       "6065       0.461583          0.270131            0.035394   \n",
       "6066      -0.258092         -0.254513            0.035394   \n",
       "6067      -0.211198         -0.201364            0.035394   \n",
       "6068      -0.258092         -0.242365            0.035394   \n",
       "6069      -0.258092         -0.256526            0.035394   \n",
       "6070      -0.211198         -0.209845            0.035394   \n",
       "6071      -0.258092         -0.266671            0.035394   \n",
       "6072      -0.211198         -0.230163            0.035394   \n",
       "6073      -0.211198         -0.185201            0.035394   \n",
       "6074      -0.211198         -0.189900            0.035394   \n",
       "6075       3.061487          2.343393            0.035394   \n",
       "6076      -0.211198         -0.194834            0.035394   \n",
       "6077      -0.211198         -0.176968            0.035394   \n",
       "6078       0.101746         -0.126516            0.035394   \n",
       "6079      -0.258092         -0.257571            0.035394   \n",
       "6080      -0.258092         -0.257904            0.035394   \n",
       "6081      -0.258092         -0.221400            0.035394   \n",
       "6082      -0.211198         -0.181234            0.035394   \n",
       "6083      -0.211198         -0.169314            0.035394   \n",
       "6084      -0.211198         -0.198384            0.035394   \n",
       "6085      -0.211198         -0.221400            0.035394   \n",
       "6086      -0.258092         -0.221400            0.035394   \n",
       "6087      -0.211198         -0.154720            0.035394   \n",
       "6088      -0.211198         -0.173175            0.035394   \n",
       "6089      -0.258092         -0.288190            0.035394   \n",
       "6090      -0.211198         -0.197379            0.035394   \n",
       "\n",
       "      Root Mean Squared Error  \n",
       "0                    0.188133  \n",
       "1                    0.188133  \n",
       "2                    0.188133  \n",
       "3                    0.188133  \n",
       "4                    0.188133  \n",
       "5                    0.188133  \n",
       "6                    0.188133  \n",
       "7                    0.188133  \n",
       "8                    0.188133  \n",
       "9                    0.188133  \n",
       "10                   0.188133  \n",
       "11                   0.188133  \n",
       "12                   0.188133  \n",
       "13                   0.188133  \n",
       "14                   0.188133  \n",
       "15                   0.188133  \n",
       "16                   0.188133  \n",
       "17                   0.188133  \n",
       "18                   0.188133  \n",
       "19                   0.188133  \n",
       "20                   0.188133  \n",
       "21                   0.188133  \n",
       "22                   0.188133  \n",
       "23                   0.188133  \n",
       "24                   0.188133  \n",
       "25                   0.188133  \n",
       "26                   0.188133  \n",
       "27                   0.188133  \n",
       "28                   0.188133  \n",
       "29                   0.188133  \n",
       "...                       ...  \n",
       "6061                 0.188133  \n",
       "6062                 0.188133  \n",
       "6063                 0.188133  \n",
       "6064                 0.188133  \n",
       "6065                 0.188133  \n",
       "6066                 0.188133  \n",
       "6067                 0.188133  \n",
       "6068                 0.188133  \n",
       "6069                 0.188133  \n",
       "6070                 0.188133  \n",
       "6071                 0.188133  \n",
       "6072                 0.188133  \n",
       "6073                 0.188133  \n",
       "6074                 0.188133  \n",
       "6075                 0.188133  \n",
       "6076                 0.188133  \n",
       "6077                 0.188133  \n",
       "6078                 0.188133  \n",
       "6079                 0.188133  \n",
       "6080                 0.188133  \n",
       "6081                 0.188133  \n",
       "6082                 0.188133  \n",
       "6083                 0.188133  \n",
       "6084                 0.188133  \n",
       "6085                 0.188133  \n",
       "6086                 0.188133  \n",
       "6087                 0.188133  \n",
       "6088                 0.188133  \n",
       "6089                 0.188133  \n",
       "6090                 0.188133  \n",
       "\n",
       "[6091 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Predicting the values for Helpful Votes on the test data \"\"\"\n",
    "y_pred_1 = regressor_1.predict(X_test)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against predicted values \"\"\"\n",
    "y_pred_1 = y_pred_1.reshape(6091,)\n",
    "temp = {'Actual Values': y_test,'Predicted Values': y_pred_1}\n",
    "y_compare_1 = pd.DataFrame(temp)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_1['Mean Squared Error'] = (np.diff(y_compare_1.values) ** 2)\n",
    "y_compare_1['Mean Squared Error'] = np.mean(y_compare_1['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_1['Root Mean Squared Error'] = y_compare_1['Mean Squared Error']**0.5\n",
    "y_compare_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values(Training)</th>\n",
       "      <th>Predicted Values(Training)</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.155893</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.195186</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.238900</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.182773</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.165683</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.224587</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.165110</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.221400</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.273406</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.246187</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.240219</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.172858</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>-0.039633</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.221400</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.231465</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.178779</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.171578</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.204171</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.221400</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.215382</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.079606</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.178706</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.175011</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.221400</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.247358</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.243928</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.181772</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.175971</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>0.191225</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.105704</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24332</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.215535</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24333</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.248991</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24334</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.272400</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24335</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.130931</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24336</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.171929</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24337</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.188288</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24338</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>-0.073774</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24339</th>\n",
       "      <td>0.606973</td>\n",
       "      <td>0.793490</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24340</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.171356</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24341</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.281915</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24342</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.145707</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24343</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.151589</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24344</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.221400</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24345</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.189644</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24346</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.206832</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24347</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.210591</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24348</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.179299</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24349</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.241460</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24350</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.200517</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24351</th>\n",
       "      <td>3.061487</td>\n",
       "      <td>3.804718</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24352</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.058867</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24353</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.238823</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24354</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.221400</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24355</th>\n",
       "      <td>-0.196210</td>\n",
       "      <td>-0.039300</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24356</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.158574</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24357</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.272147</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24358</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.159894</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24359</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.273369</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24360</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.279224</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24361</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.295848</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24362 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Values(Training)  Predicted Values(Training)  \\\n",
       "0                    -0.211198                   -0.155893   \n",
       "1                    -0.211198                   -0.195186   \n",
       "2                    -0.258092                   -0.238900   \n",
       "3                    -0.211198                   -0.182773   \n",
       "4                    -0.258092                   -0.165683   \n",
       "5                    -0.258092                   -0.224587   \n",
       "6                    -0.211198                   -0.165110   \n",
       "7                    -0.258092                   -0.221400   \n",
       "8                    -0.258092                   -0.273406   \n",
       "9                    -0.258092                   -0.246187   \n",
       "10                   -0.258092                   -0.240219   \n",
       "11                   -0.211198                   -0.172858   \n",
       "12                    0.101746                   -0.039633   \n",
       "13                   -0.211198                   -0.221400   \n",
       "14                   -0.258092                   -0.231465   \n",
       "15                   -0.211198                   -0.178779   \n",
       "16                   -0.258092                   -0.171578   \n",
       "17                   -0.211198                   -0.204171   \n",
       "18                   -0.258092                   -0.221400   \n",
       "19                   -0.211198                   -0.215382   \n",
       "20                   -0.211198                   -0.079606   \n",
       "21                   -0.211198                   -0.178706   \n",
       "22                   -0.211198                   -0.175011   \n",
       "23                   -0.258092                   -0.221400   \n",
       "24                   -0.258092                   -0.247358   \n",
       "25                   -0.258092                   -0.243928   \n",
       "26                   -0.211198                   -0.181772   \n",
       "27                   -0.211198                   -0.175971   \n",
       "28                   -0.211198                    0.191225   \n",
       "29                   -0.211198                   -0.105704   \n",
       "...                        ...                         ...   \n",
       "24332                -0.258092                   -0.215535   \n",
       "24333                -0.258092                   -0.248991   \n",
       "24334                -0.258092                   -0.272400   \n",
       "24335                -0.211198                   -0.130931   \n",
       "24336                -0.211198                   -0.171929   \n",
       "24337                -0.211198                   -0.188288   \n",
       "24338                 0.101746                   -0.073774   \n",
       "24339                 0.606973                    0.793490   \n",
       "24340                -0.211198                   -0.171356   \n",
       "24341                -0.258092                   -0.281915   \n",
       "24342                -0.211198                   -0.145707   \n",
       "24343                -0.211198                   -0.151589   \n",
       "24344                -0.258092                   -0.221400   \n",
       "24345                -0.211198                   -0.189644   \n",
       "24346                -0.258092                   -0.206832   \n",
       "24347                -0.211198                   -0.210591   \n",
       "24348                -0.211198                   -0.179299   \n",
       "24349                -0.258092                   -0.241460   \n",
       "24350                -0.258092                   -0.200517   \n",
       "24351                 3.061487                    3.804718   \n",
       "24352                -0.211198                   -0.058867   \n",
       "24353                -0.211198                   -0.238823   \n",
       "24354                -0.258092                   -0.221400   \n",
       "24355                -0.196210                   -0.039300   \n",
       "24356                -0.211198                   -0.158574   \n",
       "24357                -0.258092                   -0.272147   \n",
       "24358                -0.211198                   -0.159894   \n",
       "24359                -0.258092                   -0.273369   \n",
       "24360                -0.258092                   -0.279224   \n",
       "24361                -0.258092                   -0.295848   \n",
       "\n",
       "       Mean Squared Error  Root Mean Squared Error  \n",
       "0                0.039295                 0.198229  \n",
       "1                0.039295                 0.198229  \n",
       "2                0.039295                 0.198229  \n",
       "3                0.039295                 0.198229  \n",
       "4                0.039295                 0.198229  \n",
       "5                0.039295                 0.198229  \n",
       "6                0.039295                 0.198229  \n",
       "7                0.039295                 0.198229  \n",
       "8                0.039295                 0.198229  \n",
       "9                0.039295                 0.198229  \n",
       "10               0.039295                 0.198229  \n",
       "11               0.039295                 0.198229  \n",
       "12               0.039295                 0.198229  \n",
       "13               0.039295                 0.198229  \n",
       "14               0.039295                 0.198229  \n",
       "15               0.039295                 0.198229  \n",
       "16               0.039295                 0.198229  \n",
       "17               0.039295                 0.198229  \n",
       "18               0.039295                 0.198229  \n",
       "19               0.039295                 0.198229  \n",
       "20               0.039295                 0.198229  \n",
       "21               0.039295                 0.198229  \n",
       "22               0.039295                 0.198229  \n",
       "23               0.039295                 0.198229  \n",
       "24               0.039295                 0.198229  \n",
       "25               0.039295                 0.198229  \n",
       "26               0.039295                 0.198229  \n",
       "27               0.039295                 0.198229  \n",
       "28               0.039295                 0.198229  \n",
       "29               0.039295                 0.198229  \n",
       "...                   ...                      ...  \n",
       "24332            0.039295                 0.198229  \n",
       "24333            0.039295                 0.198229  \n",
       "24334            0.039295                 0.198229  \n",
       "24335            0.039295                 0.198229  \n",
       "24336            0.039295                 0.198229  \n",
       "24337            0.039295                 0.198229  \n",
       "24338            0.039295                 0.198229  \n",
       "24339            0.039295                 0.198229  \n",
       "24340            0.039295                 0.198229  \n",
       "24341            0.039295                 0.198229  \n",
       "24342            0.039295                 0.198229  \n",
       "24343            0.039295                 0.198229  \n",
       "24344            0.039295                 0.198229  \n",
       "24345            0.039295                 0.198229  \n",
       "24346            0.039295                 0.198229  \n",
       "24347            0.039295                 0.198229  \n",
       "24348            0.039295                 0.198229  \n",
       "24349            0.039295                 0.198229  \n",
       "24350            0.039295                 0.198229  \n",
       "24351            0.039295                 0.198229  \n",
       "24352            0.039295                 0.198229  \n",
       "24353            0.039295                 0.198229  \n",
       "24354            0.039295                 0.198229  \n",
       "24355            0.039295                 0.198229  \n",
       "24356            0.039295                 0.198229  \n",
       "24357            0.039295                 0.198229  \n",
       "24358            0.039295                 0.198229  \n",
       "24359            0.039295                 0.198229  \n",
       "24360            0.039295                 0.198229  \n",
       "24361            0.039295                 0.198229  \n",
       "\n",
       "[24362 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Now we will also predict the y values on the training set just to calculate MSE and RMSE \"\"\"\n",
    "\n",
    "y_pred_train_1 = regressor_1.predict(X_train)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against the predicted values for the training set \"\"\"\n",
    "y_pred_train_1 = y_pred_train_1.reshape(24362,)\n",
    "temp_train = {'Actual Values(Training)':y_train, 'Predicted Values(Training)': y_pred_train_1 }\n",
    "y_compare_train_1 = pd.DataFrame(temp_train)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN on TRAINING SET\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_train_1['Mean Squared Error'] = (np.diff(y_compare_train_1.values) ** 2)\n",
    "y_compare_train_1['Mean Squared Error'] = np.mean(y_compare_train_1['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_train_1['Root Mean Squared Error'] = y_compare_train_1['Mean Squared Error']**0.5\n",
    "y_compare_train_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ANN is the second best. The first one in this notebook is the best so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nNow, we will train an ANN with a very high number of nodes. And comparitively more layers.\\n\\n7-50-100-200-100-50-20-1\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "Now, we will train an ANN with a very high number of nodes. And comparitively more layers.\n",
    "\n",
    "7-50-100-200-100-50-20-1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24362/24362 [==============================] - 7s 275us/step - loss: 0.1956\n",
      "Epoch 2/100\n",
      "24362/24362 [==============================] - 6s 263us/step - loss: 0.2921\n",
      "Epoch 3/100\n",
      "24362/24362 [==============================] - 7s 274us/step - loss: 0.3348\n",
      "Epoch 4/100\n",
      "24362/24362 [==============================] - 7s 268us/step - loss: 0.2089\n",
      "Epoch 5/100\n",
      "24362/24362 [==============================] - 6s 262us/step - loss: 0.1955\n",
      "Epoch 6/100\n",
      "24362/24362 [==============================] - 6s 258us/step - loss: 0.2002\n",
      "Epoch 7/100\n",
      "24362/24362 [==============================] - 6s 262us/step - loss: 0.1028\n",
      "Epoch 8/100\n",
      "24362/24362 [==============================] - 6s 262us/step - loss: 0.3391\n",
      "Epoch 9/100\n",
      "24362/24362 [==============================] - 7s 274us/step - loss: 0.2377\n",
      "Epoch 10/100\n",
      "24362/24362 [==============================] - 7s 273us/step - loss: 0.1533\n",
      "Epoch 11/100\n",
      "24362/24362 [==============================] - 7s 268us/step - loss: 0.1785\n",
      "Epoch 12/100\n",
      "24362/24362 [==============================] - 7s 276us/step - loss: 0.1787\n",
      "Epoch 13/100\n",
      "24362/24362 [==============================] - 7s 286us/step - loss: 0.2180\n",
      "Epoch 14/100\n",
      "24362/24362 [==============================] - 7s 279us/step - loss: 0.3174\n",
      "Epoch 15/100\n",
      "24362/24362 [==============================] - 7s 279us/step - loss: 0.2903\n",
      "Epoch 16/100\n",
      "24362/24362 [==============================] - 7s 270us/step - loss: 0.2538\n",
      "Epoch 17/100\n",
      "24362/24362 [==============================] - 7s 269us/step - loss: 0.1061\n",
      "Epoch 18/100\n",
      "24362/24362 [==============================] - 7s 271us/step - loss: 0.2018\n",
      "Epoch 19/100\n",
      "24362/24362 [==============================] - 7s 267us/step - loss: 0.1299\n",
      "Epoch 20/100\n",
      "24362/24362 [==============================] - 7s 270us/step - loss: 0.5595\n",
      "Epoch 21/100\n",
      "24362/24362 [==============================] - 7s 270us/step - loss: 0.2772\n",
      "Epoch 22/100\n",
      "24362/24362 [==============================] - 7s 272us/step - loss: 0.1497\n",
      "Epoch 23/100\n",
      "24362/24362 [==============================] - 7s 272us/step - loss: 0.1653\n",
      "Epoch 24/100\n",
      "24362/24362 [==============================] - 7s 270us/step - loss: 0.1148\n",
      "Epoch 25/100\n",
      "24362/24362 [==============================] - 7s 274us/step - loss: 0.0984\n",
      "Epoch 26/100\n",
      "24362/24362 [==============================] - 7s 269us/step - loss: 0.2784\n",
      "Epoch 27/100\n",
      "24362/24362 [==============================] - 6s 265us/step - loss: 0.1993\n",
      "Epoch 28/100\n",
      "24362/24362 [==============================] - 6s 266us/step - loss: 0.1253\n",
      "Epoch 29/100\n",
      "24362/24362 [==============================] - 6s 266us/step - loss: 0.1623\n",
      "Epoch 30/100\n",
      "24362/24362 [==============================] - 6s 267us/step - loss: 0.1702\n",
      "Epoch 31/100\n",
      "24362/24362 [==============================] - 7s 287us/step - loss: 0.1922\n",
      "Epoch 32/100\n",
      "24362/24362 [==============================] - 7s 280us/step - loss: 0.1385\n",
      "Epoch 33/100\n",
      "24362/24362 [==============================] - 7s 269us/step - loss: 0.1556\n",
      "Epoch 34/100\n",
      "24362/24362 [==============================] - 6s 266us/step - loss: 0.2127\n",
      "Epoch 35/100\n",
      "24362/24362 [==============================] - 7s 272us/step - loss: 0.1380\n",
      "Epoch 36/100\n",
      "24362/24362 [==============================] - 6s 267us/step - loss: 0.1483\n",
      "Epoch 37/100\n",
      "24362/24362 [==============================] - 7s 269us/step - loss: 0.1422\n",
      "Epoch 38/100\n",
      "24362/24362 [==============================] - 7s 281us/step - loss: 0.2643\n",
      "Epoch 39/100\n",
      "24362/24362 [==============================] - 8s 313us/step - loss: 0.1367\n",
      "Epoch 40/100\n",
      "24362/24362 [==============================] - 8s 339us/step - loss: 0.1696\n",
      "Epoch 41/100\n",
      "24362/24362 [==============================] - 8s 326us/step - loss: 0.2099\n",
      "Epoch 42/100\n",
      "24362/24362 [==============================] - 7s 300us/step - loss: 0.1765\n",
      "Epoch 43/100\n",
      "24362/24362 [==============================] - 7s 298us/step - loss: 0.1460\n",
      "Epoch 44/100\n",
      "24362/24362 [==============================] - 7s 295us/step - loss: 0.2324\n",
      "Epoch 45/100\n",
      "24362/24362 [==============================] - 7s 270us/step - loss: 0.1334\n",
      "Epoch 46/100\n",
      "24362/24362 [==============================] - 7s 272us/step - loss: 0.0843\n",
      "Epoch 47/100\n",
      "24362/24362 [==============================] - 7s 283us/step - loss: 64.9576\n",
      "Epoch 48/100\n",
      "24362/24362 [==============================] - 7s 275us/step - loss: 0.0746\n",
      "Epoch 49/100\n",
      "24362/24362 [==============================] - 7s 277us/step - loss: 0.0677\n",
      "Epoch 50/100\n",
      "24362/24362 [==============================] - 7s 275us/step - loss: 0.0595\n",
      "Epoch 51/100\n",
      "24362/24362 [==============================] - 7s 267us/step - loss: 0.1869\n",
      "Epoch 52/100\n",
      "24362/24362 [==============================] - 7s 275us/step - loss: 0.2278\n",
      "Epoch 53/100\n",
      "24362/24362 [==============================] - 7s 271us/step - loss: 0.1391 0s - loss\n",
      "Epoch 54/100\n",
      "24362/24362 [==============================] - 7s 273us/step - loss: 0.2264\n",
      "Epoch 55/100\n",
      "24362/24362 [==============================] - 7s 269us/step - loss: 5.8102\n",
      "Epoch 56/100\n",
      "24362/24362 [==============================] - 7s 274us/step - loss: 0.0722\n",
      "Epoch 57/100\n",
      "24362/24362 [==============================] - 7s 275us/step - loss: 0.2497\n",
      "Epoch 58/100\n",
      "24362/24362 [==============================] - 7s 269us/step - loss: 0.1202\n",
      "Epoch 59/100\n",
      "24362/24362 [==============================] - 6s 266us/step - loss: 0.2310\n",
      "Epoch 60/100\n",
      "24362/24362 [==============================] - 7s 270us/step - loss: 0.2199\n",
      "Epoch 61/100\n",
      "24362/24362 [==============================] - 7s 276us/step - loss: 0.6530\n",
      "Epoch 62/100\n",
      "24362/24362 [==============================] - 7s 275us/step - loss: 0.1042\n",
      "Epoch 63/100\n",
      "24362/24362 [==============================] - 7s 271us/step - loss: 0.2724\n",
      "Epoch 64/100\n",
      "24362/24362 [==============================] - 7s 268us/step - loss: 0.1483\n",
      "Epoch 65/100\n",
      "24362/24362 [==============================] - 7s 272us/step - loss: 1.5232\n",
      "Epoch 66/100\n",
      "24362/24362 [==============================] - 7s 276us/step - loss: 0.1413\n",
      "Epoch 67/100\n",
      "24362/24362 [==============================] - 7s 270us/step - loss: 0.1531\n",
      "Epoch 68/100\n",
      "24362/24362 [==============================] - 7s 270us/step - loss: 0.0417\n",
      "Epoch 69/100\n",
      "24362/24362 [==============================] - 7s 273us/step - loss: 79.9284\n",
      "Epoch 70/100\n",
      "24362/24362 [==============================] - 7s 275us/step - loss: 0.0896\n",
      "Epoch 71/100\n",
      "24362/24362 [==============================] - 7s 269us/step - loss: 0.0879\n",
      "Epoch 72/100\n",
      "24362/24362 [==============================] - 7s 271us/step - loss: 0.1956\n",
      "Epoch 73/100\n",
      "24362/24362 [==============================] - 7s 270us/step - loss: 0.3995\n",
      "Epoch 74/100\n",
      "24362/24362 [==============================] - 7s 273us/step - loss: 0.1621\n",
      "Epoch 75/100\n",
      "24362/24362 [==============================] - 7s 274us/step - loss: 0.2985\n",
      "Epoch 76/100\n",
      "24362/24362 [==============================] - 7s 276us/step - loss: 0.1149\n",
      "Epoch 77/100\n",
      "24362/24362 [==============================] - 7s 272us/step - loss: 0.0913\n",
      "Epoch 78/100\n",
      "24362/24362 [==============================] - 7s 272us/step - loss: 0.1557\n",
      "Epoch 79/100\n",
      "24362/24362 [==============================] - 7s 269us/step - loss: 0.2961\n",
      "Epoch 80/100\n",
      "24362/24362 [==============================] - 7s 274us/step - loss: 0.0655\n",
      "Epoch 81/100\n",
      "24362/24362 [==============================] - 7s 278us/step - loss: 0.1264\n",
      "Epoch 82/100\n",
      "24362/24362 [==============================] - 7s 275us/step - loss: 0.1206\n",
      "Epoch 83/100\n",
      "24362/24362 [==============================] - 7s 273us/step - loss: 0.1047\n",
      "Epoch 84/100\n",
      "24362/24362 [==============================] - 7s 273us/step - loss: 0.1539\n",
      "Epoch 85/100\n",
      "24362/24362 [==============================] - 7s 277us/step - loss: 0.1769\n",
      "Epoch 86/100\n",
      "24362/24362 [==============================] - 7s 270us/step - loss: 0.1367\n",
      "Epoch 87/100\n",
      "24362/24362 [==============================] - 7s 273us/step - loss: 0.1817\n",
      "Epoch 88/100\n",
      "24362/24362 [==============================] - 7s 274us/step - loss: 0.3219\n",
      "Epoch 89/100\n",
      "24362/24362 [==============================] - 7s 280us/step - loss: 0.2239\n",
      "Epoch 90/100\n",
      "24362/24362 [==============================] - 7s 272us/step - loss: 0.1139\n",
      "Epoch 91/100\n",
      "24362/24362 [==============================] - 7s 272us/step - loss: 0.1940\n",
      "Epoch 92/100\n",
      "24362/24362 [==============================] - 7s 276us/step - loss: 0.2268\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24362/24362 [==============================] - 7s 268us/step - loss: 0.2340\n",
      "Epoch 94/100\n",
      "24362/24362 [==============================] - 7s 273us/step - loss: 0.2805\n",
      "Epoch 95/100\n",
      "24362/24362 [==============================] - 7s 272us/step - loss: 0.3039\n",
      "Epoch 96/100\n",
      "24362/24362 [==============================] - 7s 272us/step - loss: 0.1419\n",
      "Epoch 97/100\n",
      "24362/24362 [==============================] - 7s 271us/step - loss: 0.1545\n",
      "Epoch 98/100\n",
      "24362/24362 [==============================] - 7s 272us/step - loss: 47.6952\n",
      "Epoch 99/100\n",
      "24362/24362 [==============================] - 7s 274us/step - loss: 0.1583\n",
      "Epoch 100/100\n",
      "24362/24362 [==============================] - 7s 270us/step - loss: 0.0779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13032c5c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Building a deep and wide ANN with high number of nodes \"\"\"\n",
    "\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "regressor_2 = Sequential()\n",
    "regressor_2.add(Dense(50, kernel_initializer = 'normal',input_dim = 7))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(100, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(200, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(100, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(50, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(20, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(1, kernel_initializer = 'normal'))\n",
    "\n",
    "\"\"\" Compiling the regressor \"\"\"\n",
    "regressor_2.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "\"\"\" Fitting the Artifilial Neural Network to our training data \"\"\"\n",
    "regressor_2.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.183354</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.173277</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.281324</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.196210</td>\n",
       "      <td>0.060603</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.214418</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.425145</td>\n",
       "      <td>1.138649</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.264189</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.235881</td>\n",
       "      <td>-0.226377</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.254320</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.283016</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.239215</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.879658</td>\n",
       "      <td>2.138154</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.162862</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.215024</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.269849</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.247158</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.217232</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.243316</td>\n",
       "      <td>1.774622</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.216204</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.243869</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.247811</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.243316</td>\n",
       "      <td>1.982234</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.221002</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.287249</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.249163</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.182691</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.252263</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.821420</td>\n",
       "      <td>0.672389</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.125957</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.267359</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6061</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.233609</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.219329</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>16.152226</td>\n",
       "      <td>14.028356</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.233595</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>0.461583</td>\n",
       "      <td>0.281155</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.210681</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6067</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.232575</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6068</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.270507</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6069</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.261017</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6070</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.118617</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6071</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.200191</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6072</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.192348</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.231899</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.231784</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6075</th>\n",
       "      <td>3.061487</td>\n",
       "      <td>2.098654</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.316979</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.191415</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.094460</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6079</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.275014</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6080</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.286252</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6081</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.317303</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6082</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.256057</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6083</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.226193</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6084</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.190923</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6085</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.248470</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6086</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.341541</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.182190</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6088</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.228199</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6089</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.261753</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6090</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.241210</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.208971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6091 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual Values  Predicted Values  Mean Squared Error  \\\n",
       "0          0.101746          0.183354            0.043669   \n",
       "1         -0.211198         -0.173277            0.043669   \n",
       "2         -0.258092         -0.281324            0.043669   \n",
       "3         -0.196210          0.060603            0.043669   \n",
       "4         -0.211198         -0.214418            0.043669   \n",
       "5          1.425145          1.138649            0.043669   \n",
       "6         -0.211198         -0.264189            0.043669   \n",
       "7         -0.235881         -0.226377            0.043669   \n",
       "8         -0.211198         -0.254320            0.043669   \n",
       "9         -0.258092         -0.283016            0.043669   \n",
       "10        -0.211198         -0.239215            0.043669   \n",
       "11         3.879658          2.138154            0.043669   \n",
       "12        -0.211198         -0.162862            0.043669   \n",
       "13        -0.211198         -0.215024            0.043669   \n",
       "14        -0.258092         -0.269849            0.043669   \n",
       "15        -0.211198         -0.247158            0.043669   \n",
       "16        -0.211198         -0.217232            0.043669   \n",
       "17         2.243316          1.774622            0.043669   \n",
       "18        -0.211198         -0.216204            0.043669   \n",
       "19        -0.211198         -0.243869            0.043669   \n",
       "20        -0.258092         -0.247811            0.043669   \n",
       "21         2.243316          1.982234            0.043669   \n",
       "22        -0.258092         -0.221002            0.043669   \n",
       "23        -0.211198         -0.287249            0.043669   \n",
       "24        -0.211198         -0.249163            0.043669   \n",
       "25        -0.211198         -0.182691            0.043669   \n",
       "26        -0.211198         -0.252263            0.043669   \n",
       "27         0.821420          0.672389            0.043669   \n",
       "28         0.101746          0.125957            0.043669   \n",
       "29        -0.258092         -0.267359            0.043669   \n",
       "...             ...               ...                 ...   \n",
       "6061      -0.211198         -0.233609            0.043669   \n",
       "6062      -0.258092         -0.219329            0.043669   \n",
       "6063      16.152226         14.028356            0.043669   \n",
       "6064      -0.211198         -0.233595            0.043669   \n",
       "6065       0.461583          0.281155            0.043669   \n",
       "6066      -0.258092         -0.210681            0.043669   \n",
       "6067      -0.211198         -0.232575            0.043669   \n",
       "6068      -0.258092         -0.270507            0.043669   \n",
       "6069      -0.258092         -0.261017            0.043669   \n",
       "6070      -0.211198         -0.118617            0.043669   \n",
       "6071      -0.258092         -0.200191            0.043669   \n",
       "6072      -0.211198         -0.192348            0.043669   \n",
       "6073      -0.211198         -0.231899            0.043669   \n",
       "6074      -0.211198         -0.231784            0.043669   \n",
       "6075       3.061487          2.098654            0.043669   \n",
       "6076      -0.211198         -0.316979            0.043669   \n",
       "6077      -0.211198         -0.191415            0.043669   \n",
       "6078       0.101746          0.094460            0.043669   \n",
       "6079      -0.258092         -0.275014            0.043669   \n",
       "6080      -0.258092         -0.286252            0.043669   \n",
       "6081      -0.258092         -0.317303            0.043669   \n",
       "6082      -0.211198         -0.256057            0.043669   \n",
       "6083      -0.211198         -0.226193            0.043669   \n",
       "6084      -0.211198         -0.190923            0.043669   \n",
       "6085      -0.211198         -0.248470            0.043669   \n",
       "6086      -0.258092         -0.341541            0.043669   \n",
       "6087      -0.211198         -0.182190            0.043669   \n",
       "6088      -0.211198         -0.228199            0.043669   \n",
       "6089      -0.258092         -0.261753            0.043669   \n",
       "6090      -0.211198         -0.241210            0.043669   \n",
       "\n",
       "      Root Mean Squared Error  \n",
       "0                    0.208971  \n",
       "1                    0.208971  \n",
       "2                    0.208971  \n",
       "3                    0.208971  \n",
       "4                    0.208971  \n",
       "5                    0.208971  \n",
       "6                    0.208971  \n",
       "7                    0.208971  \n",
       "8                    0.208971  \n",
       "9                    0.208971  \n",
       "10                   0.208971  \n",
       "11                   0.208971  \n",
       "12                   0.208971  \n",
       "13                   0.208971  \n",
       "14                   0.208971  \n",
       "15                   0.208971  \n",
       "16                   0.208971  \n",
       "17                   0.208971  \n",
       "18                   0.208971  \n",
       "19                   0.208971  \n",
       "20                   0.208971  \n",
       "21                   0.208971  \n",
       "22                   0.208971  \n",
       "23                   0.208971  \n",
       "24                   0.208971  \n",
       "25                   0.208971  \n",
       "26                   0.208971  \n",
       "27                   0.208971  \n",
       "28                   0.208971  \n",
       "29                   0.208971  \n",
       "...                       ...  \n",
       "6061                 0.208971  \n",
       "6062                 0.208971  \n",
       "6063                 0.208971  \n",
       "6064                 0.208971  \n",
       "6065                 0.208971  \n",
       "6066                 0.208971  \n",
       "6067                 0.208971  \n",
       "6068                 0.208971  \n",
       "6069                 0.208971  \n",
       "6070                 0.208971  \n",
       "6071                 0.208971  \n",
       "6072                 0.208971  \n",
       "6073                 0.208971  \n",
       "6074                 0.208971  \n",
       "6075                 0.208971  \n",
       "6076                 0.208971  \n",
       "6077                 0.208971  \n",
       "6078                 0.208971  \n",
       "6079                 0.208971  \n",
       "6080                 0.208971  \n",
       "6081                 0.208971  \n",
       "6082                 0.208971  \n",
       "6083                 0.208971  \n",
       "6084                 0.208971  \n",
       "6085                 0.208971  \n",
       "6086                 0.208971  \n",
       "6087                 0.208971  \n",
       "6088                 0.208971  \n",
       "6089                 0.208971  \n",
       "6090                 0.208971  \n",
       "\n",
       "[6091 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Predicting the values for Helpful Votes on the test data \"\"\"\n",
    "y_pred_2 = regressor_2.predict(X_test)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against predicted values \"\"\"\n",
    "y_pred_2 = y_pred_2.reshape(6091,)\n",
    "temp = {'Actual Values': y_test,'Predicted Values': y_pred_2}\n",
    "y_compare_2 = pd.DataFrame(temp)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_2['Mean Squared Error'] = (np.diff(y_compare_2.values) ** 2)\n",
    "y_compare_2['Mean Squared Error'] = np.mean(y_compare_2['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_2['Root Mean Squared Error'] = y_compare_2['Mean Squared Error']**0.5\n",
    "y_compare_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values(Training)</th>\n",
       "      <th>Predicted Values(Training)</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.221544</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.237985</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.302174</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.501985</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.261026</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.300431</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.287276</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.313749</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.297815</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.287848</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.287539</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.233725</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.138288</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.227183</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.285923</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.251786</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.302967</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.254002</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.319858</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.253226</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.107943</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.248804</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.262082</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.290298</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.257809</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.236391</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.219934</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.243080</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.367488</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.233623</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24332</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.311096</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24333</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.262505</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24334</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.251278</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24335</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.198682</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24336</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.242211</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24337</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.242864</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24338</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.136248</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24339</th>\n",
       "      <td>0.606973</td>\n",
       "      <td>0.482672</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24340</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.276543</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24341</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.301287</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24342</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.188501</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24343</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.185566</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24344</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.349214</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24345</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.261587</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24346</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.282799</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24347</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.274744</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24348</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.231974</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24349</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.292343</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24350</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.297491</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24351</th>\n",
       "      <td>3.061487</td>\n",
       "      <td>3.271531</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24352</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.224687</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24353</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.230181</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24354</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.347085</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24355</th>\n",
       "      <td>-0.196210</td>\n",
       "      <td>-0.150506</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24356</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.209407</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24357</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.307616</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24358</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.254356</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24359</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.280688</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24360</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.303015</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24361</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.300391</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.198229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24362 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Values(Training)  Predicted Values(Training)  \\\n",
       "0                    -0.211198                   -0.221544   \n",
       "1                    -0.211198                   -0.237985   \n",
       "2                    -0.258092                   -0.302174   \n",
       "3                    -0.211198                   -0.501985   \n",
       "4                    -0.258092                   -0.261026   \n",
       "5                    -0.258092                   -0.300431   \n",
       "6                    -0.211198                   -0.287276   \n",
       "7                    -0.258092                   -0.313749   \n",
       "8                    -0.258092                   -0.297815   \n",
       "9                    -0.258092                   -0.287848   \n",
       "10                   -0.258092                   -0.287539   \n",
       "11                   -0.211198                   -0.233725   \n",
       "12                    0.101746                    0.138288   \n",
       "13                   -0.211198                   -0.227183   \n",
       "14                   -0.258092                   -0.285923   \n",
       "15                   -0.211198                   -0.251786   \n",
       "16                   -0.258092                   -0.302967   \n",
       "17                   -0.211198                   -0.254002   \n",
       "18                   -0.258092                   -0.319858   \n",
       "19                   -0.211198                   -0.253226   \n",
       "20                   -0.211198                   -0.107943   \n",
       "21                   -0.211198                   -0.248804   \n",
       "22                   -0.211198                   -0.262082   \n",
       "23                   -0.258092                   -0.290298   \n",
       "24                   -0.258092                   -0.257809   \n",
       "25                   -0.258092                   -0.236391   \n",
       "26                   -0.211198                   -0.219934   \n",
       "27                   -0.211198                   -0.243080   \n",
       "28                   -0.211198                   -0.367488   \n",
       "29                   -0.211198                   -0.233623   \n",
       "...                        ...                         ...   \n",
       "24332                -0.258092                   -0.311096   \n",
       "24333                -0.258092                   -0.262505   \n",
       "24334                -0.258092                   -0.251278   \n",
       "24335                -0.211198                   -0.198682   \n",
       "24336                -0.211198                   -0.242211   \n",
       "24337                -0.211198                   -0.242864   \n",
       "24338                 0.101746                    0.136248   \n",
       "24339                 0.606973                    0.482672   \n",
       "24340                -0.211198                   -0.276543   \n",
       "24341                -0.258092                   -0.301287   \n",
       "24342                -0.211198                   -0.188501   \n",
       "24343                -0.211198                   -0.185566   \n",
       "24344                -0.258092                   -0.349214   \n",
       "24345                -0.211198                   -0.261587   \n",
       "24346                -0.258092                   -0.282799   \n",
       "24347                -0.211198                   -0.274744   \n",
       "24348                -0.211198                   -0.231974   \n",
       "24349                -0.258092                   -0.292343   \n",
       "24350                -0.258092                   -0.297491   \n",
       "24351                 3.061487                    3.271531   \n",
       "24352                -0.211198                   -0.224687   \n",
       "24353                -0.211198                   -0.230181   \n",
       "24354                -0.258092                   -0.347085   \n",
       "24355                -0.196210                   -0.150506   \n",
       "24356                -0.211198                   -0.209407   \n",
       "24357                -0.258092                   -0.307616   \n",
       "24358                -0.211198                   -0.254356   \n",
       "24359                -0.258092                   -0.280688   \n",
       "24360                -0.258092                   -0.303015   \n",
       "24361                -0.258092                   -0.300391   \n",
       "\n",
       "       Mean Squared Error  Root Mean Squared Error  \n",
       "0                0.036747                 0.198229  \n",
       "1                0.036747                 0.198229  \n",
       "2                0.036747                 0.198229  \n",
       "3                0.036747                 0.198229  \n",
       "4                0.036747                 0.198229  \n",
       "5                0.036747                 0.198229  \n",
       "6                0.036747                 0.198229  \n",
       "7                0.036747                 0.198229  \n",
       "8                0.036747                 0.198229  \n",
       "9                0.036747                 0.198229  \n",
       "10               0.036747                 0.198229  \n",
       "11               0.036747                 0.198229  \n",
       "12               0.036747                 0.198229  \n",
       "13               0.036747                 0.198229  \n",
       "14               0.036747                 0.198229  \n",
       "15               0.036747                 0.198229  \n",
       "16               0.036747                 0.198229  \n",
       "17               0.036747                 0.198229  \n",
       "18               0.036747                 0.198229  \n",
       "19               0.036747                 0.198229  \n",
       "20               0.036747                 0.198229  \n",
       "21               0.036747                 0.198229  \n",
       "22               0.036747                 0.198229  \n",
       "23               0.036747                 0.198229  \n",
       "24               0.036747                 0.198229  \n",
       "25               0.036747                 0.198229  \n",
       "26               0.036747                 0.198229  \n",
       "27               0.036747                 0.198229  \n",
       "28               0.036747                 0.198229  \n",
       "29               0.036747                 0.198229  \n",
       "...                   ...                      ...  \n",
       "24332            0.036747                 0.198229  \n",
       "24333            0.036747                 0.198229  \n",
       "24334            0.036747                 0.198229  \n",
       "24335            0.036747                 0.198229  \n",
       "24336            0.036747                 0.198229  \n",
       "24337            0.036747                 0.198229  \n",
       "24338            0.036747                 0.198229  \n",
       "24339            0.036747                 0.198229  \n",
       "24340            0.036747                 0.198229  \n",
       "24341            0.036747                 0.198229  \n",
       "24342            0.036747                 0.198229  \n",
       "24343            0.036747                 0.198229  \n",
       "24344            0.036747                 0.198229  \n",
       "24345            0.036747                 0.198229  \n",
       "24346            0.036747                 0.198229  \n",
       "24347            0.036747                 0.198229  \n",
       "24348            0.036747                 0.198229  \n",
       "24349            0.036747                 0.198229  \n",
       "24350            0.036747                 0.198229  \n",
       "24351            0.036747                 0.198229  \n",
       "24352            0.036747                 0.198229  \n",
       "24353            0.036747                 0.198229  \n",
       "24354            0.036747                 0.198229  \n",
       "24355            0.036747                 0.198229  \n",
       "24356            0.036747                 0.198229  \n",
       "24357            0.036747                 0.198229  \n",
       "24358            0.036747                 0.198229  \n",
       "24359            0.036747                 0.198229  \n",
       "24360            0.036747                 0.198229  \n",
       "24361            0.036747                 0.198229  \n",
       "\n",
       "[24362 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Now we will also predict the y values on the training set just to calculate MSE and RMSE \"\"\"\n",
    "\n",
    "y_pred_train_2 = regressor_2.predict(X_train)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against the predicted values for the training set \"\"\"\n",
    "y_pred_train_2 = y_pred_train_2.reshape(24362,)\n",
    "temp_train = {'Actual Values(Training)':y_train, 'Predicted Values(Training)': y_pred_train_2 }\n",
    "y_compare_train_2 = pd.DataFrame(temp_train)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN on TRAINING SET\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_train_2['Mean Squared Error'] = (np.diff(y_compare_train_2.values) ** 2)\n",
    "y_compare_train_2['Mean Squared Error'] = np.mean(y_compare_train_2['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_train_2['Root Mean Squared Error'] = y_compare_train_1['Mean Squared Error']**0.5\n",
    "y_compare_train_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24362/24362 [==============================] - 4s 183us/step - loss: 0.1401\n",
      "Epoch 2/100\n",
      "24362/24362 [==============================] - 4s 170us/step - loss: 0.1189\n",
      "Epoch 3/100\n",
      "24362/24362 [==============================] - 4s 171us/step - loss: 0.0847\n",
      "Epoch 4/100\n",
      "24362/24362 [==============================] - 4s 172us/step - loss: 0.0917\n",
      "Epoch 5/100\n",
      "24362/24362 [==============================] - 4s 174us/step - loss: 0.0698\n",
      "Epoch 6/100\n",
      "24362/24362 [==============================] - 4s 172us/step - loss: 0.0558\n",
      "Epoch 7/100\n",
      "24362/24362 [==============================] - 4s 173us/step - loss: 0.0702\n",
      "Epoch 8/100\n",
      "24362/24362 [==============================] - 4s 171us/step - loss: 0.0975\n",
      "Epoch 9/100\n",
      "24362/24362 [==============================] - 4s 174us/step - loss: 0.0585\n",
      "Epoch 10/100\n",
      "24362/24362 [==============================] - 4s 171us/step - loss: 0.0892\n",
      "Epoch 11/100\n",
      "24362/24362 [==============================] - 4s 172us/step - loss: 0.0747\n",
      "Epoch 12/100\n",
      "24362/24362 [==============================] - 4s 172us/step - loss: 0.0680\n",
      "Epoch 13/100\n",
      "24362/24362 [==============================] - 4s 174us/step - loss: 0.0710\n",
      "Epoch 14/100\n",
      "24362/24362 [==============================] - 4s 171us/step - loss: 0.0417\n",
      "Epoch 15/100\n",
      "24362/24362 [==============================] - 4s 169us/step - loss: 0.0527\n",
      "Epoch 16/100\n",
      "24362/24362 [==============================] - 4s 170us/step - loss: 0.0552\n",
      "Epoch 17/100\n",
      "24362/24362 [==============================] - 4s 172us/step - loss: 0.0703\n",
      "Epoch 18/100\n",
      "24362/24362 [==============================] - 4s 173us/step - loss: 0.1071\n",
      "Epoch 19/100\n",
      "24362/24362 [==============================] - 4s 173us/step - loss: 0.0592\n",
      "Epoch 20/100\n",
      "24362/24362 [==============================] - 4s 173us/step - loss: 0.0538\n",
      "Epoch 21/100\n",
      "24362/24362 [==============================] - 4s 171us/step - loss: 0.0457\n",
      "Epoch 22/100\n",
      "24362/24362 [==============================] - 4s 171us/step - loss: 0.0713\n",
      "Epoch 23/100\n",
      "24362/24362 [==============================] - 4s 171us/step - loss: 0.0406\n",
      "Epoch 24/100\n",
      "24362/24362 [==============================] - 4s 170us/step - loss: 0.0405\n",
      "Epoch 25/100\n",
      "24362/24362 [==============================] - 4s 172us/step - loss: 0.0414\n",
      "Epoch 26/100\n",
      "24362/24362 [==============================] - 4s 172us/step - loss: 0.0694\n",
      "Epoch 27/100\n",
      "24362/24362 [==============================] - 4s 171us/step - loss: 0.0385\n",
      "Epoch 28/100\n",
      "24362/24362 [==============================] - 4s 171us/step - loss: 0.0547\n",
      "Epoch 29/100\n",
      "24362/24362 [==============================] - 4s 172us/step - loss: 0.0323\n",
      "Epoch 30/100\n",
      "24362/24362 [==============================] - 4s 177us/step - loss: 0.0266\n",
      "Epoch 31/100\n",
      "24362/24362 [==============================] - 4s 179us/step - loss: 0.0284\n",
      "Epoch 32/100\n",
      "24362/24362 [==============================] - 4s 180us/step - loss: 0.0468\n",
      "Epoch 33/100\n",
      "24362/24362 [==============================] - 4s 175us/step - loss: 0.0375\n",
      "Epoch 34/100\n",
      "24362/24362 [==============================] - 4s 173us/step - loss: 0.0362\n",
      "Epoch 35/100\n",
      "24362/24362 [==============================] - 4s 174us/step - loss: 0.0365\n",
      "Epoch 36/100\n",
      "24362/24362 [==============================] - 4s 170us/step - loss: 0.0344\n",
      "Epoch 37/100\n",
      "24362/24362 [==============================] - 4s 175us/step - loss: 0.0394\n",
      "Epoch 38/100\n",
      "24362/24362 [==============================] - 4s 180us/step - loss: 0.0360\n",
      "Epoch 39/100\n",
      "24362/24362 [==============================] - 4s 177us/step - loss: 0.0552\n",
      "Epoch 40/100\n",
      "24362/24362 [==============================] - 4s 174us/step - loss: 0.0382\n",
      "Epoch 41/100\n",
      "24362/24362 [==============================] - 4s 173us/step - loss: 0.0265\n",
      "Epoch 42/100\n",
      "24362/24362 [==============================] - 4s 172us/step - loss: 0.0462\n",
      "Epoch 43/100\n",
      "24362/24362 [==============================] - 4s 172us/step - loss: 0.0242\n",
      "Epoch 44/100\n",
      "24362/24362 [==============================] - 4s 174us/step - loss: 0.0284\n",
      "Epoch 45/100\n",
      "24362/24362 [==============================] - 4s 173us/step - loss: 0.0163\n",
      "Epoch 46/100\n",
      "24362/24362 [==============================] - 4s 176us/step - loss: 0.0269\n",
      "Epoch 47/100\n",
      "24362/24362 [==============================] - 4s 174us/step - loss: 0.0317\n",
      "Epoch 48/100\n",
      "24362/24362 [==============================] - 4s 176us/step - loss: 0.0333\n",
      "Epoch 49/100\n",
      "24362/24362 [==============================] - 4s 172us/step - loss: 0.0388\n",
      "Epoch 50/100\n",
      "24362/24362 [==============================] - 4s 171us/step - loss: 0.0916\n",
      "Epoch 51/100\n",
      "24362/24362 [==============================] - 4s 173us/step - loss: 0.0171\n",
      "Epoch 52/100\n",
      "24362/24362 [==============================] - 4s 178us/step - loss: 0.0287\n",
      "Epoch 53/100\n",
      "24362/24362 [==============================] - 4s 174us/step - loss: 0.0345\n",
      "Epoch 54/100\n",
      "24362/24362 [==============================] - 4s 172us/step - loss: 0.0212\n",
      "Epoch 55/100\n",
      "24362/24362 [==============================] - 4s 171us/step - loss: 0.0902\n",
      "Epoch 56/100\n",
      "24362/24362 [==============================] - 4s 170us/step - loss: 0.0183\n",
      "Epoch 57/100\n",
      "24362/24362 [==============================] - 4s 168us/step - loss: 0.0248\n",
      "Epoch 58/100\n",
      "24362/24362 [==============================] - 4s 176us/step - loss: 0.0313\n",
      "Epoch 59/100\n",
      "24362/24362 [==============================] - 4s 171us/step - loss: 0.0406\n",
      "Epoch 60/100\n",
      "24362/24362 [==============================] - 4s 173us/step - loss: 0.0096\n",
      "Epoch 61/100\n",
      "24362/24362 [==============================] - 4s 170us/step - loss: 0.0372\n",
      "Epoch 62/100\n",
      "24362/24362 [==============================] - 4s 172us/step - loss: 0.0127\n",
      "Epoch 63/100\n",
      "24362/24362 [==============================] - 4s 183us/step - loss: 0.0417\n",
      "Epoch 64/100\n",
      "24362/24362 [==============================] - 4s 170us/step - loss: 0.0210\n",
      "Epoch 65/100\n",
      "24362/24362 [==============================] - 4s 176us/step - loss: 0.0694\n",
      "Epoch 66/100\n",
      "24362/24362 [==============================] - 4s 170us/step - loss: 0.0176\n",
      "Epoch 67/100\n",
      "24362/24362 [==============================] - 4s 169us/step - loss: 0.0112\n",
      "Epoch 68/100\n",
      "24362/24362 [==============================] - 4s 168us/step - loss: 0.0322\n",
      "Epoch 69/100\n",
      "24362/24362 [==============================] - 4s 172us/step - loss: 0.0189\n",
      "Epoch 70/100\n",
      "24362/24362 [==============================] - 4s 171us/step - loss: 0.0494\n",
      "Epoch 71/100\n",
      "24362/24362 [==============================] - 4s 173us/step - loss: 0.0211\n",
      "Epoch 72/100\n",
      "24362/24362 [==============================] - 4s 172us/step - loss: 0.0209\n",
      "Epoch 73/100\n",
      "24362/24362 [==============================] - 4s 179us/step - loss: 0.0378\n",
      "Epoch 74/100\n",
      "24362/24362 [==============================] - 4s 175us/step - loss: 0.0231\n",
      "Epoch 75/100\n",
      "24362/24362 [==============================] - 4s 173us/step - loss: 0.0116\n",
      "Epoch 76/100\n",
      "24362/24362 [==============================] - 4s 179us/step - loss: 0.0202\n",
      "Epoch 77/100\n",
      "24362/24362 [==============================] - 4s 175us/step - loss: 0.0258\n",
      "Epoch 78/100\n",
      "24362/24362 [==============================] - 4s 170us/step - loss: 0.0273\n",
      "Epoch 79/100\n",
      "24362/24362 [==============================] - 4s 169us/step - loss: 0.0233\n",
      "Epoch 80/100\n",
      "24362/24362 [==============================] - 4s 169us/step - loss: 0.0140\n",
      "Epoch 81/100\n",
      "24362/24362 [==============================] - 4s 172us/step - loss: 0.0205\n",
      "Epoch 82/100\n",
      "24362/24362 [==============================] - 4s 171us/step - loss: 0.0224\n",
      "Epoch 83/100\n",
      "24362/24362 [==============================] - 4s 171us/step - loss: 0.0178\n",
      "Epoch 84/100\n",
      "24362/24362 [==============================] - 4s 172us/step - loss: 0.0112\n",
      "Epoch 85/100\n",
      "24362/24362 [==============================] - 4s 172us/step - loss: 0.0542\n",
      "Epoch 86/100\n",
      "24362/24362 [==============================] - 5s 201us/step - loss: 0.0124\n",
      "Epoch 87/100\n",
      "24362/24362 [==============================] - 5s 187us/step - loss: 0.0123\n",
      "Epoch 88/100\n",
      "24362/24362 [==============================] - 4s 174us/step - loss: 0.0221\n",
      "Epoch 89/100\n",
      "24362/24362 [==============================] - 5s 187us/step - loss: 0.0218\n",
      "Epoch 90/100\n",
      "24362/24362 [==============================] - 4s 171us/step - loss: 0.0183\n",
      "Epoch 91/100\n",
      "24362/24362 [==============================] - 4s 173us/step - loss: 0.0083\n",
      "Epoch 92/100\n",
      "24362/24362 [==============================] - 4s 171us/step - loss: 0.0109\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24362/24362 [==============================] - 4s 184us/step - loss: 0.0236\n",
      "Epoch 94/100\n",
      "24362/24362 [==============================] - 6s 260us/step - loss: 0.0140\n",
      "Epoch 95/100\n",
      "24362/24362 [==============================] - 5s 215us/step - loss: 0.0160\n",
      "Epoch 96/100\n",
      "24362/24362 [==============================] - 5s 222us/step - loss: 0.0077\n",
      "Epoch 97/100\n",
      "24362/24362 [==============================] - 4s 174us/step - loss: 0.0267\n",
      "Epoch 98/100\n",
      "24362/24362 [==============================] - 5s 200us/step - loss: 0.0158\n",
      "Epoch 99/100\n",
      "24362/24362 [==============================] - 6s 261us/step - loss: 0.0106\n",
      "Epoch 100/100\n",
      "24362/24362 [==============================] - 5s 220us/step - loss: 0.0233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x130b4a9b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Building a 3 layer ANN with 2 layers of 50 nodes \"\"\"\n",
    "\n",
    "regressor_3 = Sequential()\n",
    "regressor_3.add(Dense(50, kernel_initializer = 'normal',activation = 'relu',input_dim = 7))\n",
    "regressor_3.add(Dense(50, kernel_initializer = 'normal', activation = 'relu'))\n",
    "regressor_3.add(Dense(1, kernel_initializer = 'normal'))\n",
    "\n",
    "\"\"\" Compiling the regressor \"\"\"\n",
    "regressor_3.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "\"\"\" Fitting the Artifilial Neural Network to our training data \"\"\"\n",
    "regressor_3.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.081904</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.205656</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.243534</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.196210</td>\n",
       "      <td>-0.178537</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.219856</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.425145</td>\n",
       "      <td>1.349278</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.213184</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.235881</td>\n",
       "      <td>-0.209586</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.232883</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.242955</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.208059</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.879658</td>\n",
       "      <td>2.127845</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.219952</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.194443</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.247386</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.210666</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.210557</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.243316</td>\n",
       "      <td>1.900721</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.200325</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.205219</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.253790</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.243316</td>\n",
       "      <td>2.045408</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.231189</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.215189</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.200611</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.208761</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.226274</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.821420</td>\n",
       "      <td>0.744240</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.075491</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.239025</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6061</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.199487</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.224735</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>16.152226</td>\n",
       "      <td>13.193227</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.221023</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>0.461583</td>\n",
       "      <td>0.391176</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.234373</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6067</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.199332</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6068</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.246242</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6069</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.228117</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6070</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.225231</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6071</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.227766</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6072</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.205505</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.218406</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.205129</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6075</th>\n",
       "      <td>3.061487</td>\n",
       "      <td>1.948639</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.225848</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.205515</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.072059</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6079</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.250899</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6080</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.242129</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6081</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.208923</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6082</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.210665</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6083</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.218698</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6084</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.194095</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6085</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.191311</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6086</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.231203</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.202978</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6088</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.214937</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6089</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.261026</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6090</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.201909</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.282514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6091 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual Values  Predicted Values  Mean Squared Error  \\\n",
       "0          0.101746          0.081904            0.079814   \n",
       "1         -0.211198         -0.205656            0.079814   \n",
       "2         -0.258092         -0.243534            0.079814   \n",
       "3         -0.196210         -0.178537            0.079814   \n",
       "4         -0.211198         -0.219856            0.079814   \n",
       "5          1.425145          1.349278            0.079814   \n",
       "6         -0.211198         -0.213184            0.079814   \n",
       "7         -0.235881         -0.209586            0.079814   \n",
       "8         -0.211198         -0.232883            0.079814   \n",
       "9         -0.258092         -0.242955            0.079814   \n",
       "10        -0.211198         -0.208059            0.079814   \n",
       "11         3.879658          2.127845            0.079814   \n",
       "12        -0.211198         -0.219952            0.079814   \n",
       "13        -0.211198         -0.194443            0.079814   \n",
       "14        -0.258092         -0.247386            0.079814   \n",
       "15        -0.211198         -0.210666            0.079814   \n",
       "16        -0.211198         -0.210557            0.079814   \n",
       "17         2.243316          1.900721            0.079814   \n",
       "18        -0.211198         -0.200325            0.079814   \n",
       "19        -0.211198         -0.205219            0.079814   \n",
       "20        -0.258092         -0.253790            0.079814   \n",
       "21         2.243316          2.045408            0.079814   \n",
       "22        -0.258092         -0.231189            0.079814   \n",
       "23        -0.211198         -0.215189            0.079814   \n",
       "24        -0.211198         -0.200611            0.079814   \n",
       "25        -0.211198         -0.208761            0.079814   \n",
       "26        -0.211198         -0.226274            0.079814   \n",
       "27         0.821420          0.744240            0.079814   \n",
       "28         0.101746          0.075491            0.079814   \n",
       "29        -0.258092         -0.239025            0.079814   \n",
       "...             ...               ...                 ...   \n",
       "6061      -0.211198         -0.199487            0.079814   \n",
       "6062      -0.258092         -0.224735            0.079814   \n",
       "6063      16.152226         13.193227            0.079814   \n",
       "6064      -0.211198         -0.221023            0.079814   \n",
       "6065       0.461583          0.391176            0.079814   \n",
       "6066      -0.258092         -0.234373            0.079814   \n",
       "6067      -0.211198         -0.199332            0.079814   \n",
       "6068      -0.258092         -0.246242            0.079814   \n",
       "6069      -0.258092         -0.228117            0.079814   \n",
       "6070      -0.211198         -0.225231            0.079814   \n",
       "6071      -0.258092         -0.227766            0.079814   \n",
       "6072      -0.211198         -0.205505            0.079814   \n",
       "6073      -0.211198         -0.218406            0.079814   \n",
       "6074      -0.211198         -0.205129            0.079814   \n",
       "6075       3.061487          1.948639            0.079814   \n",
       "6076      -0.211198         -0.225848            0.079814   \n",
       "6077      -0.211198         -0.205515            0.079814   \n",
       "6078       0.101746          0.072059            0.079814   \n",
       "6079      -0.258092         -0.250899            0.079814   \n",
       "6080      -0.258092         -0.242129            0.079814   \n",
       "6081      -0.258092         -0.208923            0.079814   \n",
       "6082      -0.211198         -0.210665            0.079814   \n",
       "6083      -0.211198         -0.218698            0.079814   \n",
       "6084      -0.211198         -0.194095            0.079814   \n",
       "6085      -0.211198         -0.191311            0.079814   \n",
       "6086      -0.258092         -0.231203            0.079814   \n",
       "6087      -0.211198         -0.202978            0.079814   \n",
       "6088      -0.211198         -0.214937            0.079814   \n",
       "6089      -0.258092         -0.261026            0.079814   \n",
       "6090      -0.211198         -0.201909            0.079814   \n",
       "\n",
       "      Root Mean Squared Error  \n",
       "0                    0.282514  \n",
       "1                    0.282514  \n",
       "2                    0.282514  \n",
       "3                    0.282514  \n",
       "4                    0.282514  \n",
       "5                    0.282514  \n",
       "6                    0.282514  \n",
       "7                    0.282514  \n",
       "8                    0.282514  \n",
       "9                    0.282514  \n",
       "10                   0.282514  \n",
       "11                   0.282514  \n",
       "12                   0.282514  \n",
       "13                   0.282514  \n",
       "14                   0.282514  \n",
       "15                   0.282514  \n",
       "16                   0.282514  \n",
       "17                   0.282514  \n",
       "18                   0.282514  \n",
       "19                   0.282514  \n",
       "20                   0.282514  \n",
       "21                   0.282514  \n",
       "22                   0.282514  \n",
       "23                   0.282514  \n",
       "24                   0.282514  \n",
       "25                   0.282514  \n",
       "26                   0.282514  \n",
       "27                   0.282514  \n",
       "28                   0.282514  \n",
       "29                   0.282514  \n",
       "...                       ...  \n",
       "6061                 0.282514  \n",
       "6062                 0.282514  \n",
       "6063                 0.282514  \n",
       "6064                 0.282514  \n",
       "6065                 0.282514  \n",
       "6066                 0.282514  \n",
       "6067                 0.282514  \n",
       "6068                 0.282514  \n",
       "6069                 0.282514  \n",
       "6070                 0.282514  \n",
       "6071                 0.282514  \n",
       "6072                 0.282514  \n",
       "6073                 0.282514  \n",
       "6074                 0.282514  \n",
       "6075                 0.282514  \n",
       "6076                 0.282514  \n",
       "6077                 0.282514  \n",
       "6078                 0.282514  \n",
       "6079                 0.282514  \n",
       "6080                 0.282514  \n",
       "6081                 0.282514  \n",
       "6082                 0.282514  \n",
       "6083                 0.282514  \n",
       "6084                 0.282514  \n",
       "6085                 0.282514  \n",
       "6086                 0.282514  \n",
       "6087                 0.282514  \n",
       "6088                 0.282514  \n",
       "6089                 0.282514  \n",
       "6090                 0.282514  \n",
       "\n",
       "[6091 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Predicting the values for Helpful Votes on the test data \"\"\"\n",
    "y_pred_3 = regressor_3.predict(X_test)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against predicted values \"\"\"\n",
    "y_pred_3 = y_pred_3.reshape(6091,)\n",
    "temp = {'Actual Values': y_test,'Predicted Values': y_pred_3}\n",
    "y_compare_3 = pd.DataFrame(temp)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_3['Mean Squared Error'] = (np.diff(y_compare_3.values) ** 2)\n",
    "y_compare_3['Mean Squared Error'] = np.mean(y_compare_3['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_3['Root Mean Squared Error'] = y_compare_3['Mean Squared Error']**0.5\n",
    "y_compare_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values(Training)</th>\n",
       "      <th>Predicted Values(Training)</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.215896</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.224239</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.240641</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.202208</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.235803</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.257148</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.235682</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.234265</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.247991</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.257589</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.265599</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.218754</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.111600</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.211462</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.257450</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.223785</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.225631</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.209364</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.236719</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.213961</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.201663</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.233280</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.220924</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.256879</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.265667</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.246377</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.217613</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.225719</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.181205</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.224148</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24332</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.251231</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24333</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.257458</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24334</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.246284</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24335</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.218977</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24336</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.227017</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24337</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.229127</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24338</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.105402</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24339</th>\n",
       "      <td>0.606973</td>\n",
       "      <td>0.547163</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24340</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.229588</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24341</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.260262</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24342</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.232277</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24343</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.227987</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24344</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.210253</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24345</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.205840</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24346</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.228742</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24347</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.216435</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24348</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.221894</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24349</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.265951</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24350</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.232564</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24351</th>\n",
       "      <td>3.061487</td>\n",
       "      <td>2.885953</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24352</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.224530</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24353</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.216459</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24354</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.238568</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24355</th>\n",
       "      <td>-0.196210</td>\n",
       "      <td>-0.213305</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24356</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.199002</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24357</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.246007</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24358</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.220071</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24359</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.244936</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24360</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.252943</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24361</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.259072</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.201736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24362 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Values(Training)  Predicted Values(Training)  \\\n",
       "0                    -0.211198                   -0.215896   \n",
       "1                    -0.211198                   -0.224239   \n",
       "2                    -0.258092                   -0.240641   \n",
       "3                    -0.211198                   -0.202208   \n",
       "4                    -0.258092                   -0.235803   \n",
       "5                    -0.258092                   -0.257148   \n",
       "6                    -0.211198                   -0.235682   \n",
       "7                    -0.258092                   -0.234265   \n",
       "8                    -0.258092                   -0.247991   \n",
       "9                    -0.258092                   -0.257589   \n",
       "10                   -0.258092                   -0.265599   \n",
       "11                   -0.211198                   -0.218754   \n",
       "12                    0.101746                    0.111600   \n",
       "13                   -0.211198                   -0.211462   \n",
       "14                   -0.258092                   -0.257450   \n",
       "15                   -0.211198                   -0.223785   \n",
       "16                   -0.258092                   -0.225631   \n",
       "17                   -0.211198                   -0.209364   \n",
       "18                   -0.258092                   -0.236719   \n",
       "19                   -0.211198                   -0.213961   \n",
       "20                   -0.211198                   -0.201663   \n",
       "21                   -0.211198                   -0.233280   \n",
       "22                   -0.211198                   -0.220924   \n",
       "23                   -0.258092                   -0.256879   \n",
       "24                   -0.258092                   -0.265667   \n",
       "25                   -0.258092                   -0.246377   \n",
       "26                   -0.211198                   -0.217613   \n",
       "27                   -0.211198                   -0.225719   \n",
       "28                   -0.211198                   -0.181205   \n",
       "29                   -0.211198                   -0.224148   \n",
       "...                        ...                         ...   \n",
       "24332                -0.258092                   -0.251231   \n",
       "24333                -0.258092                   -0.257458   \n",
       "24334                -0.258092                   -0.246284   \n",
       "24335                -0.211198                   -0.218977   \n",
       "24336                -0.211198                   -0.227017   \n",
       "24337                -0.211198                   -0.229127   \n",
       "24338                 0.101746                    0.105402   \n",
       "24339                 0.606973                    0.547163   \n",
       "24340                -0.211198                   -0.229588   \n",
       "24341                -0.258092                   -0.260262   \n",
       "24342                -0.211198                   -0.232277   \n",
       "24343                -0.211198                   -0.227987   \n",
       "24344                -0.258092                   -0.210253   \n",
       "24345                -0.211198                   -0.205840   \n",
       "24346                -0.258092                   -0.228742   \n",
       "24347                -0.211198                   -0.216435   \n",
       "24348                -0.211198                   -0.221894   \n",
       "24349                -0.258092                   -0.265951   \n",
       "24350                -0.258092                   -0.232564   \n",
       "24351                 3.061487                    2.885953   \n",
       "24352                -0.211198                   -0.224530   \n",
       "24353                -0.211198                   -0.216459   \n",
       "24354                -0.258092                   -0.238568   \n",
       "24355                -0.196210                   -0.213305   \n",
       "24356                -0.211198                   -0.199002   \n",
       "24357                -0.258092                   -0.246007   \n",
       "24358                -0.211198                   -0.220071   \n",
       "24359                -0.258092                   -0.244936   \n",
       "24360                -0.258092                   -0.252943   \n",
       "24361                -0.258092                   -0.259072   \n",
       "\n",
       "       Mean Squared Error  Root Mean Squared Error  \n",
       "0                0.040697                 0.201736  \n",
       "1                0.040697                 0.201736  \n",
       "2                0.040697                 0.201736  \n",
       "3                0.040697                 0.201736  \n",
       "4                0.040697                 0.201736  \n",
       "5                0.040697                 0.201736  \n",
       "6                0.040697                 0.201736  \n",
       "7                0.040697                 0.201736  \n",
       "8                0.040697                 0.201736  \n",
       "9                0.040697                 0.201736  \n",
       "10               0.040697                 0.201736  \n",
       "11               0.040697                 0.201736  \n",
       "12               0.040697                 0.201736  \n",
       "13               0.040697                 0.201736  \n",
       "14               0.040697                 0.201736  \n",
       "15               0.040697                 0.201736  \n",
       "16               0.040697                 0.201736  \n",
       "17               0.040697                 0.201736  \n",
       "18               0.040697                 0.201736  \n",
       "19               0.040697                 0.201736  \n",
       "20               0.040697                 0.201736  \n",
       "21               0.040697                 0.201736  \n",
       "22               0.040697                 0.201736  \n",
       "23               0.040697                 0.201736  \n",
       "24               0.040697                 0.201736  \n",
       "25               0.040697                 0.201736  \n",
       "26               0.040697                 0.201736  \n",
       "27               0.040697                 0.201736  \n",
       "28               0.040697                 0.201736  \n",
       "29               0.040697                 0.201736  \n",
       "...                   ...                      ...  \n",
       "24332            0.040697                 0.201736  \n",
       "24333            0.040697                 0.201736  \n",
       "24334            0.040697                 0.201736  \n",
       "24335            0.040697                 0.201736  \n",
       "24336            0.040697                 0.201736  \n",
       "24337            0.040697                 0.201736  \n",
       "24338            0.040697                 0.201736  \n",
       "24339            0.040697                 0.201736  \n",
       "24340            0.040697                 0.201736  \n",
       "24341            0.040697                 0.201736  \n",
       "24342            0.040697                 0.201736  \n",
       "24343            0.040697                 0.201736  \n",
       "24344            0.040697                 0.201736  \n",
       "24345            0.040697                 0.201736  \n",
       "24346            0.040697                 0.201736  \n",
       "24347            0.040697                 0.201736  \n",
       "24348            0.040697                 0.201736  \n",
       "24349            0.040697                 0.201736  \n",
       "24350            0.040697                 0.201736  \n",
       "24351            0.040697                 0.201736  \n",
       "24352            0.040697                 0.201736  \n",
       "24353            0.040697                 0.201736  \n",
       "24354            0.040697                 0.201736  \n",
       "24355            0.040697                 0.201736  \n",
       "24356            0.040697                 0.201736  \n",
       "24357            0.040697                 0.201736  \n",
       "24358            0.040697                 0.201736  \n",
       "24359            0.040697                 0.201736  \n",
       "24360            0.040697                 0.201736  \n",
       "24361            0.040697                 0.201736  \n",
       "\n",
       "[24362 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Now we will also predict the y values on the training set just to calculate MSE and RMSE \"\"\"\n",
    "\n",
    "y_pred_train_3 = regressor_3.predict(X_train)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against the predicted values for the training set \"\"\"\n",
    "y_pred_train_3 = y_pred_train_3.reshape(24362,)\n",
    "temp_train = {'Actual Values(Training)':y_train, 'Predicted Values(Training)': y_pred_train_3 }\n",
    "y_compare_train_3 = pd.DataFrame(temp_train)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN on TRAINING SET\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_train_3['Mean Squared Error'] = (np.diff(y_compare_train_3.values) ** 2)\n",
    "y_compare_train_3['Mean Squared Error'] = np.mean(y_compare_train_3['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_train_3['Root Mean Squared Error'] = y_compare_train_3['Mean Squared Error']**0.5\n",
    "y_compare_train_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24362/24362 [==============================] - 5s 187us/step - loss: 0.1264\n",
      "Epoch 2/100\n",
      "24362/24362 [==============================] - 4s 183us/step - loss: 0.0959\n",
      "Epoch 3/100\n",
      "24362/24362 [==============================] - 5s 192us/step - loss: 0.0951\n",
      "Epoch 4/100\n",
      "24362/24362 [==============================] - 4s 180us/step - loss: 0.0790\n",
      "Epoch 5/100\n",
      "24362/24362 [==============================] - 4s 179us/step - loss: 0.0739\n",
      "Epoch 6/100\n",
      "24362/24362 [==============================] - 4s 180us/step - loss: 0.0843\n",
      "Epoch 7/100\n",
      "24362/24362 [==============================] - 4s 175us/step - loss: 0.0519\n",
      "Epoch 8/100\n",
      "24362/24362 [==============================] - 4s 174us/step - loss: 0.0726\n",
      "Epoch 9/100\n",
      "24362/24362 [==============================] - 4s 174us/step - loss: 0.1344\n",
      "Epoch 10/100\n",
      "24362/24362 [==============================] - 4s 179us/step - loss: 0.0423\n",
      "Epoch 11/100\n",
      "24362/24362 [==============================] - 4s 174us/step - loss: 0.0611\n",
      "Epoch 12/100\n",
      "24362/24362 [==============================] - 4s 180us/step - loss: 0.0576\n",
      "Epoch 13/100\n",
      "24362/24362 [==============================] - 4s 183us/step - loss: 0.0497\n",
      "Epoch 14/100\n",
      "24362/24362 [==============================] - 4s 182us/step - loss: 0.0694\n",
      "Epoch 15/100\n",
      "24362/24362 [==============================] - 5s 189us/step - loss: 0.0616\n",
      "Epoch 16/100\n",
      "24362/24362 [==============================] - 5s 198us/step - loss: 0.0501\n",
      "Epoch 17/100\n",
      "24362/24362 [==============================] - 5s 195us/step - loss: 0.0581\n",
      "Epoch 18/100\n",
      "24362/24362 [==============================] - 4s 184us/step - loss: 0.0471\n",
      "Epoch 19/100\n",
      "24362/24362 [==============================] - 5s 191us/step - loss: 0.0601\n",
      "Epoch 20/100\n",
      "24362/24362 [==============================] - 5s 188us/step - loss: 0.0519\n",
      "Epoch 21/100\n",
      "24362/24362 [==============================] - 4s 184us/step - loss: 0.0646\n",
      "Epoch 22/100\n",
      "24362/24362 [==============================] - 5s 186us/step - loss: 0.0471\n",
      "Epoch 23/100\n",
      "24362/24362 [==============================] - 5s 187us/step - loss: 0.0398\n",
      "Epoch 24/100\n",
      "24362/24362 [==============================] - 5s 189us/step - loss: 0.0585\n",
      "Epoch 25/100\n",
      "24362/24362 [==============================] - 5s 190us/step - loss: 0.0407\n",
      "Epoch 26/100\n",
      "24362/24362 [==============================] - 5s 186us/step - loss: 0.0948\n",
      "Epoch 27/100\n",
      "24362/24362 [==============================] - 5s 186us/step - loss: 0.0582\n",
      "Epoch 28/100\n",
      "24362/24362 [==============================] - 4s 183us/step - loss: 0.0351\n",
      "Epoch 29/100\n",
      "24362/24362 [==============================] - 4s 180us/step - loss: 0.0553\n",
      "Epoch 30/100\n",
      "24362/24362 [==============================] - 5s 195us/step - loss: 0.0270\n",
      "Epoch 31/100\n",
      "24362/24362 [==============================] - 5s 189us/step - loss: 0.0869\n",
      "Epoch 32/100\n",
      "24362/24362 [==============================] - 4s 184us/step - loss: 0.0583\n",
      "Epoch 33/100\n",
      "24362/24362 [==============================] - 5s 187us/step - loss: 0.0444\n",
      "Epoch 34/100\n",
      "24362/24362 [==============================] - 5s 186us/step - loss: 0.0417\n",
      "Epoch 35/100\n",
      "24362/24362 [==============================] - 5s 187us/step - loss: 0.0562\n",
      "Epoch 36/100\n",
      "24362/24362 [==============================] - 5s 185us/step - loss: 0.0480\n",
      "Epoch 37/100\n",
      "24362/24362 [==============================] - 4s 180us/step - loss: 0.0438\n",
      "Epoch 38/100\n",
      "24362/24362 [==============================] - 5s 188us/step - loss: 0.0467\n",
      "Epoch 39/100\n",
      "24362/24362 [==============================] - 4s 184us/step - loss: 0.0497\n",
      "Epoch 40/100\n",
      "24362/24362 [==============================] - 5s 193us/step - loss: 0.0439\n",
      "Epoch 41/100\n",
      "24362/24362 [==============================] - 5s 188us/step - loss: 0.0402\n",
      "Epoch 42/100\n",
      "24362/24362 [==============================] - 5s 189us/step - loss: 0.0458\n",
      "Epoch 43/100\n",
      "24362/24362 [==============================] - 5s 190us/step - loss: 0.0452\n",
      "Epoch 44/100\n",
      "24362/24362 [==============================] - 5s 190us/step - loss: 0.0671\n",
      "Epoch 45/100\n",
      "24362/24362 [==============================] - 5s 194us/step - loss: 0.0354\n",
      "Epoch 46/100\n",
      "24362/24362 [==============================] - 5s 187us/step - loss: 0.0419\n",
      "Epoch 47/100\n",
      "24362/24362 [==============================] - 5s 189us/step - loss: 0.0360\n",
      "Epoch 48/100\n",
      "24362/24362 [==============================] - 5s 186us/step - loss: 0.0401\n",
      "Epoch 49/100\n",
      "24362/24362 [==============================] - 5s 185us/step - loss: 0.0530\n",
      "Epoch 50/100\n",
      "24362/24362 [==============================] - 4s 181us/step - loss: 0.0327\n",
      "Epoch 51/100\n",
      "24362/24362 [==============================] - 4s 181us/step - loss: 0.0352\n",
      "Epoch 52/100\n",
      "24362/24362 [==============================] - 4s 181us/step - loss: 0.0378\n",
      "Epoch 53/100\n",
      "24362/24362 [==============================] - 4s 177us/step - loss: 0.0519\n",
      "Epoch 54/100\n",
      "24362/24362 [==============================] - 4s 182us/step - loss: 0.0369\n",
      "Epoch 55/100\n",
      "24362/24362 [==============================] - 4s 183us/step - loss: 0.0395\n",
      "Epoch 56/100\n",
      "24362/24362 [==============================] - 4s 178us/step - loss: 0.0380\n",
      "Epoch 57/100\n",
      "24362/24362 [==============================] - 4s 180us/step - loss: 0.0355\n",
      "Epoch 58/100\n",
      "24362/24362 [==============================] - 4s 178us/step - loss: 0.0437\n",
      "Epoch 59/100\n",
      "24362/24362 [==============================] - 4s 181us/step - loss: 0.0323\n",
      "Epoch 60/100\n",
      "24362/24362 [==============================] - 5s 190us/step - loss: 0.0273\n",
      "Epoch 61/100\n",
      "24362/24362 [==============================] - 5s 195us/step - loss: 0.0472\n",
      "Epoch 62/100\n",
      "24362/24362 [==============================] - 4s 184us/step - loss: 0.0340\n",
      "Epoch 63/100\n",
      "24362/24362 [==============================] - 4s 179us/step - loss: 0.0326\n",
      "Epoch 64/100\n",
      "24362/24362 [==============================] - 4s 175us/step - loss: 0.0623\n",
      "Epoch 65/100\n",
      "24362/24362 [==============================] - 4s 183us/step - loss: 0.0278\n",
      "Epoch 66/100\n",
      "24362/24362 [==============================] - 4s 183us/step - loss: 0.0650\n",
      "Epoch 67/100\n",
      "24362/24362 [==============================] - 4s 181us/step - loss: 0.0243\n",
      "Epoch 68/100\n",
      "24362/24362 [==============================] - 4s 183us/step - loss: 0.0322\n",
      "Epoch 69/100\n",
      "24362/24362 [==============================] - 4s 177us/step - loss: 0.0198\n",
      "Epoch 70/100\n",
      "24362/24362 [==============================] - 4s 180us/step - loss: 0.0361\n",
      "Epoch 71/100\n",
      "24362/24362 [==============================] - 4s 183us/step - loss: 0.0296\n",
      "Epoch 72/100\n",
      "24362/24362 [==============================] - 4s 176us/step - loss: 0.0378\n",
      "Epoch 73/100\n",
      "24362/24362 [==============================] - 4s 176us/step - loss: 0.0308\n",
      "Epoch 74/100\n",
      "24362/24362 [==============================] - 4s 183us/step - loss: 0.0408\n",
      "Epoch 75/100\n",
      "24362/24362 [==============================] - 4s 178us/step - loss: 0.0280\n",
      "Epoch 76/100\n",
      "24362/24362 [==============================] - 4s 182us/step - loss: 0.0923\n",
      "Epoch 77/100\n",
      "24362/24362 [==============================] - 4s 178us/step - loss: 0.0168\n",
      "Epoch 78/100\n",
      "24362/24362 [==============================] - 4s 174us/step - loss: 0.0255\n",
      "Epoch 79/100\n",
      "24362/24362 [==============================] - 4s 175us/step - loss: 0.0180\n",
      "Epoch 80/100\n",
      "24362/24362 [==============================] - 4s 180us/step - loss: 0.0310\n",
      "Epoch 81/100\n",
      "24362/24362 [==============================] - 4s 179us/step - loss: 0.0629\n",
      "Epoch 82/100\n",
      "24362/24362 [==============================] - 4s 176us/step - loss: 0.0191\n",
      "Epoch 83/100\n",
      "24362/24362 [==============================] - 4s 182us/step - loss: 0.0177\n",
      "Epoch 84/100\n",
      "24362/24362 [==============================] - 4s 179us/step - loss: 0.0469\n",
      "Epoch 85/100\n",
      "24362/24362 [==============================] - 4s 181us/step - loss: 0.0302\n",
      "Epoch 86/100\n",
      "24362/24362 [==============================] - 4s 181us/step - loss: 0.0220\n",
      "Epoch 87/100\n",
      "24362/24362 [==============================] - 4s 178us/step - loss: 0.0363\n",
      "Epoch 88/100\n",
      "24362/24362 [==============================] - 5s 190us/step - loss: 0.0351\n",
      "Epoch 89/100\n",
      "24362/24362 [==============================] - 5s 200us/step - loss: 0.0764\n",
      "Epoch 90/100\n",
      "24362/24362 [==============================] - 4s 179us/step - loss: 0.0342\n",
      "Epoch 91/100\n",
      "24362/24362 [==============================] - 4s 179us/step - loss: 0.0211\n",
      "Epoch 92/100\n",
      "24362/24362 [==============================] - 4s 181us/step - loss: 0.0216\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24362/24362 [==============================] - 4s 176us/step - loss: 0.0258\n",
      "Epoch 94/100\n",
      "24362/24362 [==============================] - 4s 175us/step - loss: 0.0185\n",
      "Epoch 95/100\n",
      "24362/24362 [==============================] - 4s 178us/step - loss: 0.0288\n",
      "Epoch 96/100\n",
      "24362/24362 [==============================] - 4s 175us/step - loss: 0.0126\n",
      "Epoch 97/100\n",
      "24362/24362 [==============================] - 4s 179us/step - loss: 0.0382\n",
      "Epoch 98/100\n",
      "24362/24362 [==============================] - 4s 178us/step - loss: 0.0187\n",
      "Epoch 99/100\n",
      "24362/24362 [==============================] - 4s 176us/step - loss: 0.0241\n",
      "Epoch 100/100\n",
      "24362/24362 [==============================] - 4s 178us/step - loss: 0.0308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1311d7438>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Building a 3 layer ANN with 2 layers of 20 nodes \"\"\"\n",
    "\n",
    "regressor_4 = Sequential()\n",
    "regressor_4.add(Dense(20, kernel_initializer = 'normal',activation = 'relu',input_dim = 7))\n",
    "regressor_4.add(Dense(20, kernel_initializer = 'normal', activation = 'relu'))\n",
    "regressor_4.add(Dense(1, kernel_initializer = 'normal'))\n",
    "\n",
    "\"\"\" Compiling the regressor \"\"\"\n",
    "regressor_4.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "\"\"\" Fitting the Artifilial Neural Network to our training data \"\"\"\n",
    "regressor_4.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.096325</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.224709</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.239055</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.196210</td>\n",
       "      <td>-0.174625</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.214196</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.425145</td>\n",
       "      <td>1.322313</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.222329</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.235881</td>\n",
       "      <td>-0.223323</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.215833</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.243268</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.212636</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.879658</td>\n",
       "      <td>2.508815</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.204237</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.205972</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.237831</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.222695</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.218848</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.243316</td>\n",
       "      <td>1.859028</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.204723</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.230598</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.250761</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.243316</td>\n",
       "      <td>2.031666</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.239524</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.223130</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.225863</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.227994</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.215235</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.821420</td>\n",
       "      <td>0.687311</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.030321</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.238685</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6061</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.209316</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.212361</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>16.152226</td>\n",
       "      <td>13.367814</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.196461</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>0.461583</td>\n",
       "      <td>0.258130</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.241258</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6067</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.212265</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6068</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.232465</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6069</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.228631</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6070</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.198283</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6071</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.240660</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6072</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.219096</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.220459</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.209059</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6075</th>\n",
       "      <td>3.061487</td>\n",
       "      <td>2.530996</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.216867</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.204028</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.062770</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6079</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.243934</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6080</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.229416</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6081</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.229977</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6082</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.208560</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6083</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.206365</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6084</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.219441</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6085</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.198374</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6086</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.235899</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.224494</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6088</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.219584</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6089</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.255375</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6090</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.208793</td>\n",
       "      <td>0.054166</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6091 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual Values  Predicted Values  Mean Squared Error  \\\n",
       "0          0.101746          0.096325            0.054166   \n",
       "1         -0.211198         -0.224709            0.054166   \n",
       "2         -0.258092         -0.239055            0.054166   \n",
       "3         -0.196210         -0.174625            0.054166   \n",
       "4         -0.211198         -0.214196            0.054166   \n",
       "5          1.425145          1.322313            0.054166   \n",
       "6         -0.211198         -0.222329            0.054166   \n",
       "7         -0.235881         -0.223323            0.054166   \n",
       "8         -0.211198         -0.215833            0.054166   \n",
       "9         -0.258092         -0.243268            0.054166   \n",
       "10        -0.211198         -0.212636            0.054166   \n",
       "11         3.879658          2.508815            0.054166   \n",
       "12        -0.211198         -0.204237            0.054166   \n",
       "13        -0.211198         -0.205972            0.054166   \n",
       "14        -0.258092         -0.237831            0.054166   \n",
       "15        -0.211198         -0.222695            0.054166   \n",
       "16        -0.211198         -0.218848            0.054166   \n",
       "17         2.243316          1.859028            0.054166   \n",
       "18        -0.211198         -0.204723            0.054166   \n",
       "19        -0.211198         -0.230598            0.054166   \n",
       "20        -0.258092         -0.250761            0.054166   \n",
       "21         2.243316          2.031666            0.054166   \n",
       "22        -0.258092         -0.239524            0.054166   \n",
       "23        -0.211198         -0.223130            0.054166   \n",
       "24        -0.211198         -0.225863            0.054166   \n",
       "25        -0.211198         -0.227994            0.054166   \n",
       "26        -0.211198         -0.215235            0.054166   \n",
       "27         0.821420          0.687311            0.054166   \n",
       "28         0.101746          0.030321            0.054166   \n",
       "29        -0.258092         -0.238685            0.054166   \n",
       "...             ...               ...                 ...   \n",
       "6061      -0.211198         -0.209316            0.054166   \n",
       "6062      -0.258092         -0.212361            0.054166   \n",
       "6063      16.152226         13.367814            0.054166   \n",
       "6064      -0.211198         -0.196461            0.054166   \n",
       "6065       0.461583          0.258130            0.054166   \n",
       "6066      -0.258092         -0.241258            0.054166   \n",
       "6067      -0.211198         -0.212265            0.054166   \n",
       "6068      -0.258092         -0.232465            0.054166   \n",
       "6069      -0.258092         -0.228631            0.054166   \n",
       "6070      -0.211198         -0.198283            0.054166   \n",
       "6071      -0.258092         -0.240660            0.054166   \n",
       "6072      -0.211198         -0.219096            0.054166   \n",
       "6073      -0.211198         -0.220459            0.054166   \n",
       "6074      -0.211198         -0.209059            0.054166   \n",
       "6075       3.061487          2.530996            0.054166   \n",
       "6076      -0.211198         -0.216867            0.054166   \n",
       "6077      -0.211198         -0.204028            0.054166   \n",
       "6078       0.101746          0.062770            0.054166   \n",
       "6079      -0.258092         -0.243934            0.054166   \n",
       "6080      -0.258092         -0.229416            0.054166   \n",
       "6081      -0.258092         -0.229977            0.054166   \n",
       "6082      -0.211198         -0.208560            0.054166   \n",
       "6083      -0.211198         -0.206365            0.054166   \n",
       "6084      -0.211198         -0.219441            0.054166   \n",
       "6085      -0.211198         -0.198374            0.054166   \n",
       "6086      -0.258092         -0.235899            0.054166   \n",
       "6087      -0.211198         -0.224494            0.054166   \n",
       "6088      -0.211198         -0.219584            0.054166   \n",
       "6089      -0.258092         -0.255375            0.054166   \n",
       "6090      -0.211198         -0.208793            0.054166   \n",
       "\n",
       "      Root Mean Squared Error  \n",
       "0                    0.232735  \n",
       "1                    0.232735  \n",
       "2                    0.232735  \n",
       "3                    0.232735  \n",
       "4                    0.232735  \n",
       "5                    0.232735  \n",
       "6                    0.232735  \n",
       "7                    0.232735  \n",
       "8                    0.232735  \n",
       "9                    0.232735  \n",
       "10                   0.232735  \n",
       "11                   0.232735  \n",
       "12                   0.232735  \n",
       "13                   0.232735  \n",
       "14                   0.232735  \n",
       "15                   0.232735  \n",
       "16                   0.232735  \n",
       "17                   0.232735  \n",
       "18                   0.232735  \n",
       "19                   0.232735  \n",
       "20                   0.232735  \n",
       "21                   0.232735  \n",
       "22                   0.232735  \n",
       "23                   0.232735  \n",
       "24                   0.232735  \n",
       "25                   0.232735  \n",
       "26                   0.232735  \n",
       "27                   0.232735  \n",
       "28                   0.232735  \n",
       "29                   0.232735  \n",
       "...                       ...  \n",
       "6061                 0.232735  \n",
       "6062                 0.232735  \n",
       "6063                 0.232735  \n",
       "6064                 0.232735  \n",
       "6065                 0.232735  \n",
       "6066                 0.232735  \n",
       "6067                 0.232735  \n",
       "6068                 0.232735  \n",
       "6069                 0.232735  \n",
       "6070                 0.232735  \n",
       "6071                 0.232735  \n",
       "6072                 0.232735  \n",
       "6073                 0.232735  \n",
       "6074                 0.232735  \n",
       "6075                 0.232735  \n",
       "6076                 0.232735  \n",
       "6077                 0.232735  \n",
       "6078                 0.232735  \n",
       "6079                 0.232735  \n",
       "6080                 0.232735  \n",
       "6081                 0.232735  \n",
       "6082                 0.232735  \n",
       "6083                 0.232735  \n",
       "6084                 0.232735  \n",
       "6085                 0.232735  \n",
       "6086                 0.232735  \n",
       "6087                 0.232735  \n",
       "6088                 0.232735  \n",
       "6089                 0.232735  \n",
       "6090                 0.232735  \n",
       "\n",
       "[6091 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Predicting the values for Helpful Votes on the test data \"\"\"\n",
    "y_pred_4 = regressor_4.predict(X_test)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against predicted values \"\"\"\n",
    "y_pred_4 = y_pred_4.reshape(6091,)\n",
    "temp = {'Actual Values': y_test,'Predicted Values': y_pred_4}\n",
    "y_compare_4 = pd.DataFrame(temp)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_4['Mean Squared Error'] = (np.diff(y_compare_4.values) ** 2)\n",
    "y_compare_4['Mean Squared Error'] = np.mean(y_compare_4['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_4['Root Mean Squared Error'] = y_compare_4['Mean Squared Error']**0.5\n",
    "y_compare_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values(Training)</th>\n",
       "      <th>Predicted Values(Training)</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.207469</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.220632</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.237735</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.285135</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.225629</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.251068</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.224203</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.251624</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.255054</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.249237</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.247101</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.210516</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.108073</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.205614</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.243605</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.229845</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.233283</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.216579</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.246764</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.224960</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.225949</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.230061</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.230672</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.263673</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.254206</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.254015</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.208809</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.217641</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.296586</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.216510</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24332</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.248938</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24333</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.255153</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24334</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.251735</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24335</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.227303</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24336</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.227693</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24337</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.225587</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24338</th>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.093160</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24339</th>\n",
       "      <td>0.606973</td>\n",
       "      <td>0.627830</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24340</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.195808</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24341</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.252666</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24342</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.195368</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24343</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.210761</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24344</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.243882</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24345</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.218274</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24346</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.235881</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24347</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.226392</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24348</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.209708</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24349</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.248992</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24350</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.232639</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24351</th>\n",
       "      <td>3.061487</td>\n",
       "      <td>3.668170</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24352</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.206922</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24353</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.230877</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24354</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.255640</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24355</th>\n",
       "      <td>-0.196210</td>\n",
       "      <td>-0.219113</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24356</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.197420</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24357</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.251163</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24358</th>\n",
       "      <td>-0.211198</td>\n",
       "      <td>-0.229316</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24359</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.254455</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24360</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.254657</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24361</th>\n",
       "      <td>-0.258092</td>\n",
       "      <td>-0.259360</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24362 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Values(Training)  Predicted Values(Training)  \\\n",
       "0                    -0.211198                   -0.207469   \n",
       "1                    -0.211198                   -0.220632   \n",
       "2                    -0.258092                   -0.237735   \n",
       "3                    -0.211198                   -0.285135   \n",
       "4                    -0.258092                   -0.225629   \n",
       "5                    -0.258092                   -0.251068   \n",
       "6                    -0.211198                   -0.224203   \n",
       "7                    -0.258092                   -0.251624   \n",
       "8                    -0.258092                   -0.255054   \n",
       "9                    -0.258092                   -0.249237   \n",
       "10                   -0.258092                   -0.247101   \n",
       "11                   -0.211198                   -0.210516   \n",
       "12                    0.101746                    0.108073   \n",
       "13                   -0.211198                   -0.205614   \n",
       "14                   -0.258092                   -0.243605   \n",
       "15                   -0.211198                   -0.229845   \n",
       "16                   -0.258092                   -0.233283   \n",
       "17                   -0.211198                   -0.216579   \n",
       "18                   -0.258092                   -0.246764   \n",
       "19                   -0.211198                   -0.224960   \n",
       "20                   -0.211198                   -0.225949   \n",
       "21                   -0.211198                   -0.230061   \n",
       "22                   -0.211198                   -0.230672   \n",
       "23                   -0.258092                   -0.263673   \n",
       "24                   -0.258092                   -0.254206   \n",
       "25                   -0.258092                   -0.254015   \n",
       "26                   -0.211198                   -0.208809   \n",
       "27                   -0.211198                   -0.217641   \n",
       "28                   -0.211198                   -0.296586   \n",
       "29                   -0.211198                   -0.216510   \n",
       "...                        ...                         ...   \n",
       "24332                -0.258092                   -0.248938   \n",
       "24333                -0.258092                   -0.255153   \n",
       "24334                -0.258092                   -0.251735   \n",
       "24335                -0.211198                   -0.227303   \n",
       "24336                -0.211198                   -0.227693   \n",
       "24337                -0.211198                   -0.225587   \n",
       "24338                 0.101746                    0.093160   \n",
       "24339                 0.606973                    0.627830   \n",
       "24340                -0.211198                   -0.195808   \n",
       "24341                -0.258092                   -0.252666   \n",
       "24342                -0.211198                   -0.195368   \n",
       "24343                -0.211198                   -0.210761   \n",
       "24344                -0.258092                   -0.243882   \n",
       "24345                -0.211198                   -0.218274   \n",
       "24346                -0.258092                   -0.235881   \n",
       "24347                -0.211198                   -0.226392   \n",
       "24348                -0.211198                   -0.209708   \n",
       "24349                -0.258092                   -0.248992   \n",
       "24350                -0.258092                   -0.232639   \n",
       "24351                 3.061487                    3.668170   \n",
       "24352                -0.211198                   -0.206922   \n",
       "24353                -0.211198                   -0.230877   \n",
       "24354                -0.258092                   -0.255640   \n",
       "24355                -0.196210                   -0.219113   \n",
       "24356                -0.211198                   -0.197420   \n",
       "24357                -0.258092                   -0.251163   \n",
       "24358                -0.211198                   -0.229316   \n",
       "24359                -0.258092                   -0.254455   \n",
       "24360                -0.258092                   -0.254657   \n",
       "24361                -0.258092                   -0.259360   \n",
       "\n",
       "       Mean Squared Error  Root Mean Squared Error  \n",
       "0                0.025126                 0.158512  \n",
       "1                0.025126                 0.158512  \n",
       "2                0.025126                 0.158512  \n",
       "3                0.025126                 0.158512  \n",
       "4                0.025126                 0.158512  \n",
       "5                0.025126                 0.158512  \n",
       "6                0.025126                 0.158512  \n",
       "7                0.025126                 0.158512  \n",
       "8                0.025126                 0.158512  \n",
       "9                0.025126                 0.158512  \n",
       "10               0.025126                 0.158512  \n",
       "11               0.025126                 0.158512  \n",
       "12               0.025126                 0.158512  \n",
       "13               0.025126                 0.158512  \n",
       "14               0.025126                 0.158512  \n",
       "15               0.025126                 0.158512  \n",
       "16               0.025126                 0.158512  \n",
       "17               0.025126                 0.158512  \n",
       "18               0.025126                 0.158512  \n",
       "19               0.025126                 0.158512  \n",
       "20               0.025126                 0.158512  \n",
       "21               0.025126                 0.158512  \n",
       "22               0.025126                 0.158512  \n",
       "23               0.025126                 0.158512  \n",
       "24               0.025126                 0.158512  \n",
       "25               0.025126                 0.158512  \n",
       "26               0.025126                 0.158512  \n",
       "27               0.025126                 0.158512  \n",
       "28               0.025126                 0.158512  \n",
       "29               0.025126                 0.158512  \n",
       "...                   ...                      ...  \n",
       "24332            0.025126                 0.158512  \n",
       "24333            0.025126                 0.158512  \n",
       "24334            0.025126                 0.158512  \n",
       "24335            0.025126                 0.158512  \n",
       "24336            0.025126                 0.158512  \n",
       "24337            0.025126                 0.158512  \n",
       "24338            0.025126                 0.158512  \n",
       "24339            0.025126                 0.158512  \n",
       "24340            0.025126                 0.158512  \n",
       "24341            0.025126                 0.158512  \n",
       "24342            0.025126                 0.158512  \n",
       "24343            0.025126                 0.158512  \n",
       "24344            0.025126                 0.158512  \n",
       "24345            0.025126                 0.158512  \n",
       "24346            0.025126                 0.158512  \n",
       "24347            0.025126                 0.158512  \n",
       "24348            0.025126                 0.158512  \n",
       "24349            0.025126                 0.158512  \n",
       "24350            0.025126                 0.158512  \n",
       "24351            0.025126                 0.158512  \n",
       "24352            0.025126                 0.158512  \n",
       "24353            0.025126                 0.158512  \n",
       "24354            0.025126                 0.158512  \n",
       "24355            0.025126                 0.158512  \n",
       "24356            0.025126                 0.158512  \n",
       "24357            0.025126                 0.158512  \n",
       "24358            0.025126                 0.158512  \n",
       "24359            0.025126                 0.158512  \n",
       "24360            0.025126                 0.158512  \n",
       "24361            0.025126                 0.158512  \n",
       "\n",
       "[24362 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Now we will also predict the y values on the training set just to calculate MSE and RMSE \"\"\"\n",
    "\n",
    "y_pred_train_4 = regressor_4.predict(X_train)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against the predicted values for the training set \"\"\"\n",
    "y_pred_train_4 = y_pred_train_4.reshape(24362,)\n",
    "temp_train = {'Actual Values(Training)':y_train, 'Predicted Values(Training)': y_pred_train_4 }\n",
    "y_compare_train_4 = pd.DataFrame(temp_train)\n",
    "    \n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN on TRAINING SET\"\"\"\n",
    "# We are calculating this MSE in two steps. Don't get confused.\n",
    "y_compare_train_4['Mean Squared Error'] = (np.diff(y_compare_train_4.values) ** 2)\n",
    "y_compare_train_4['Mean Squared Error'] = np.mean(y_compare_train_4['Mean Squared Error'])\n",
    "\n",
    "# Now calculating the Root Mean Squared Error(RMSE)\n",
    "y_compare_train_4['Root Mean Squared Error'] = y_compare_train_4['Mean Squared Error']**0.5\n",
    "y_compare_train_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
