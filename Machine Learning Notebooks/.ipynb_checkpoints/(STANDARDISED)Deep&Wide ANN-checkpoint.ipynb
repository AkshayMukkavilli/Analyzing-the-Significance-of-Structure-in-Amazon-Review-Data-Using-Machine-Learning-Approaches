{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will use the same Artificial Neural Networks as in ANN(Deep and Wide with High Nodes Vs Low Nodes) but we will scale the dataset using StandardScaler from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Words</th>\n",
       "      <th>Paragraphs</th>\n",
       "      <th>No.break tags</th>\n",
       "      <th>Percentage_Upper_Case</th>\n",
       "      <th>Percentage_Lower_Case</th>\n",
       "      <th>Avg_len_paragraph_per_review</th>\n",
       "      <th>Helpful Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>565</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "      <td>3087.000000</td>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>162</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>343</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>468.500000</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>730</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>394.272727</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>194</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>91</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stars  Words  Paragraphs  No.break tags  Percentage_Upper_Case  \\\n",
       "0      3    565           1              0                      3   \n",
       "1      5    162           3              4                      3   \n",
       "2      4    343           4              6                      4   \n",
       "3      4    730          11             20                      3   \n",
       "4      5    194           2              1                      6   \n",
       "\n",
       "   Percentage_Lower_Case  Avg_len_paragraph_per_review  Helpful Votes  \n",
       "0                     93                   3087.000000            837  \n",
       "1                     91                    300.000000            374  \n",
       "2                     90                    468.500000            263  \n",
       "3                     91                    394.272727            200  \n",
       "4                     91                    492.000000            247  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(r'C:\\Users\\aksha\\PycharmProjects\\FinalProject_WorkingCopy\\FinalFeatures.csv')\n",
    "\n",
    "# The below line of code is to remove all the columns with z-scores from the dataset and move the Helpful Votes \n",
    "# column to the end\n",
    "dataset = dataset[['Stars','Words', 'Paragraphs','No.break tags','Percentage_Upper_Case','Percentage_Lower_Case','Avg_len_paragraph_per_review','Helpful Votes']]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating the independant variables from the dependant variable which is \"Helpful Votes\" in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,0:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Splitting the data into training data and testing data\"\"\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2,random_state=0)\n",
    "\n",
    "\"\"\"Scaling the data using StandardScaler from sklearn package\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing keras and other required functions\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24362/24362 [==============================] - 4s 148us/step - loss: 2103.7034\n",
      "Epoch 2/100\n",
      "24362/24362 [==============================] - 3s 126us/step - loss: 2113.1969\n",
      "Epoch 3/100\n",
      "24362/24362 [==============================] - 3s 122us/step - loss: 2055.08900s - loss:\n",
      "Epoch 4/100\n",
      "24362/24362 [==============================] - 3s 118us/step - loss: 2109.0873\n",
      "Epoch 5/100\n",
      "24362/24362 [==============================] - 3s 120us/step - loss: 2091.29910s - loss: 2683. - ETA: 0s - loss:\n",
      "Epoch 6/100\n",
      "24362/24362 [==============================] - 3s 120us/step - loss: 2114.1772\n",
      "Epoch 7/100\n",
      "24362/24362 [==============================] - 3s 127us/step - loss: 2102.26601s - loss: 3145.87 - E - ETA:  - ETA: 0s - loss: 2121.96\n",
      "Epoch 8/100\n",
      "24362/24362 [==============================] - 3s 121us/step - loss: 2091.6230\n",
      "Epoch 9/100\n",
      "24362/24362 [==============================] - 3s 121us/step - loss: 2087.2450\n",
      "Epoch 10/100\n",
      "24362/24362 [==============================] - 3s 121us/step - loss: 2089.8538\n",
      "Epoch 11/100\n",
      "24362/24362 [==============================] - 3s 128us/step - loss: 2047.0933\n",
      "Epoch 12/100\n",
      "24362/24362 [==============================] - 3s 130us/step - loss: 2070.54201s - - ETA:  - ETA\n",
      "Epoch 13/100\n",
      "24362/24362 [==============================] - 3s 136us/step - loss: 2059.2324\n",
      "Epoch 14/100\n",
      "24362/24362 [==============================] - 3s 128us/step - loss: 2082.1379\n",
      "Epoch 15/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 2061.7967\n",
      "Epoch 16/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 2103.5729\n",
      "Epoch 17/100\n",
      "24362/24362 [==============================] - 3s 134us/step - loss: 2084.3268\n",
      "Epoch 18/100\n",
      "24362/24362 [==============================] - 3s 115us/step - loss: 2012.74810s - los\n",
      "Epoch 19/100\n",
      "24362/24362 [==============================] - 3s 114us/step - loss: 2086.8992\n",
      "Epoch 20/100\n",
      "24362/24362 [==============================] - 3s 115us/step - loss: 2074.9931\n",
      "Epoch 21/100\n",
      "24362/24362 [==============================] - 3s 117us/step - loss: 2082.42030s - los\n",
      "Epoch 22/100\n",
      "24362/24362 [==============================] - 3s 137us/step - loss: 1990.3739\n",
      "Epoch 23/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 2084.45660s - loss: 2134.\n",
      "Epoch 24/100\n",
      "24362/24362 [==============================] - 3s 124us/step - loss: 2061.32410s - loss: 229 - ETA: 0s - l\n",
      "Epoch 25/100\n",
      "24362/24362 [==============================] - 3s 128us/step - loss: 2090.68710s - loss: 233 - ETA: 0s - loss:\n",
      "Epoch 26/100\n",
      "24362/24362 [==============================] - 3s 133us/step - loss: 2091.73052s - - ETA: 0s\n",
      "Epoch 27/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 2074.7345\n",
      "Epoch 28/100\n",
      "24362/24362 [==============================] - 3s 124us/step - loss: 2077.08611s - los - ETA: 1s - loss: 508 - ETA: 0s - loss - ETA: \n",
      "Epoch 29/100\n",
      "24362/24362 [==============================] - 3s 137us/step - loss: 2058.61360s - l\n",
      "Epoch 30/100\n",
      "24362/24362 [==============================] - 3s 132us/step - loss: 2042.69970s - loss:\n",
      "Epoch 31/100\n",
      "24362/24362 [==============================] - 3s 131us/step - loss: 2061.2971\n",
      "Epoch 32/100\n",
      "24362/24362 [==============================] - 3s 135us/step - loss: 2056.0616\n",
      "Epoch 33/100\n",
      "24362/24362 [==============================] - 3s 134us/step - loss: 2058.8470\n",
      "Epoch 34/100\n",
      "24362/24362 [==============================] - 3s 134us/step - loss: 2061.5598\n",
      "Epoch 35/100\n",
      "24362/24362 [==============================] - 3s 133us/step - loss: 2017.1113\n",
      "Epoch 36/100\n",
      "24362/24362 [==============================] - 3s 135us/step - loss: 2016.5696\n",
      "Epoch 37/100\n",
      "24362/24362 [==============================] - 3s 125us/step - loss: 2069.54450s - loss: 2096.79\n",
      "Epoch 38/100\n",
      "24362/24362 [==============================] - 3s 129us/step - loss: 2031.8772\n",
      "Epoch 39/100\n",
      "24362/24362 [==============================] - 3s 126us/step - loss: 2067.1494\n",
      "Epoch 40/100\n",
      "24362/24362 [==============================] - 3s 127us/step - loss: 2007.3385\n",
      "Epoch 41/100\n",
      "24362/24362 [==============================] - 3s 130us/step - loss: 2035.8818\n",
      "Epoch 42/100\n",
      "24362/24362 [==============================] - 3s 124us/step - loss: 2005.01640s - loss: - ETA\n",
      "Epoch 43/100\n",
      "24362/24362 [==============================] - 3s 125us/step - loss: 2074.8931\n",
      "Epoch 44/100\n",
      "24362/24362 [==============================] - 3s 125us/step - loss: 2040.1696\n",
      "Epoch 45/100\n",
      "24362/24362 [==============================] - 3s 126us/step - loss: 2006.5763\n",
      "Epoch 46/100\n",
      "24362/24362 [==============================] - 3s 125us/step - loss: 2078.1712\n",
      "Epoch 47/100\n",
      "24362/24362 [==============================] - 3s 126us/step - loss: 1990.8148 ETA: 0s - loss: 205\n",
      "Epoch 48/100\n",
      "24362/24362 [==============================] - 3s 125us/step - loss: 2050.8994\n",
      "Epoch 49/100\n",
      "24362/24362 [==============================] - 3s 125us/step - loss: 2032.05060s - loss: 214 - ETA: 0s - loss: 202\n",
      "Epoch 50/100\n",
      "24362/24362 [==============================] - 3s 125us/step - loss: 2055.9558\n",
      "Epoch 51/100\n",
      "24362/24362 [==============================] - 3s 125us/step - loss: 2058.6174\n",
      "Epoch 52/100\n",
      "24362/24362 [==============================] - 3s 125us/step - loss: 2068.4261\n",
      "Epoch 53/100\n",
      "24362/24362 [==============================] - 3s 129us/step - loss: 2015.27870s - loss: 2029.91\n",
      "Epoch 54/100\n",
      "24362/24362 [==============================] - 3s 133us/step - loss: 2043.22360s - l\n",
      "Epoch 55/100\n",
      "24362/24362 [==============================] - 3s 132us/step - loss: 2033.7230\n",
      "Epoch 56/100\n",
      "24362/24362 [==============================] - 3s 128us/step - loss: 2051.9499\n",
      "Epoch 57/100\n",
      "24362/24362 [==============================] - 3s 125us/step - loss: 2062.21100s - loss: 431.574 - ETA:\n",
      "Epoch 58/100\n",
      "24362/24362 [==============================] - 3s 124us/step - loss: 2035.57880s - loss: 2\n",
      "Epoch 59/100\n",
      "24362/24362 [==============================] - 3s 125us/step - loss: 2056.6077\n",
      "Epoch 60/100\n",
      "24362/24362 [==============================] - 3s 125us/step - loss: 2002.14510s - loss:\n",
      "Epoch 61/100\n",
      "24362/24362 [==============================] - 3s 126us/step - loss: 2067.2722\n",
      "Epoch 62/100\n",
      "24362/24362 [==============================] - 3s 126us/step - loss: 2020.2001- ETA\n",
      "Epoch 63/100\n",
      "24362/24362 [==============================] - 3s 127us/step - loss: 2039.7462\n",
      "Epoch 64/100\n",
      "24362/24362 [==============================] - 3s 126us/step - loss: 2018.71900s - loss: 2\n",
      "Epoch 65/100\n",
      "24362/24362 [==============================] - 3s 126us/step - loss: 2069.9828\n",
      "Epoch 66/100\n",
      "24362/24362 [==============================] - 3s 126us/step - loss: 2024.5251\n",
      "Epoch 67/100\n",
      "24362/24362 [==============================] - 3s 126us/step - loss: 2053.1124\n",
      "Epoch 68/100\n",
      "24362/24362 [==============================] - 3s 127us/step - loss: 1991.6849\n",
      "Epoch 69/100\n",
      "24362/24362 [==============================] - 3s 125us/step - loss: 2019.2242\n",
      "Epoch 70/100\n",
      "24362/24362 [==============================] - 3s 136us/step - loss: 1993.8454\n",
      "Epoch 71/100\n",
      "24362/24362 [==============================] - 3s 144us/step - loss: 2060.0255\n",
      "Epoch 72/100\n",
      "24362/24362 [==============================] - 3s 135us/step - loss: 2025.5379\n",
      "Epoch 73/100\n",
      "24362/24362 [==============================] - 3s 130us/step - loss: 2024.9992\n",
      "Epoch 74/100\n",
      "24362/24362 [==============================] - 3s 126us/step - loss: 2013.1129\n",
      "Epoch 75/100\n",
      "24362/24362 [==============================] - 3s 120us/step - loss: 2045.72092s\n",
      "Epoch 76/100\n",
      "24362/24362 [==============================] - 3s 118us/step - loss: 2043.1921 ETA: 0s - loss: 211\n",
      "Epoch 77/100\n",
      "24362/24362 [==============================] - 3s 123us/step - loss: 1995.58872s - loss: 456 - ETA: 2s - loss: 344 - ETA: 2s - los - ETA: 0s - loss: 228 - ETA: 0s -\n",
      "Epoch 78/100\n",
      "24362/24362 [==============================] - 3s 128us/step - loss: 2057.0096\n",
      "Epoch 79/100\n",
      "24362/24362 [==============================] - 3s 136us/step - loss: 2051.1423\n",
      "Epoch 80/100\n",
      "24362/24362 [==============================] - 3s 128us/step - loss: 1946.7430\n",
      "Epoch 81/100\n",
      "24362/24362 [==============================] - 3s 131us/step - loss: 2063.71630s - loss: 2077.91\n",
      "Epoch 82/100\n",
      "24362/24362 [==============================] - 3s 125us/step - loss: 2055.9444\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24362/24362 [==============================] - 3s 131us/step - loss: 2107.05680s - loss: 2136.\n",
      "Epoch 84/100\n",
      "24362/24362 [==============================] - 3s 132us/step - loss: 1996.96680s - los\n",
      "Epoch 85/100\n",
      "24362/24362 [==============================] - 3s 128us/step - loss: 1965.1003\n",
      "Epoch 86/100\n",
      "24362/24362 [==============================] - 3s 132us/step - loss: 2031.3377\n",
      "Epoch 87/100\n",
      "24362/24362 [==============================] - 4s 150us/step - loss: 2033.6401\n",
      "Epoch 88/100\n",
      "24362/24362 [==============================] - 4s 149us/step - loss: 2055.78890s -\n",
      "Epoch 89/100\n",
      "24362/24362 [==============================] - 4s 145us/step - loss: 2052.8319\n",
      "Epoch 90/100\n",
      "24362/24362 [==============================] - 3s 130us/step - loss: 2025.5936 ETA: 0s - loss: 2055.\n",
      "Epoch 91/100\n",
      "24362/24362 [==============================] - 3s 136us/step - loss: 2050.7755\n",
      "Epoch 92/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 2050.8315\n",
      "Epoch 93/100\n",
      "24362/24362 [==============================] - 3s 133us/step - loss: 2034.3791\n",
      "Epoch 94/100\n",
      "24362/24362 [==============================] - 4s 167us/step - loss: 2054.57540s - loss: 1049.\n",
      "Epoch 95/100\n",
      "24362/24362 [==============================] - 3s 133us/step - loss: 1981.8910\n",
      "Epoch 96/100\n",
      "24362/24362 [==============================] - 3s 143us/step - loss: 2034.78700s - loss: 2427.95 - E\n",
      "Epoch 97/100\n",
      "24362/24362 [==============================] - 3s 128us/step - loss: 2021.0126\n",
      "Epoch 98/100\n",
      "24362/24362 [==============================] - 4s 145us/step - loss: 2002.4308\n",
      "Epoch 99/100\n",
      "24362/24362 [==============================] - 3s 128us/step - loss: 2037.4865\n",
      "Epoch 100/100\n",
      "24362/24362 [==============================] - 3s 130us/step - loss: 1992.84521s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c3448f3ac8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Building a 3 layer ANN with high number of nodes \"\"\"\n",
    "\n",
    "regressor = Sequential()\n",
    "regressor.add(Dense(100, kernel_initializer = 'normal',activation = 'relu',input_dim = 7))\n",
    "regressor.add(Dense(100, kernel_initializer = 'normal', activation = 'relu'))\n",
    "regressor.add(Dense(1, kernel_initializer = 'normal'))\n",
    "\n",
    "\"\"\" Compiling the regressor \"\"\"\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "\"\"\" Fitting the Artifilial Neural Network to our training data \"\"\"\n",
    "regressor.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.252046</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.175394</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.491296</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.873026</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.608089</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.293209</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.703063</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.387502</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.523363</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0.348880</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.767763</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.148071</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.087284</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.711158</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.255480</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.479155</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.611232</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>6.648627</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0.197908</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0.050710</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.061297</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12</td>\n",
       "      <td>2.269091</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0.324774</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.428245</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.959574</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0.288574</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0.137986</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0.627365</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.050727</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0.538688</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6041</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.965639</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6042</th>\n",
       "      <td>2</td>\n",
       "      <td>0.502549</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>7</td>\n",
       "      <td>8.578031</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6044</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.208190</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6045</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.309182</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6046</th>\n",
       "      <td>0</td>\n",
       "      <td>0.598300</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6047</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.130526</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6048</th>\n",
       "      <td>8</td>\n",
       "      <td>0.160782</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.354153</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6050</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.472081</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6051</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.191729</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6052</th>\n",
       "      <td>0</td>\n",
       "      <td>3.770354</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6053</th>\n",
       "      <td>1</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6054</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.116908</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6055</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.005120</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6056</th>\n",
       "      <td>0</td>\n",
       "      <td>0.233917</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6057</th>\n",
       "      <td>0</td>\n",
       "      <td>0.121915</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6058</th>\n",
       "      <td>2</td>\n",
       "      <td>12.893869</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6059</th>\n",
       "      <td>0</td>\n",
       "      <td>0.401788</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6060</th>\n",
       "      <td>0</td>\n",
       "      <td>0.501061</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6061</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.257473</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.159212</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>33</td>\n",
       "      <td>206.126404</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>1</td>\n",
       "      <td>1.110458</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>2</td>\n",
       "      <td>3.232991</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>0</td>\n",
       "      <td>0.524350</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6067</th>\n",
       "      <td>0</td>\n",
       "      <td>0.328725</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6068</th>\n",
       "      <td>0</td>\n",
       "      <td>0.082291</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6069</th>\n",
       "      <td>1</td>\n",
       "      <td>0.583036</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6070</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.016357</td>\n",
       "      <td>16.793489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6071 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual Values  Predicted Values  Mean Squared Error\n",
       "0                 1         -0.252046           16.793489\n",
       "1                 0          1.175394           16.793489\n",
       "2                 0          0.491296           16.793489\n",
       "3                 0         -0.873026           16.793489\n",
       "4                 0         -0.608089           16.793489\n",
       "5                 0          0.293209           16.793489\n",
       "6                 0          0.703063           16.793489\n",
       "7                 0          0.387502           16.793489\n",
       "8                 0          0.523363           16.793489\n",
       "9                 1          0.348880           16.793489\n",
       "10                0          0.767763           16.793489\n",
       "11                1         -0.148071           16.793489\n",
       "12                1         -0.087284           16.793489\n",
       "13                0         -0.711158           16.793489\n",
       "14                0          0.255480           16.793489\n",
       "15                0          0.479155           16.793489\n",
       "16                1         -0.611232           16.793489\n",
       "17                1          6.648627           16.793489\n",
       "18                0          0.197908           16.793489\n",
       "19                0          0.050710           16.793489\n",
       "20                0          0.061297           16.793489\n",
       "21               12          2.269091           16.793489\n",
       "22                1          0.324774           16.793489\n",
       "23                0         -0.428245           16.793489\n",
       "24                0         -0.959574           16.793489\n",
       "25                0          0.288574           16.793489\n",
       "26                0          0.137986           16.793489\n",
       "27                0          0.627365           16.793489\n",
       "28                0         -0.050727           16.793489\n",
       "29                0          0.538688           16.793489\n",
       "...             ...               ...                 ...\n",
       "6041              0         -1.965639           16.793489\n",
       "6042              2          0.502549           16.793489\n",
       "6043              7          8.578031           16.793489\n",
       "6044              0         -0.208190           16.793489\n",
       "6045              0         -0.309182           16.793489\n",
       "6046              0          0.598300           16.793489\n",
       "6047              0         -0.130526           16.793489\n",
       "6048              8          0.160782           16.793489\n",
       "6049              0         -0.354153           16.793489\n",
       "6050              0         -0.472081           16.793489\n",
       "6051              0         -0.191729           16.793489\n",
       "6052              0          3.770354           16.793489\n",
       "6053              1          0.255814           16.793489\n",
       "6054              0         -0.116908           16.793489\n",
       "6055              0         -0.005120           16.793489\n",
       "6056              0          0.233917           16.793489\n",
       "6057              0          0.121915           16.793489\n",
       "6058              2         12.893869           16.793489\n",
       "6059              0          0.401788           16.793489\n",
       "6060              0          0.501061           16.793489\n",
       "6061              0         -0.257473           16.793489\n",
       "6062              1         -1.159212           16.793489\n",
       "6063             33        206.126404           16.793489\n",
       "6064              1          1.110458           16.793489\n",
       "6065              2          3.232991           16.793489\n",
       "6066              0          0.524350           16.793489\n",
       "6067              0          0.328725           16.793489\n",
       "6068              0          0.082291           16.793489\n",
       "6069              1          0.583036           16.793489\n",
       "6070              1         -1.016357           16.793489\n",
       "\n",
       "[6071 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Predicting the values for Helpful Votes on the test data \"\"\"\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against predicted values \"\"\"\n",
    "y_pred = y_pred.reshape(6091,)\n",
    "temp = {'Actual Values': y_test,'Predicted Values': y_pred}\n",
    "y_compare = pd.DataFrame(temp)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN\"\"\"\n",
    "y_compare['Mean Squared Error'] = ((np.diff(y_compare.values) ** 2).mean() ** .5)\n",
    "y_compare.head(-20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is huge in the above regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24362/24362 [==============================] - 4s 148us/step - loss: 2125.7819\n",
      "Epoch 2/100\n",
      "24362/24362 [==============================] - 3s 134us/step - loss: 2125.11730s - los\n",
      "Epoch 3/100\n",
      "24362/24362 [==============================] - 3s 121us/step - loss: 2124.86380s - l - ETA: 0s - loss: 2169.\n",
      "Epoch 4/100\n",
      "24362/24362 [==============================] - 3s 120us/step - loss: 2124.6856\n",
      "Epoch 5/100\n",
      "24362/24362 [==============================] - 3s 120us/step - loss: 2124.5903\n",
      "Epoch 6/100\n",
      "24362/24362 [==============================] - 3s 119us/step - loss: 2124.56232s - loss: 142  - ETA: 0s\n",
      "Epoch 7/100\n",
      "24362/24362 [==============================] - 3s 120us/step - loss: 2124.50512s -\n",
      "Epoch 8/100\n",
      "24362/24362 [==============================] - 3s 119us/step - loss: 2124.4813\n",
      "Epoch 9/100\n",
      "24362/24362 [==============================] - 3s 115us/step - loss: 2124.4636 - ETA: 0s - loss: 2915. - - ETA: 0s - loss: 2191.\n",
      "Epoch 10/100\n",
      "24362/24362 [==============================] - 3s 115us/step - loss: 2124.4400\n",
      "Epoch 11/100\n",
      "24362/24362 [==============================] - 3s 117us/step - loss: 2124.4729\n",
      "Epoch 12/100\n",
      "24362/24362 [==============================] - 3s 117us/step - loss: 2124.4553\n",
      "Epoch 13/100\n",
      "24362/24362 [==============================] - 3s 119us/step - loss: 2124.4336 - ETA: \n",
      "Epoch 14/100\n",
      "24362/24362 [==============================] - 3s 113us/step - loss: 2124.4109\n",
      "Epoch 15/100\n",
      "24362/24362 [==============================] - ETA: 0s - loss: 2163.2925- ETA:  - 3s 111us/step - loss: 2124.4249\n",
      "Epoch 16/100\n",
      "24362/24362 [==============================] - 3s 119us/step - loss: 2124.4153\n",
      "Epoch 17/100\n",
      "24362/24362 [==============================] - 3s 122us/step - loss: 2124.41961s\n",
      "Epoch 18/100\n",
      "24362/24362 [==============================] - 3s 122us/step - loss: 2124.43442s - loss:  - ETA\n",
      "Epoch 19/100\n",
      "24362/24362 [==============================] - 3s 124us/step - loss: 2124.44470s -\n",
      "Epoch 20/100\n",
      "24362/24362 [==============================] - 3s 123us/step - loss: 2124.4165\n",
      "Epoch 21/100\n",
      "24362/24362 [==============================] - 3s 125us/step - loss: 2124.4069\n",
      "Epoch 22/100\n",
      "24362/24362 [==============================] - 3s 123us/step - loss: 2124.4027\n",
      "Epoch 23/100\n",
      "24362/24362 [==============================] - 3s 125us/step - loss: 2124.3953\n",
      "Epoch 24/100\n",
      "24362/24362 [==============================] - 3s 122us/step - loss: 2124.40370s - loss: 2161.52\n",
      "Epoch 25/100\n",
      "24362/24362 [==============================] - 3s 120us/step - loss: 2124.4081\n",
      "Epoch 26/100\n",
      "24362/24362 [==============================] - 3s 119us/step - loss: 2124.3954\n",
      "Epoch 27/100\n",
      "24362/24362 [==============================] - 3s 119us/step - loss: 2124.4014\n",
      "Epoch 28/100\n",
      "24362/24362 [==============================] - 3s 117us/step - loss: 2124.41530s - loss: 1\n",
      "Epoch 29/100\n",
      "24362/24362 [==============================] - 3s 119us/step - loss: 2124.4071\n",
      "Epoch 30/100\n",
      "24362/24362 [==============================] - 3s 117us/step - loss: 2124.4137TA: 0s - loss: 658.9 - \n",
      "Epoch 31/100\n",
      "24362/24362 [==============================] - 3s 122us/step - loss: 2124.39430s - los -\n",
      "Epoch 32/100\n",
      "24362/24362 [==============================] - 3s 121us/step - loss: 2124.4001\n",
      "Epoch 33/100\n",
      "24362/24362 [==============================] - 3s 121us/step - loss: 2124.41250s - loss: 775.0\n",
      "Epoch 34/100\n",
      "24362/24362 [==============================] - 3s 121us/step - loss: 2124.3900\n",
      "Epoch 35/100\n",
      "24362/24362 [==============================] - 3s 121us/step - loss: 2124.41950s - loss: - ETA: 0s - loss: 221\n",
      "Epoch 36/100\n",
      "24362/24362 [==============================] - 3s 127us/step - loss: 2124.41380s - loss: 175\n",
      "Epoch 37/100\n",
      "24362/24362 [==============================] - 3s 125us/step - loss: 2124.4159\n",
      "Epoch 38/100\n",
      "24362/24362 [==============================] - 3s 123us/step - loss: 2124.4047\n",
      "Epoch 39/100\n",
      "24362/24362 [==============================] - 3s 114us/step - loss: 2124.39370s - ETA: 0s -\n",
      "Epoch 40/100\n",
      "24362/24362 [==============================] - 3s 112us/step - loss: 2124.39202s - loss: 2 - ETA: 2s -  - ETA: 0s - - ETA:  - ETA: 0s - loss: 2164.\n",
      "Epoch 41/100\n",
      "24362/24362 [==============================] - 3s 125us/step - loss: 2124.3985\n",
      "Epoch 42/100\n",
      "24362/24362 [==============================] - 3s 131us/step - loss: 2124.3977\n",
      "Epoch 43/100\n",
      "24362/24362 [==============================] - 3s 111us/step - loss: 2124.4131\n",
      "Epoch 44/100\n",
      "24362/24362 [==============================] - 3s 111us/step - loss: 2124.4149\n",
      "Epoch 45/100\n",
      "24362/24362 [==============================] - 3s 113us/step - loss: 2124.4248\n",
      "Epoch 46/100\n",
      "24362/24362 [==============================] - 3s 111us/step - loss: 2124.4118\n",
      "Epoch 47/100\n",
      "24362/24362 [==============================] - 3s 111us/step - loss: 2124.39860s - loss: 2\n",
      "Epoch 48/100\n",
      "24362/24362 [==============================] - 3s 111us/step - loss: 2124.40930s - los\n",
      "Epoch 49/100\n",
      "24362/24362 [==============================] - 3s 111us/step - loss: 2124.3947ETA: 1s - l\n",
      "Epoch 50/100\n",
      "24362/24362 [==============================] - 3s 126us/step - loss: 2124.40311s - los\n",
      "Epoch 51/100\n",
      "24362/24362 [==============================] - 3s 112us/step - loss: 2124.3989\n",
      "Epoch 52/100\n",
      "24362/24362 [==============================] - 3s 112us/step - loss: 2124.40130s - loss: 1784.66 - E\n",
      "Epoch 53/100\n",
      "24362/24362 [==============================] - 3s 111us/step - loss: 2124.3815 - ETA: 0s - l\n",
      "Epoch 54/100\n",
      "24362/24362 [==============================] - 3s 111us/step - loss: 2124.39042s - loss: 2839.43 - ETA: 2s - loss: 2484.40 - ETA: 2s - loss: -\n",
      "Epoch 55/100\n",
      "24362/24362 [==============================] - 3s 111us/step - loss: 2124.41262s - loss: 3 - ET\n",
      "Epoch 56/100\n",
      "24362/24362 [==============================] - 3s 111us/step - loss: 2124.4116\n",
      "Epoch 57/100\n",
      "24362/24362 [==============================] - 3s 112us/step - loss: 2124.40541s - loss: 2 - - ETA: 0s - loss: 2\n",
      "Epoch 58/100\n",
      "24362/24362 [==============================] - 3s 111us/step - loss: 2124.40030s - loss: 2\n",
      "Epoch 59/100\n",
      "24362/24362 [==============================] - 3s 110us/step - loss: 2124.4143: 0s - - ETA: 0s - loss: 222\n",
      "Epoch 60/100\n",
      "24362/24362 [==============================] - 3s 111us/step - loss: 2124.4127\n",
      "Epoch 61/100\n",
      "24362/24362 [==============================] - 3s 115us/step - loss: 2124.4205 - ETA: 0s - loss: 2340.69 - ETA: 0s - loss:\n",
      "Epoch 62/100\n",
      "24362/24362 [==============================] - 3s 112us/step - loss: 2124.4002ETA: 0s - - ETA\n",
      "Epoch 63/100\n",
      "24362/24362 [==============================] - 3s 111us/step - loss: 2124.4598 2s - los - ETA: 1 -\n",
      "Epoch 64/100\n",
      "24362/24362 [==============================] - 3s 111us/step - loss: 2124.42740s - loss: 185 - ETA: 0s - loss: 1748.\n",
      "Epoch 65/100\n",
      "24362/24362 [==============================] - 3s 111us/step - loss: 2124.4119\n",
      "Epoch 66/100\n",
      "24362/24362 [==============================] - 3s 116us/step - loss: 2124.4079\n",
      "Epoch 67/100\n",
      "24362/24362 [==============================] - 3s 119us/step - loss: 2124.4247\n",
      "Epoch 68/100\n",
      "24362/24362 [==============================] - 3s 135us/step - loss: 2124.4048\n",
      "Epoch 69/100\n",
      "24362/24362 [==============================] - 3s 129us/step - loss: 2124.4412\n",
      "Epoch 70/100\n",
      "24362/24362 [==============================] - 3s 128us/step - loss: 2124.4044\n",
      "Epoch 71/100\n",
      "24362/24362 [==============================] - 3s 127us/step - loss: 2124.4124\n",
      "Epoch 72/100\n",
      "24362/24362 [==============================] - 3s 127us/step - loss: 2124.4286\n",
      "Epoch 73/100\n",
      "24362/24362 [==============================] - 3s 126us/step - loss: 2124.42202s - lo\n",
      "Epoch 74/100\n",
      "24362/24362 [==============================] - 3s 125us/step - loss: 2124.3999\n",
      "Epoch 75/100\n",
      "24362/24362 [==============================] - 3s 125us/step - loss: 2124.44690s - los\n",
      "Epoch 76/100\n",
      "24362/24362 [==============================] - 3s 122us/step - loss: 2124.4201\n",
      "Epoch 77/100\n",
      "24362/24362 [==============================] - 3s 118us/step - loss: 2124.4094\n",
      "Epoch 78/100\n",
      "24362/24362 [==============================] - 4s 144us/step - loss: 2124.4099\n",
      "Epoch 79/100\n",
      "24362/24362 [==============================] - 3s 122us/step - loss: 2124.41220s - loss: 2124.58\n",
      "Epoch 80/100\n",
      "24362/24362 [==============================] - 3s 122us/step - loss: 2124.40170s - loss: 1\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24362/24362 [==============================] - 3s 111us/step - loss: 2124.39162s - loss: - ETA: 1s - loss: - ETA: 1s - loss: 380 - ETA: 1s - - ETA: 1s - loss: - ETA: 0s - los - ETA: 0s - loss: 2568. - ETA: 0s - - ETA: 0s - loss: 2093.\n",
      "Epoch 82/100\n",
      "24362/24362 [==============================] - 3s 112us/step - loss: 2124.3925\n",
      "Epoch 83/100\n",
      "24362/24362 [==============================] - 3s 111us/step - loss: 2124.4233\n",
      "Epoch 84/100\n",
      "24362/24362 [==============================] - 3s 111us/step - loss: 2124.44671s - los - ETA: 1s - - ETA: \n",
      "Epoch 85/100\n",
      "24362/24362 [==============================] - 3s 112us/step - loss: 2124.4126\n",
      "Epoch 86/100\n",
      "24362/24362 [==============================] - 3s 117us/step - loss: 2124.40720s - l\n",
      "Epoch 87/100\n",
      "24362/24362 [==============================] - 3s 122us/step - loss: 2124.41370s - loss: 2\n",
      "Epoch 88/100\n",
      "24362/24362 [==============================] - 3s 122us/step - loss: 2124.3971\n",
      "Epoch 89/100\n",
      "24362/24362 [==============================] - 3s 122us/step - loss: 2124.4027TA\n",
      "Epoch 90/100\n",
      "24362/24362 [==============================] - 3s 122us/step - loss: 2124.4048 ETA: 0s - loss: 229 - ETA: 0s - loss: 2168.\n",
      "Epoch 91/100\n",
      "24362/24362 [==============================] - 3s 126us/step - loss: 2124.40070s - l - ETA: 0s - los\n",
      "Epoch 92/100\n",
      "24362/24362 [==============================] - 3s 123us/step - loss: 2124.40160s - loss: 2153. - ETA: 0s - loss: - ETA: 0s - loss:\n",
      "Epoch 93/100\n",
      "24362/24362 [==============================] - 3s 124us/step - loss: 2124.40250s - loss: 2105.61\n",
      "Epoch 94/100\n",
      "24362/24362 [==============================] - 3s 121us/step - loss: 2124.37671s - - ETA: 0s - loss: 2716.78 - ETA: 0s - l - ETA: 0s - loss:\n",
      "Epoch 95/100\n",
      "24362/24362 [==============================] - 3s 116us/step - loss: 2124.4055\n",
      "Epoch 96/100\n",
      "24362/24362 [==============================] - 3s 120us/step - loss: 2124.4063\n",
      "Epoch 97/100\n",
      "24362/24362 [==============================] - 3s 122us/step - loss: 2124.41880s - loss: 2132.00\n",
      "Epoch 98/100\n",
      "24362/24362 [==============================] - 3s 119us/step - loss: 2124.3992TA: 0s - loss: - ETA: 0s - loss: 2183.\n",
      "Epoch 99/100\n",
      "24362/24362 [==============================] - 3s 118us/step - loss: 2124.39580s - - ETA: 0s - loss: 220\n",
      "Epoch 100/100\n",
      "24362/24362 [==============================] - 3s 119us/step - loss: 2124.41420s - l\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c3448da4a8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Building a 3 layer ANN with less number of nodes \"\"\"\n",
    "\n",
    "regressor_1 = Sequential()\n",
    "regressor_1.add(Dense(4, kernel_initializer = 'normal',activation = 'relu',input_dim = 7))\n",
    "regressor_1.add(Dense(4, kernel_initializer = 'normal', activation = 'relu'))\n",
    "regressor_1.add(Dense(1, kernel_initializer = 'normal'))\n",
    "\n",
    "\"\"\" Compiling the regressor \"\"\"\n",
    "regressor_1.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "\"\"\" Fitting the Artifilial Neural Network to our training data \"\"\"\n",
    "regressor_1.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6041</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6042</th>\n",
       "      <td>2</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>7</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6044</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6045</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6046</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6047</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6048</th>\n",
       "      <td>8</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6050</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6051</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6052</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6053</th>\n",
       "      <td>1</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6054</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6055</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6056</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6057</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6058</th>\n",
       "      <td>2</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6059</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6060</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6061</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>1</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>33</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>1</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>2</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6067</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6068</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6069</th>\n",
       "      <td>1</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6070</th>\n",
       "      <td>1</td>\n",
       "      <td>1.23644</td>\n",
       "      <td>15.27024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6071 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual Values  Predicted Values  Mean Squared Error\n",
       "0                 1           1.23644            15.27024\n",
       "1                 0           1.23644            15.27024\n",
       "2                 0           1.23644            15.27024\n",
       "3                 0           1.23644            15.27024\n",
       "4                 0           1.23644            15.27024\n",
       "5                 0           1.23644            15.27024\n",
       "6                 0           1.23644            15.27024\n",
       "7                 0           1.23644            15.27024\n",
       "8                 0           1.23644            15.27024\n",
       "9                 1           1.23644            15.27024\n",
       "10                0           1.23644            15.27024\n",
       "11                1           1.23644            15.27024\n",
       "12                1           1.23644            15.27024\n",
       "13                0           1.23644            15.27024\n",
       "14                0           1.23644            15.27024\n",
       "15                0           1.23644            15.27024\n",
       "16                1           1.23644            15.27024\n",
       "17                1           1.23644            15.27024\n",
       "18                0           1.23644            15.27024\n",
       "19                0           1.23644            15.27024\n",
       "20                0           1.23644            15.27024\n",
       "21               12           1.23644            15.27024\n",
       "22                1           1.23644            15.27024\n",
       "23                0           1.23644            15.27024\n",
       "24                0           1.23644            15.27024\n",
       "25                0           1.23644            15.27024\n",
       "26                0           1.23644            15.27024\n",
       "27                0           1.23644            15.27024\n",
       "28                0           1.23644            15.27024\n",
       "29                0           1.23644            15.27024\n",
       "...             ...               ...                 ...\n",
       "6041              0           1.23644            15.27024\n",
       "6042              2           1.23644            15.27024\n",
       "6043              7           1.23644            15.27024\n",
       "6044              0           1.23644            15.27024\n",
       "6045              0           1.23644            15.27024\n",
       "6046              0           1.23644            15.27024\n",
       "6047              0           1.23644            15.27024\n",
       "6048              8           1.23644            15.27024\n",
       "6049              0           1.23644            15.27024\n",
       "6050              0           1.23644            15.27024\n",
       "6051              0           1.23644            15.27024\n",
       "6052              0           1.23644            15.27024\n",
       "6053              1           1.23644            15.27024\n",
       "6054              0           1.23644            15.27024\n",
       "6055              0           1.23644            15.27024\n",
       "6056              0           1.23644            15.27024\n",
       "6057              0           1.23644            15.27024\n",
       "6058              2           1.23644            15.27024\n",
       "6059              0           1.23644            15.27024\n",
       "6060              0           1.23644            15.27024\n",
       "6061              0           1.23644            15.27024\n",
       "6062              1           1.23644            15.27024\n",
       "6063             33           1.23644            15.27024\n",
       "6064              1           1.23644            15.27024\n",
       "6065              2           1.23644            15.27024\n",
       "6066              0           1.23644            15.27024\n",
       "6067              0           1.23644            15.27024\n",
       "6068              0           1.23644            15.27024\n",
       "6069              1           1.23644            15.27024\n",
       "6070              1           1.23644            15.27024\n",
       "\n",
       "[6071 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Predicting the values for Helpful Votes on the test data \"\"\"\n",
    "y_pred_1 = regressor_1.predict(X_test)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against predicted values \"\"\"\n",
    "y_pred_1 = y_pred_1.reshape(6091,)\n",
    "temp_1 = {'Actual Values': y_test,'Predicted Values': y_pred_1}\n",
    "y_compare_1 = pd.DataFrame(temp_1)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN\"\"\"\n",
    "y_compare_1['Mean Squared Error'] = ((np.diff(y_compare_1.values) ** 2).mean() ** .5)\n",
    "y_compare_1.head(-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24362/24362 [==============================] - 5s 221us/step - loss: 2119.9938\n",
      "Epoch 2/100\n",
      "24362/24362 [==============================] - 5s 203us/step - loss: 2112.1743\n",
      "Epoch 3/100\n",
      "24362/24362 [==============================] - 5s 205us/step - loss: 2109.5409\n",
      "Epoch 4/100\n",
      "24362/24362 [==============================] - 5s 205us/step - loss: 2100.7813\n",
      "Epoch 5/100\n",
      "24362/24362 [==============================] - 5s 223us/step - loss: 2121.3702\n",
      "Epoch 6/100\n",
      "24362/24362 [==============================] - 6s 265us/step - loss: 2101.7492\n",
      "Epoch 7/100\n",
      "24362/24362 [==============================] - 6s 243us/step - loss: 2116.1138\n",
      "Epoch 8/100\n",
      "24362/24362 [==============================] - 6s 253us/step - loss: 2093.5740\n",
      "Epoch 9/100\n",
      "24362/24362 [==============================] - 5s 223us/step - loss: 2112.8190\n",
      "Epoch 10/100\n",
      "24362/24362 [==============================] - 5s 225us/step - loss: 2118.8175\n",
      "Epoch 11/100\n",
      "24362/24362 [==============================] - 5s 224us/step - loss: 2112.6232\n",
      "Epoch 12/100\n",
      "24362/24362 [==============================] - 6s 230us/step - loss: 2090.3064\n",
      "Epoch 13/100\n",
      "24362/24362 [==============================] - 5s 223us/step - loss: 2080.9652\n",
      "Epoch 14/100\n",
      "24362/24362 [==============================] - 5s 225us/step - loss: 2107.7483\n",
      "Epoch 15/100\n",
      "24362/24362 [==============================] - 5s 223us/step - loss: 2093.5271\n",
      "Epoch 16/100\n",
      "24362/24362 [==============================] - 7s 273us/step - loss: 2106.1513\n",
      "Epoch 17/100\n",
      "24362/24362 [==============================] - 7s 273us/step - loss: 2080.9039\n",
      "Epoch 18/100\n",
      "24362/24362 [==============================] - 6s 236us/step - loss: 2069.4864\n",
      "Epoch 19/100\n",
      "24362/24362 [==============================] - 6s 229us/step - loss: 2061.2803\n",
      "Epoch 20/100\n",
      "24362/24362 [==============================] - 5s 224us/step - loss: 2113.6677\n",
      "Epoch 21/100\n",
      "24362/24362 [==============================] - 5s 224us/step - loss: 2093.2706\n",
      "Epoch 22/100\n",
      "24362/24362 [==============================] - 5s 224us/step - loss: 2423.0647\n",
      "Epoch 23/100\n",
      "24362/24362 [==============================] - 6s 227us/step - loss: 2065.1125\n",
      "Epoch 24/100\n",
      "24362/24362 [==============================] - 6s 227us/step - loss: 2110.4232\n",
      "Epoch 25/100\n",
      "24362/24362 [==============================] - 5s 223us/step - loss: 2083.8535\n",
      "Epoch 26/100\n",
      "24362/24362 [==============================] - 5s 225us/step - loss: 2044.2594\n",
      "Epoch 27/100\n",
      "24362/24362 [==============================] - 5s 226us/step - loss: 2074.8972\n",
      "Epoch 28/100\n",
      "24362/24362 [==============================] - 5s 225us/step - loss: 2095.6169\n",
      "Epoch 29/100\n",
      "24362/24362 [==============================] - 5s 224us/step - loss: 2055.3769\n",
      "Epoch 30/100\n",
      "24362/24362 [==============================] - 5s 223us/step - loss: 2080.6382\n",
      "Epoch 31/100\n",
      "24362/24362 [==============================] - 5s 225us/step - loss: 13228.8440\n",
      "Epoch 32/100\n",
      "24362/24362 [==============================] - 5s 224us/step - loss: 2041.0601\n",
      "Epoch 33/100\n",
      "24362/24362 [==============================] - 5s 224us/step - loss: 2031.0358\n",
      "Epoch 34/100\n",
      "24362/24362 [==============================] - 5s 225us/step - loss: 2053.9390\n",
      "Epoch 35/100\n",
      "24362/24362 [==============================] - 5s 225us/step - loss: 2083.8444\n",
      "Epoch 36/100\n",
      "24362/24362 [==============================] - 6s 227us/step - loss: 379458.3856\n",
      "Epoch 37/100\n",
      "24362/24362 [==============================] - 5s 225us/step - loss: 2073.5643\n",
      "Epoch 38/100\n",
      "24362/24362 [==============================] - 5s 225us/step - loss: 2068.8425\n",
      "Epoch 39/100\n",
      "24362/24362 [==============================] - 5s 225us/step - loss: 2046.1362\n",
      "Epoch 40/100\n",
      "24362/24362 [==============================] - 6s 227us/step - loss: 2094.4633\n",
      "Epoch 41/100\n",
      "24362/24362 [==============================] - 5s 225us/step - loss: 2063.3815\n",
      "Epoch 42/100\n",
      "24362/24362 [==============================] - 5s 225us/step - loss: 2058.3470\n",
      "Epoch 43/100\n",
      "24362/24362 [==============================] - 6s 257us/step - loss: 72908.2809\n",
      "Epoch 44/100\n",
      "24362/24362 [==============================] - 6s 248us/step - loss: 2046.1420\n",
      "Epoch 45/100\n",
      "24362/24362 [==============================] - 6s 231us/step - loss: 2061.6780\n",
      "Epoch 46/100\n",
      "24362/24362 [==============================] - 6s 228us/step - loss: 102516.5825\n",
      "Epoch 47/100\n",
      "24362/24362 [==============================] - 6s 230us/step - loss: 2025.1431\n",
      "Epoch 48/100\n",
      "24362/24362 [==============================] - 6s 234us/step - loss: 2065.9964\n",
      "Epoch 49/100\n",
      "24362/24362 [==============================] - 6s 229us/step - loss: 2046.3402\n",
      "Epoch 50/100\n",
      "24362/24362 [==============================] - 6s 228us/step - loss: 2083.3961\n",
      "Epoch 51/100\n",
      "24362/24362 [==============================] - 6s 233us/step - loss: 2056.4937\n",
      "Epoch 52/100\n",
      "24362/24362 [==============================] - 6s 229us/step - loss: 5973229.0925\n",
      "Epoch 53/100\n",
      "24362/24362 [==============================] - 6s 227us/step - loss: 2092.5227\n",
      "Epoch 54/100\n",
      "24362/24362 [==============================] - 6s 228us/step - loss: 2092.6702\n",
      "Epoch 55/100\n",
      "24362/24362 [==============================] - 6s 226us/step - loss: 2107.3959\n",
      "Epoch 56/100\n",
      "24362/24362 [==============================] - 6s 227us/step - loss: 2102.9718\n",
      "Epoch 57/100\n",
      "24362/24362 [==============================] - 6s 229us/step - loss: 2076.5708\n",
      "Epoch 58/100\n",
      "24362/24362 [==============================] - 6s 229us/step - loss: 1210203.7283\n",
      "Epoch 59/100\n",
      "24362/24362 [==============================] - 6s 228us/step - loss: 2097.4769\n",
      "Epoch 60/100\n",
      "24362/24362 [==============================] - 6s 229us/step - loss: 2085.8608\n",
      "Epoch 61/100\n",
      "24362/24362 [==============================] - 6s 230us/step - loss: 2861155.9561\n",
      "Epoch 62/100\n",
      "24362/24362 [==============================] - 6s 228us/step - loss: 2061.8387\n",
      "Epoch 63/100\n",
      "24362/24362 [==============================] - 6s 229us/step - loss: 2065.8327\n",
      "Epoch 64/100\n",
      "24362/24362 [==============================] - 6s 229us/step - loss: 2089.1964\n",
      "Epoch 65/100\n",
      "24362/24362 [==============================] - 6s 226us/step - loss: 2143.5193\n",
      "Epoch 66/100\n",
      "24362/24362 [==============================] - 6s 232us/step - loss: 2017.1714\n",
      "Epoch 67/100\n",
      "24362/24362 [==============================] - 6s 227us/step - loss: 3289.4228\n",
      "Epoch 68/100\n",
      "24362/24362 [==============================] - 6s 227us/step - loss: 2122.8422\n",
      "Epoch 69/100\n",
      "24362/24362 [==============================] - 6s 227us/step - loss: 2114.9081\n",
      "Epoch 70/100\n",
      "24362/24362 [==============================] - 6s 228us/step - loss: 2147.5267\n",
      "Epoch 71/100\n",
      "24362/24362 [==============================] - 6s 231us/step - loss: 2075.9887\n",
      "Epoch 72/100\n",
      "24362/24362 [==============================] - 6s 246us/step - loss: 2098.2078\n",
      "Epoch 73/100\n",
      "24362/24362 [==============================] - 6s 246us/step - loss: 2302.7989\n",
      "Epoch 74/100\n",
      "24362/24362 [==============================] - 6s 228us/step - loss: 2075.3750\n",
      "Epoch 75/100\n",
      "24362/24362 [==============================] - 6s 227us/step - loss: 2093.7489\n",
      "Epoch 76/100\n",
      "24362/24362 [==============================] - 6s 230us/step - loss: 15821.9150\n",
      "Epoch 77/100\n",
      "24362/24362 [==============================] - 6s 233us/step - loss: 2073.6957\n",
      "Epoch 78/100\n",
      "24362/24362 [==============================] - 6s 230us/step - loss: 1972.1872\n",
      "Epoch 79/100\n",
      "24362/24362 [==============================] - 6s 228us/step - loss: 2085.5162\n",
      "Epoch 80/100\n",
      "24362/24362 [==============================] - 6s 228us/step - loss: 5202904.2446\n",
      "Epoch 81/100\n",
      "24362/24362 [==============================] - 6s 231us/step - loss: 2383.5921\n",
      "Epoch 82/100\n",
      "24362/24362 [==============================] - 6s 233us/step - loss: 2101.3353\n",
      "Epoch 83/100\n",
      "24362/24362 [==============================] - 6s 230us/step - loss: 2075.4777\n",
      "Epoch 84/100\n",
      "24362/24362 [==============================] - 6s 233us/step - loss: 2098.5403\n",
      "Epoch 85/100\n",
      "24362/24362 [==============================] - 6s 230us/step - loss: 2090.6872\n",
      "Epoch 86/100\n",
      "24362/24362 [==============================] - 6s 231us/step - loss: 2122.9758\n",
      "Epoch 87/100\n",
      "24362/24362 [==============================] - 6s 230us/step - loss: 8433.0878\n",
      "Epoch 88/100\n",
      "24362/24362 [==============================] - 6s 233us/step - loss: 2061.8993\n",
      "Epoch 89/100\n",
      "24362/24362 [==============================] - 6s 228us/step - loss: 2116.0501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "24362/24362 [==============================] - 5s 219us/step - loss: 2196.9392\n",
      "Epoch 91/100\n",
      "24362/24362 [==============================] - 5s 220us/step - loss: 2072.4282\n",
      "Epoch 92/100\n",
      "24362/24362 [==============================] - 5s 220us/step - loss: 54950399.9232\n",
      "Epoch 93/100\n",
      "24362/24362 [==============================] - 5s 219us/step - loss: 2136.0558\n",
      "Epoch 94/100\n",
      "24362/24362 [==============================] - 5s 218us/step - loss: 2078.2422\n",
      "Epoch 95/100\n",
      "24362/24362 [==============================] - 5s 218us/step - loss: 2036.5795\n",
      "Epoch 96/100\n",
      "24362/24362 [==============================] - 5s 219us/step - loss: 2055.9212\n",
      "Epoch 97/100\n",
      "24362/24362 [==============================] - 5s 224us/step - loss: 2043.3981\n",
      "Epoch 98/100\n",
      "24362/24362 [==============================] - 6s 237us/step - loss: 2068.3993\n",
      "Epoch 99/100\n",
      "24362/24362 [==============================] - 6s 228us/step - loss: 2121.2547\n",
      "Epoch 100/100\n",
      "24362/24362 [==============================] - 5s 225us/step - loss: 2093.3453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c345fc8e80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Building a deep and wide ANN with high number of nodes \"\"\"\n",
    "\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "regressor_2 = Sequential()\n",
    "regressor_2.add(Dense(50, kernel_initializer = 'normal',input_dim = 7))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(100, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(200, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(100, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(50, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(20, kernel_initializer = 'normal'))\n",
    "regressor_2.add(LeakyReLU(alpha=0.05))\n",
    "regressor_2.add(Dense(1, kernel_initializer = 'normal'))\n",
    "\n",
    "\"\"\" Compiling the regressor \"\"\"\n",
    "regressor_2.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "\"\"\" Fitting the Artifilial Neural Network to our training data \"\"\"\n",
    "regressor_2.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.521215</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.706998</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.457158</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.389343</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.278412</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.168786</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.789794</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.511756</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.979642</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0.707419</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.581238</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0.350277</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.802967</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.250975</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.733216</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.510103</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.142097</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>6.115778</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0.075755</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0.883215</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.435312</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12</td>\n",
       "      <td>1.100290</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0.546869</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0.068324</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0.544905</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0.731185</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0.242653</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0.946087</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0.482518</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0.848592</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6041</th>\n",
       "      <td>0</td>\n",
       "      <td>0.325729</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6042</th>\n",
       "      <td>2</td>\n",
       "      <td>0.749274</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>7</td>\n",
       "      <td>6.685916</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6044</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.288976</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6045</th>\n",
       "      <td>0</td>\n",
       "      <td>0.684041</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6046</th>\n",
       "      <td>0</td>\n",
       "      <td>0.318143</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6047</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.036463</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6048</th>\n",
       "      <td>8</td>\n",
       "      <td>0.450840</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049</th>\n",
       "      <td>0</td>\n",
       "      <td>0.516143</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6050</th>\n",
       "      <td>0</td>\n",
       "      <td>0.512131</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6051</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.019842</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6052</th>\n",
       "      <td>0</td>\n",
       "      <td>0.992813</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6053</th>\n",
       "      <td>1</td>\n",
       "      <td>0.402910</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6054</th>\n",
       "      <td>0</td>\n",
       "      <td>0.725623</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6055</th>\n",
       "      <td>0</td>\n",
       "      <td>0.359190</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6056</th>\n",
       "      <td>0</td>\n",
       "      <td>0.916548</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6057</th>\n",
       "      <td>0</td>\n",
       "      <td>0.305466</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6058</th>\n",
       "      <td>2</td>\n",
       "      <td>4.186343</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6059</th>\n",
       "      <td>0</td>\n",
       "      <td>0.310738</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6060</th>\n",
       "      <td>0</td>\n",
       "      <td>0.551270</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6061</th>\n",
       "      <td>0</td>\n",
       "      <td>0.609394</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>1</td>\n",
       "      <td>0.459345</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>33</td>\n",
       "      <td>102.945564</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>1</td>\n",
       "      <td>1.336434</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>2</td>\n",
       "      <td>0.256507</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>0</td>\n",
       "      <td>0.567934</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6067</th>\n",
       "      <td>0</td>\n",
       "      <td>0.730871</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6068</th>\n",
       "      <td>0</td>\n",
       "      <td>0.448889</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6069</th>\n",
       "      <td>1</td>\n",
       "      <td>0.666302</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6070</th>\n",
       "      <td>1</td>\n",
       "      <td>0.202780</td>\n",
       "      <td>14.665057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6071 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual Values  Predicted Values  Mean Squared Error\n",
       "0                 1         -0.521215           14.665057\n",
       "1                 0          0.706998           14.665057\n",
       "2                 0          0.457158           14.665057\n",
       "3                 0         -0.389343           14.665057\n",
       "4                 0         -0.278412           14.665057\n",
       "5                 0          0.168786           14.665057\n",
       "6                 0         -1.789794           14.665057\n",
       "7                 0          0.511756           14.665057\n",
       "8                 0         -0.979642           14.665057\n",
       "9                 1          0.707419           14.665057\n",
       "10                0          0.581238           14.665057\n",
       "11                1          0.350277           14.665057\n",
       "12                1          0.802967           14.665057\n",
       "13                0         -0.250975           14.665057\n",
       "14                0          0.733216           14.665057\n",
       "15                0          0.510103           14.665057\n",
       "16                1         -0.142097           14.665057\n",
       "17                1          6.115778           14.665057\n",
       "18                0          0.075755           14.665057\n",
       "19                0          0.883215           14.665057\n",
       "20                0          0.435312           14.665057\n",
       "21               12          1.100290           14.665057\n",
       "22                1          0.546869           14.665057\n",
       "23                0          0.068324           14.665057\n",
       "24                0          0.544905           14.665057\n",
       "25                0          0.731185           14.665057\n",
       "26                0          0.242653           14.665057\n",
       "27                0          0.946087           14.665057\n",
       "28                0          0.482518           14.665057\n",
       "29                0          0.848592           14.665057\n",
       "...             ...               ...                 ...\n",
       "6041              0          0.325729           14.665057\n",
       "6042              2          0.749274           14.665057\n",
       "6043              7          6.685916           14.665057\n",
       "6044              0         -0.288976           14.665057\n",
       "6045              0          0.684041           14.665057\n",
       "6046              0          0.318143           14.665057\n",
       "6047              0         -0.036463           14.665057\n",
       "6048              8          0.450840           14.665057\n",
       "6049              0          0.516143           14.665057\n",
       "6050              0          0.512131           14.665057\n",
       "6051              0         -0.019842           14.665057\n",
       "6052              0          0.992813           14.665057\n",
       "6053              1          0.402910           14.665057\n",
       "6054              0          0.725623           14.665057\n",
       "6055              0          0.359190           14.665057\n",
       "6056              0          0.916548           14.665057\n",
       "6057              0          0.305466           14.665057\n",
       "6058              2          4.186343           14.665057\n",
       "6059              0          0.310738           14.665057\n",
       "6060              0          0.551270           14.665057\n",
       "6061              0          0.609394           14.665057\n",
       "6062              1          0.459345           14.665057\n",
       "6063             33        102.945564           14.665057\n",
       "6064              1          1.336434           14.665057\n",
       "6065              2          0.256507           14.665057\n",
       "6066              0          0.567934           14.665057\n",
       "6067              0          0.730871           14.665057\n",
       "6068              0          0.448889           14.665057\n",
       "6069              1          0.666302           14.665057\n",
       "6070              1          0.202780           14.665057\n",
       "\n",
       "[6071 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Predicting the values for Helpful Votes on the test data \"\"\"\n",
    "y_pred_2 = regressor_2.predict(X_test)\n",
    "\n",
    "\"\"\" Creating a dataframe to compare the actual values against predicted values \"\"\"\n",
    "y_pred_2 = y_pred_2.reshape(6091,)\n",
    "temp_2 = {'Actual Values': y_test,'Predicted Values': y_pred_2}\n",
    "y_compare_2 = pd.DataFrame(temp_2)\n",
    "\n",
    "\"\"\" Calculating the Mean Squared Error to estimate the efficiency of the ANN\"\"\"\n",
    "y_compare_2['Mean Squared Error'] = ((np.diff(y_compare_1.values) ** 2).mean() ** .5)\n",
    "y_compare_2.head(-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
