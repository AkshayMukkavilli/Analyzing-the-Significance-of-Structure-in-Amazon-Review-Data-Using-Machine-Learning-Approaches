{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Z_Score_Words</th>\n",
       "      <th>Paragraphs</th>\n",
       "      <th>No.break tags</th>\n",
       "      <th>Percentage_Upper_Case</th>\n",
       "      <th>Percentage_Lower_Case</th>\n",
       "      <th>Avg_len_paragraph_per_review</th>\n",
       "      <th>Z_Score_HelpfulVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>6.453577</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "      <td>3087.000000</td>\n",
       "      <td>-0.235881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1.394079</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.915696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3.666459</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>468.500000</td>\n",
       "      <td>1.491485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8.525083</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>394.272727</td>\n",
       "      <td>5.522007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.795826</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>91</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>0.339908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stars  Z_Score_Words  Paragraphs  No.break tags  Percentage_Upper_Case  \\\n",
       "0      3       6.453577           1              0                      3   \n",
       "1      5       1.394079           3              4                      3   \n",
       "2      4       3.666459           4              6                      4   \n",
       "3      4       8.525083          11             20                      3   \n",
       "4      5       1.795826           2              1                      6   \n",
       "\n",
       "   Percentage_Lower_Case  Avg_len_paragraph_per_review  Z_Score_HelpfulVotes  \n",
       "0                     93                   3087.000000             -0.235881  \n",
       "1                     91                    300.000000              0.915696  \n",
       "2                     90                    468.500000              1.491485  \n",
       "3                     91                    394.272727              5.522007  \n",
       "4                     91                    492.000000              0.339908  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(r'C:\\Users\\aksha\\PycharmProjects\\FinalProject_WorkingCopy\\FinalFeatures.csv')\n",
    "dataset = dataset.drop(['Date','Helpful Votes','Words'],axis=1)\n",
    "dataset = dataset[['Stars','Z_Score_Words', 'Paragraphs','No.break tags','Percentage_Upper_Case','Percentage_Lower_Case','Avg_len_paragraph_per_review','Z_Score_HelpfulVotes']]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Z_Score_Words</th>\n",
       "      <th>Paragraphs</th>\n",
       "      <th>No.break tags</th>\n",
       "      <th>Percentage_Upper_Case</th>\n",
       "      <th>Percentage_Lower_Case</th>\n",
       "      <th>Avg_len_paragraph_per_review</th>\n",
       "      <th>Z_Score_HelpfulVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.315262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.417478</td>\n",
       "      <td>0.000484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.091377</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.026846</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.040449</td>\n",
       "      <td>0.025593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.191931</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.040268</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.063244</td>\n",
       "      <td>0.038147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.406928</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>0.134228</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.053202</td>\n",
       "      <td>0.126026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.109154</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.066423</td>\n",
       "      <td>0.013038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stars  Z_Score_Words  Paragraphs  No.break tags  Percentage_Upper_Case  \\\n",
       "0   0.50       0.315262    0.000000       0.000000                   0.03   \n",
       "1   1.00       0.091377    0.015873       0.026846                   0.03   \n",
       "2   0.75       0.191931    0.023810       0.040268                   0.04   \n",
       "3   0.75       0.406928    0.079365       0.134228                   0.03   \n",
       "4   1.00       0.109154    0.007937       0.006711                   0.06   \n",
       "\n",
       "   Percentage_Lower_Case  Avg_len_paragraph_per_review  Z_Score_HelpfulVotes  \n",
       "0                   0.93                      0.417478              0.000484  \n",
       "1                   0.91                      0.040449              0.025593  \n",
       "2                   0.90                      0.063244              0.038147  \n",
       "3                   0.91                      0.053202              0.126026  \n",
       "4                   0.91                      0.066423              0.013038  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "dataset_new = scaler.fit_transform(dataset)\n",
    "dataset_new = pd.DataFrame(dataset_new,columns=dataset.columns)\n",
    "dataset_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dataset_new.iloc[:,0:-1].values\n",
    "y = dataset_new.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to use StandardScaler for scaling the data instead of MinMaxScaler, this code can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regressor = Sequential()\n",
    "regressor.add(Dense(6, kernel_initializer = 'uniform',activation = 'relu',input_dim = 7))\n",
    "regressor.add(Dense(4, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "regressor.add(Dense(1, kernel_initializer = 'uniform'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dense class that we've imported above will help us initilize the neural network with small weights close to 0 but not 0\n",
    "\n",
    "We did not provide any activation function in the output layer since we are not classifying the data. For classification, we need to provide an activation function for the output layer, whereas we do not need to provide one for regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we will compile the regressor\n",
    "\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24362/24362 [==============================] - 6s 227us/step - loss: 1.1877e-04 - acc: 0.3445\n",
      "Epoch 2/100\n",
      "24362/24362 [==============================] - 3s 134us/step - loss: 7.0549e-05 - acc: 0.3445\n",
      "Epoch 3/100\n",
      "24362/24362 [==============================] - 3s 135us/step - loss: 7.2124e-05 - acc: 0.3445\n",
      "Epoch 4/100\n",
      "24362/24362 [==============================] - 3s 134us/step - loss: 6.7934e-05 - acc: 0.3445\n",
      "Epoch 5/100\n",
      "24362/24362 [==============================] - 3s 136us/step - loss: 6.6138e-05 - acc: 0.3445\n",
      "Epoch 6/100\n",
      "24362/24362 [==============================] - 3s 134us/step - loss: 6.3972e-05 - acc: 0.3446\n",
      "Epoch 7/100\n",
      "24362/24362 [==============================] - 3s 134us/step - loss: 6.1439e-05 - acc: 0.3445\n",
      "Epoch 8/100\n",
      "24362/24362 [==============================] - 3s 134us/step - loss: 6.3673e-05 - acc: 0.3445\n",
      "Epoch 9/100\n",
      "24362/24362 [==============================] - 3s 137us/step - loss: 6.0529e-05 - acc: 0.3445\n",
      "Epoch 10/100\n",
      "24362/24362 [==============================] - 3s 137us/step - loss: 5.9624e-05 - acc: 0.3445\n",
      "Epoch 11/100\n",
      "24362/24362 [==============================] - 3s 137us/step - loss: 5.7738e-05 - acc: 0.3445\n",
      "Epoch 12/100\n",
      "24362/24362 [==============================] - 3s 136us/step - loss: 5.5169e-05 - acc: 0.3445\n",
      "Epoch 13/100\n",
      "24362/24362 [==============================] - 3s 134us/step - loss: 5.4089e-05 - acc: 0.3445\n",
      "Epoch 14/100\n",
      "24362/24362 [==============================] - 3s 135us/step - loss: 4.8486e-05 - acc: 0.3446\n",
      "Epoch 15/100\n",
      "24362/24362 [==============================] - 3s 135us/step - loss: 4.8746e-05 - acc: 0.3446\n",
      "Epoch 16/100\n",
      "24362/24362 [==============================] - 3s 135us/step - loss: 4.7727e-05 - acc: 0.3445\n",
      "Epoch 17/100\n",
      "24362/24362 [==============================] - 3s 134us/step - loss: 4.8324e-05 - acc: 0.3446\n",
      "Epoch 18/100\n",
      "24362/24362 [==============================] - 3s 135us/step - loss: 4.3137e-05 - acc: 0.3445\n",
      "Epoch 19/100\n",
      "24362/24362 [==============================] - 3s 135us/step - loss: 4.5693e-05 - acc: 0.3445\n",
      "Epoch 20/100\n",
      "24362/24362 [==============================] - 3s 133us/step - loss: 4.4388e-05 - acc: 0.3445\n",
      "Epoch 21/100\n",
      "24362/24362 [==============================] - 3s 135us/step - loss: 4.5173e-05 - acc: 0.3445\n",
      "Epoch 22/100\n",
      "24362/24362 [==============================] - 3s 134us/step - loss: 4.0099e-05 - acc: 0.3445\n",
      "Epoch 23/100\n",
      "24362/24362 [==============================] - 3s 134us/step - loss: 4.2277e-05 - acc: 0.3446\n",
      "Epoch 24/100\n",
      "24362/24362 [==============================] - 3s 135us/step - loss: 3.9274e-05 - acc: 0.3446\n",
      "Epoch 25/100\n",
      "24362/24362 [==============================] - 3s 134us/step - loss: 3.9510e-05 - acc: 0.3445\n",
      "Epoch 26/100\n",
      "24362/24362 [==============================] - 3s 136us/step - loss: 4.3754e-05 - acc: 0.3445\n",
      "Epoch 27/100\n",
      "24362/24362 [==============================] - 3s 135us/step - loss: 4.1261e-05 - acc: 0.3445\n",
      "Epoch 28/100\n",
      "24362/24362 [==============================] - 3s 134us/step - loss: 3.8013e-05 - acc: 0.3446\n",
      "Epoch 29/100\n",
      "24362/24362 [==============================] - 3s 136us/step - loss: 4.7689e-05 - acc: 0.3445\n",
      "Epoch 30/100\n",
      "24362/24362 [==============================] - 3s 135us/step - loss: 3.8326e-05 - acc: 0.3445\n",
      "Epoch 31/100\n",
      "24362/24362 [==============================] - 3s 134us/step - loss: 3.6803e-05 - acc: 0.3446\n",
      "Epoch 32/100\n",
      "24362/24362 [==============================] - 3s 136us/step - loss: 3.5360e-05 - acc: 0.3446\n",
      "Epoch 33/100\n",
      "24362/24362 [==============================] - 3s 135us/step - loss: 4.3449e-05 - acc: 0.3446\n",
      "Epoch 34/100\n",
      "24362/24362 [==============================] - 4s 154us/step - loss: 3.7605e-05 - acc: 0.3446\n",
      "Epoch 35/100\n",
      "24362/24362 [==============================] - 3s 143us/step - loss: 3.9523e-05 - acc: 0.3445\n",
      "Epoch 36/100\n",
      "24362/24362 [==============================] - 3s 134us/step - loss: 4.0600e-05 - acc: 0.3445\n",
      "Epoch 37/100\n",
      "24362/24362 [==============================] - 4s 148us/step - loss: 3.6927e-05 - acc: 0.3446\n",
      "Epoch 38/100\n",
      "24362/24362 [==============================] - 3s 134us/step - loss: 3.9065e-05 - acc: 0.3446\n",
      "Epoch 39/100\n",
      "24362/24362 [==============================] - 4s 149us/step - loss: 3.7132e-05 - acc: 0.3446\n",
      "Epoch 40/100\n",
      "24362/24362 [==============================] - 4s 146us/step - loss: 3.9864e-05 - acc: 0.3446\n",
      "Epoch 41/100\n",
      "24362/24362 [==============================] - 4s 153us/step - loss: 3.7608e-05 - acc: 0.3446\n",
      "Epoch 42/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 4.1815e-05 - acc: 0.3445\n",
      "Epoch 43/100\n",
      "24362/24362 [==============================] - 3s 143us/step - loss: 3.3556e-05 - acc: 0.3446\n",
      "Epoch 44/100\n",
      "24362/24362 [==============================] - 3s 137us/step - loss: 3.8281e-05 - acc: 0.3446\n",
      "Epoch 45/100\n",
      "24362/24362 [==============================] - 3s 138us/step - loss: 3.3521e-05 - acc: 0.3446\n",
      "Epoch 46/100\n",
      "24362/24362 [==============================] - 4s 155us/step - loss: 3.5823e-05 - acc: 0.3446\n",
      "Epoch 47/100\n",
      "24362/24362 [==============================] - 4s 156us/step - loss: 3.5485e-05 - acc: 0.3446\n",
      "Epoch 48/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 3.7039e-05 - acc: 0.3445\n",
      "Epoch 49/100\n",
      "24362/24362 [==============================] - 3s 136us/step - loss: 3.3667e-05 - acc: 0.3446\n",
      "Epoch 50/100\n",
      "24362/24362 [==============================] - 4s 151us/step - loss: 3.7092e-05 - acc: 0.3446\n",
      "Epoch 51/100\n",
      "24362/24362 [==============================] - 4s 152us/step - loss: 3.8502e-05 - acc: 0.3445\n",
      "Epoch 52/100\n",
      "24362/24362 [==============================] - 4s 148us/step - loss: 3.7300e-05 - acc: 0.3446\n",
      "Epoch 53/100\n",
      "24362/24362 [==============================] - 4s 156us/step - loss: 3.7972e-05 - acc: 0.3446\n",
      "Epoch 54/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 3.4560e-05 - acc: 0.3445\n",
      "Epoch 55/100\n",
      "24362/24362 [==============================] - 4s 168us/step - loss: 3.3362e-05 - acc: 0.3445\n",
      "Epoch 56/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 3.5217e-05 - acc: 0.3446\n",
      "Epoch 57/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 3.2639e-05 - acc: 0.3446\n",
      "Epoch 58/100\n",
      "24362/24362 [==============================] - 3s 137us/step - loss: 4.0225e-05 - acc: 0.3445\n",
      "Epoch 59/100\n",
      "24362/24362 [==============================] - 3s 141us/step - loss: 3.9381e-05 - acc: 0.3446\n",
      "Epoch 60/100\n",
      "24362/24362 [==============================] - 4s 147us/step - loss: 3.4333e-05 - acc: 0.3446\n",
      "Epoch 61/100\n",
      "24362/24362 [==============================] - 4s 155us/step - loss: 3.3816e-05 - acc: 0.3446\n",
      "Epoch 62/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 3.4798e-05 - acc: 0.3445\n",
      "Epoch 63/100\n",
      "24362/24362 [==============================] - 3s 138us/step - loss: 3.7729e-05 - acc: 0.3445\n",
      "Epoch 64/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 3.2702e-05 - acc: 0.3445\n",
      "Epoch 65/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 3.4601e-05 - acc: 0.3446\n",
      "Epoch 66/100\n",
      "24362/24362 [==============================] - 3s 143us/step - loss: 3.1797e-05 - acc: 0.3446\n",
      "Epoch 67/100\n",
      "24362/24362 [==============================] - 4s 148us/step - loss: 3.3828e-05 - acc: 0.3446\n",
      "Epoch 68/100\n",
      "24362/24362 [==============================] - 4s 148us/step - loss: 3.4905e-05 - acc: 0.3445\n",
      "Epoch 69/100\n",
      "24362/24362 [==============================] - 4s 148us/step - loss: 3.7757e-05 - acc: 0.3445\n",
      "Epoch 70/100\n",
      "24362/24362 [==============================] - 4s 144us/step - loss: 3.6246e-05 - acc: 0.3445\n",
      "Epoch 71/100\n",
      "24362/24362 [==============================] - 4s 144us/step - loss: 2.9669e-05 - acc: 0.3445\n",
      "Epoch 72/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 3.0294e-05 - acc: 0.3446\n",
      "Epoch 73/100\n",
      "24362/24362 [==============================] - 3s 136us/step - loss: 3.3550e-05 - acc: 0.3446\n",
      "Epoch 74/100\n",
      "24362/24362 [==============================] - 3s 136us/step - loss: 3.2683e-05 - acc: 0.3446\n",
      "Epoch 75/100\n",
      "24362/24362 [==============================] - 3s 136us/step - loss: 3.3184e-05 - acc: 0.3446\n",
      "Epoch 76/100\n",
      "24362/24362 [==============================] - 3s 136us/step - loss: 3.3712e-05 - acc: 0.3445\n",
      "Epoch 77/100\n",
      "24362/24362 [==============================] - 3s 143us/step - loss: 3.3478e-05 - acc: 0.3446\n",
      "Epoch 78/100\n",
      "24362/24362 [==============================] - 3s 138us/step - loss: 3.3475e-05 - acc: 0.3446\n",
      "Epoch 79/100\n",
      "24362/24362 [==============================] - 3s 141us/step - loss: 3.1674e-05 - acc: 0.3446\n",
      "Epoch 80/100\n",
      "24362/24362 [==============================] - 3s 141us/step - loss: 3.0746e-05 - acc: 0.3446\n",
      "Epoch 81/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 3.5609e-05 - acc: 0.3446\n",
      "Epoch 82/100\n",
      "24362/24362 [==============================] - 3s 137us/step - loss: 2.7349e-05 - acc: 0.3446\n",
      "Epoch 83/100\n",
      "24362/24362 [==============================] - 3s 136us/step - loss: 3.0589e-05 - acc: 0.3446\n",
      "Epoch 84/100\n",
      "24362/24362 [==============================] - 3s 137us/step - loss: 3.0546e-05 - acc: 0.3445\n",
      "Epoch 85/100\n",
      "24362/24362 [==============================] - 3s 136us/step - loss: 3.0710e-05 - acc: 0.3446\n",
      "Epoch 86/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 3.1262e-05 - acc: 0.3446\n",
      "Epoch 87/100\n",
      "24362/24362 [==============================] - 3s 136us/step - loss: 3.0042e-05 - acc: 0.3446\n",
      "Epoch 88/100\n",
      "24362/24362 [==============================] - 3s 136us/step - loss: 3.2816e-05 - acc: 0.3445\n",
      "Epoch 89/100\n",
      "24362/24362 [==============================] - 3s 136us/step - loss: 3.1014e-05 - acc: 0.3446\n",
      "Epoch 90/100\n",
      "24362/24362 [==============================] - 3s 138us/step - loss: 3.1189e-05 - acc: 0.3446\n",
      "Epoch 91/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 3.3644e-05 - acc: 0.3445\n",
      "Epoch 92/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 3.2874e-05 - acc: 0.3446\n",
      "Epoch 93/100\n",
      "24362/24362 [==============================] - 3s 144us/step - loss: 2.9870e-05 - acc: 0.3446\n",
      "Epoch 94/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 3.2731e-05 - acc: 0.3445\n",
      "Epoch 95/100\n",
      "24362/24362 [==============================] - 3s 136us/step - loss: 3.4425e-05 - acc: 0.3446\n",
      "Epoch 96/100\n",
      "24362/24362 [==============================] - 3s 136us/step - loss: 3.6089e-05 - acc: 0.3446\n",
      "Epoch 97/100\n",
      "24362/24362 [==============================] - 3s 138us/step - loss: 3.3538e-05 - acc: 0.3445\n",
      "Epoch 98/100\n",
      "24362/24362 [==============================] - 3s 137us/step - loss: 2.9328e-05 - acc: 0.3446\n",
      "Epoch 99/100\n",
      "24362/24362 [==============================] - 3s 137us/step - loss: 2.6989e-05 - acc: 0.3446\n",
      "Epoch 100/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 3.1433e-05 - acc: 0.3445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f734aefa90>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the Artifilial Neural Network to our training data\n",
    "regressor.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_deep_network = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_deep_network=y_pred_deep_network.reshape(6091,)\n",
    "temp={'Actual Values': y_test,'Predicted Values': y_pred_deep_network}\n",
    "y_compare= pd.DataFrame(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_compare['Mean Squared Error'] = ((np.diff(y_compare.values) ** 2).mean() ** .5)\n",
    "y_compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24362/24362 [==============================] - 4s 147us/step - loss: 1.7362e-04 - acc: 0.3445\n",
      "Epoch 2/100\n",
      "24362/24362 [==============================] - 3s 138us/step - loss: 8.2735e-05 - acc: 0.3445\n",
      "Epoch 3/100\n",
      "24362/24362 [==============================] - 3s 138us/step - loss: 7.3504e-05 - acc: 0.3445\n",
      "Epoch 4/100\n",
      "24362/24362 [==============================] - 3s 138us/step - loss: 7.2215e-05 - acc: 0.3445\n",
      "Epoch 5/100\n",
      "24362/24362 [==============================] - 3s 142us/step - loss: 6.9295e-05 - acc: 0.3445\n",
      "Epoch 6/100\n",
      "24362/24362 [==============================] - 3s 137us/step - loss: 7.0144e-05 - acc: 0.3445\n",
      "Epoch 7/100\n",
      "24362/24362 [==============================] - 4s 146us/step - loss: 6.7433e-05 - acc: 0.3445\n",
      "Epoch 8/100\n",
      "24362/24362 [==============================] - 4s 144us/step - loss: 6.3706e-05 - acc: 0.3445\n",
      "Epoch 9/100\n",
      "24362/24362 [==============================] - 4s 145us/step - loss: 6.6123e-05 - acc: 0.3445\n",
      "Epoch 10/100\n",
      "24362/24362 [==============================] - 3s 142us/step - loss: 6.3914e-05 - acc: 0.3445\n",
      "Epoch 11/100\n",
      "24362/24362 [==============================] - 3s 137us/step - loss: 5.9885e-05 - acc: 0.3446\n",
      "Epoch 12/100\n",
      "24362/24362 [==============================] - 3s 138us/step - loss: 6.3136e-05 - acc: 0.3445\n",
      "Epoch 13/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 6.2616e-05 - acc: 0.3446\n",
      "Epoch 14/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 6.3483e-05 - acc: 0.3445\n",
      "Epoch 15/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 6.1144e-05 - acc: 0.3445\n",
      "Epoch 16/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 5.7693e-05 - acc: 0.3446\n",
      "Epoch 17/100\n",
      "24362/24362 [==============================] - 3s 143us/step - loss: 6.0727e-05 - acc: 0.3446\n",
      "Epoch 18/100\n",
      "24362/24362 [==============================] - 4s 147us/step - loss: 5.7828e-05 - acc: 0.3446\n",
      "Epoch 19/100\n",
      "24362/24362 [==============================] - 3s 138us/step - loss: 6.0374e-05 - acc: 0.3445\n",
      "Epoch 20/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 5.8806e-05 - acc: 0.3445\n",
      "Epoch 21/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 5.8551e-05 - acc: 0.3446\n",
      "Epoch 22/100\n",
      "24362/24362 [==============================] - 3s 142us/step - loss: 5.6732e-05 - acc: 0.3446\n",
      "Epoch 23/100\n",
      "24362/24362 [==============================] - 3s 137us/step - loss: 5.8770e-05 - acc: 0.3445\n",
      "Epoch 24/100\n",
      "24362/24362 [==============================] - 3s 138us/step - loss: 5.7320e-05 - acc: 0.3446\n",
      "Epoch 25/100\n",
      "24362/24362 [==============================] - 3s 138us/step - loss: 5.0875e-05 - acc: 0.3446\n",
      "Epoch 26/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 5.1741e-05 - acc: 0.3446\n",
      "Epoch 27/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 4.8208e-05 - acc: 0.3445\n",
      "Epoch 28/100\n",
      "24362/24362 [==============================] - 3s 136us/step - loss: 4.8755e-05 - acc: 0.3446\n",
      "Epoch 29/100\n",
      "24362/24362 [==============================] - 3s 138us/step - loss: 4.9783e-05 - acc: 0.3445\n",
      "Epoch 30/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 4.4398e-05 - acc: 0.3446\n",
      "Epoch 31/100\n",
      "24362/24362 [==============================] - 3s 137us/step - loss: 4.8934e-05 - acc: 0.3445\n",
      "Epoch 32/100\n",
      "24362/24362 [==============================] - 3s 142us/step - loss: 4.3838e-05 - acc: 0.3446\n",
      "Epoch 33/100\n",
      "24362/24362 [==============================] - 3s 138us/step - loss: 4.7014e-05 - acc: 0.3445\n",
      "Epoch 34/100\n",
      "24362/24362 [==============================] - 3s 138us/step - loss: 4.2161e-05 - acc: 0.3446\n",
      "Epoch 35/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 3.8214e-05 - acc: 0.3446\n",
      "Epoch 36/100\n",
      "24362/24362 [==============================] - 3s 142us/step - loss: 4.4481e-05 - acc: 0.3445\n",
      "Epoch 37/100\n",
      "24362/24362 [==============================] - 3s 142us/step - loss: 4.3022e-05 - acc: 0.3446\n",
      "Epoch 38/100\n",
      "24362/24362 [==============================] - 3s 142us/step - loss: 4.1901e-05 - acc: 0.3445\n",
      "Epoch 39/100\n",
      "24362/24362 [==============================] - 4s 161us/step - loss: 4.0961e-05 - acc: 0.3445\n",
      "Epoch 40/100\n",
      "24362/24362 [==============================] - 4s 146us/step - loss: 3.8942e-05 - acc: 0.3446\n",
      "Epoch 41/100\n",
      "24362/24362 [==============================] - 4s 146us/step - loss: 4.3971e-05 - acc: 0.3445\n",
      "Epoch 42/100\n",
      "24362/24362 [==============================] - 4s 144us/step - loss: 4.0897e-05 - acc: 0.3445\n",
      "Epoch 43/100\n",
      "24362/24362 [==============================] - 4s 146us/step - loss: 4.0134e-05 - acc: 0.3446\n",
      "Epoch 44/100\n",
      "24362/24362 [==============================] - 3s 143us/step - loss: 4.0977e-05 - acc: 0.3445\n",
      "Epoch 45/100\n",
      "24362/24362 [==============================] - 3s 141us/step - loss: 4.0497e-05 - acc: 0.3445\n",
      "Epoch 46/100\n",
      "24362/24362 [==============================] - 4s 145us/step - loss: 4.1678e-05 - acc: 0.3445\n",
      "Epoch 47/100\n",
      "24362/24362 [==============================] - 3s 141us/step - loss: 3.6797e-05 - acc: 0.3446\n",
      "Epoch 48/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 3.4933e-05 - acc: 0.3446\n",
      "Epoch 49/100\n",
      "24362/24362 [==============================] - 3s 142us/step - loss: 3.7809e-05 - acc: 0.3445\n",
      "Epoch 50/100\n",
      "24362/24362 [==============================] - 3s 141us/step - loss: 3.7419e-05 - acc: 0.3446\n",
      "Epoch 51/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 3.7716e-05 - acc: 0.3446\n",
      "Epoch 52/100\n",
      "24362/24362 [==============================] - 3s 141us/step - loss: 4.1144e-05 - acc: 0.3445\n",
      "Epoch 53/100\n",
      "24362/24362 [==============================] - 3s 141us/step - loss: 3.9159e-05 - acc: 0.3445\n",
      "Epoch 54/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 3.8965e-05 - acc: 0.3445\n",
      "Epoch 55/100\n",
      "24362/24362 [==============================] - 3s 142us/step - loss: 3.3831e-05 - acc: 0.3446\n",
      "Epoch 56/100\n",
      "24362/24362 [==============================] - 3s 143us/step - loss: 4.3257e-05 - acc: 0.3446\n",
      "Epoch 57/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 4.1144e-05 - acc: 0.3445\n",
      "Epoch 58/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 3.9319e-05 - acc: 0.3445\n",
      "Epoch 59/100\n",
      "24362/24362 [==============================] - 4s 146us/step - loss: 3.9608e-05 - acc: 0.3445\n",
      "Epoch 60/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 3.8491e-05 - acc: 0.3446\n",
      "Epoch 61/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 3.9256e-05 - acc: 0.3445\n",
      "Epoch 62/100\n",
      "24362/24362 [==============================] - 3s 143us/step - loss: 4.0756e-05 - acc: 0.3445\n",
      "Epoch 63/100\n",
      "24362/24362 [==============================] - 3s 142us/step - loss: 3.7710e-05 - acc: 0.3446\n",
      "Epoch 64/100\n",
      "24362/24362 [==============================] - 4s 147us/step - loss: 3.6505e-05 - acc: 0.3446\n",
      "Epoch 65/100\n",
      "24362/24362 [==============================] - 4s 147us/step - loss: 4.0260e-05 - acc: 0.3445\n",
      "Epoch 66/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 3.8071e-05 - acc: 0.3446\n",
      "Epoch 67/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 3.8566e-05 - acc: 0.3445\n",
      "Epoch 68/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 3.8002e-05 - acc: 0.3446\n",
      "Epoch 69/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 3.6896e-05 - acc: 0.3446\n",
      "Epoch 70/100\n",
      "24362/24362 [==============================] - 3s 143us/step - loss: 3.9750e-05 - acc: 0.3445\n",
      "Epoch 71/100\n",
      "24362/24362 [==============================] - 3s 142us/step - loss: 3.6970e-05 - acc: 0.3446\n",
      "Epoch 72/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 3.9030e-05 - acc: 0.3446\n",
      "Epoch 73/100\n",
      "24362/24362 [==============================] - 3s 142us/step - loss: 3.8857e-05 - acc: 0.3445\n",
      "Epoch 74/100\n",
      "24362/24362 [==============================] - 3s 141us/step - loss: 3.6879e-05 - acc: 0.3445\n",
      "Epoch 75/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 3.7042e-05 - acc: 0.3446\n",
      "Epoch 76/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 3.6754e-05 - acc: 0.3446\n",
      "Epoch 77/100\n",
      "24362/24362 [==============================] - 3s 137us/step - loss: 4.0725e-05 - acc: 0.3445\n",
      "Epoch 78/100\n",
      "24362/24362 [==============================] - 3s 138us/step - loss: 4.3080e-05 - acc: 0.3446\n",
      "Epoch 79/100\n",
      "24362/24362 [==============================] - 3s 137us/step - loss: 3.8924e-05 - acc: 0.3445\n",
      "Epoch 80/100\n",
      "24362/24362 [==============================] - 3s 137us/step - loss: 3.8514e-05 - acc: 0.3446\n",
      "Epoch 81/100\n",
      "24362/24362 [==============================] - 3s 138us/step - loss: 3.7471e-05 - acc: 0.3445\n",
      "Epoch 82/100\n",
      "24362/24362 [==============================] - 3s 136us/step - loss: 4.2214e-05 - acc: 0.3446\n",
      "Epoch 83/100\n",
      "24362/24362 [==============================] - 4s 145us/step - loss: 3.8687e-05 - acc: 0.3446\n",
      "Epoch 84/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 3.9112e-05 - acc: 0.3445\n",
      "Epoch 85/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 3.9139e-05 - acc: 0.3445\n",
      "Epoch 86/100\n",
      "24362/24362 [==============================] - 3s 143us/step - loss: 3.5744e-05 - acc: 0.3445\n",
      "Epoch 87/100\n",
      "24362/24362 [==============================] - 3s 137us/step - loss: 3.7654e-05 - acc: 0.3446\n",
      "Epoch 88/100\n",
      "24362/24362 [==============================] - 3s 141us/step - loss: 3.9956e-05 - acc: 0.3445\n",
      "Epoch 89/100\n",
      "24362/24362 [==============================] - 3s 141us/step - loss: 3.9745e-05 - acc: 0.3445\n",
      "Epoch 90/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 3.5160e-05 - acc: 0.3446\n",
      "Epoch 91/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 3.7540e-05 - acc: 0.3445\n",
      "Epoch 92/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 3.4162e-05 - acc: 0.3446\n",
      "Epoch 93/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 3.9247e-05 - acc: 0.3445\n",
      "Epoch 94/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 3.4741e-05 - acc: 0.3446\n",
      "Epoch 95/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 3.2743e-05 - acc: 0.3446\n",
      "Epoch 96/100\n",
      "24362/24362 [==============================] - 3s 139us/step - loss: 3.9060e-05 - acc: 0.3445\n",
      "Epoch 97/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 3.8738e-05 - acc: 0.3445\n",
      "Epoch 98/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 3.4342e-05 - acc: 0.3446\n",
      "Epoch 99/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 3.7325e-05 - acc: 0.3445\n",
      "Epoch 100/100\n",
      "24362/24362 [==============================] - 4s 146us/step - loss: 3.8798e-05 - acc: 0.3446\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007846</td>\n",
       "      <td>0.007409</td>\n",
       "      <td>0.005702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001022</td>\n",
       "      <td>-0.000501</td>\n",
       "      <td>0.005702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000501</td>\n",
       "      <td>0.005702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001349</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>0.005702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001022</td>\n",
       "      <td>-0.000501</td>\n",
       "      <td>0.005702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual Values  Predicted Values  Mean Squared Error\n",
       "0       0.007846          0.007409            0.005702\n",
       "1       0.001022         -0.000501            0.005702\n",
       "2       0.000000         -0.000501            0.005702\n",
       "3       0.001349          0.001689            0.005702\n",
       "4       0.001022         -0.000501            0.005702"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_1 = Sequential()\n",
    "regressor_1.add(Dense(12, kernel_initializer = 'uniform',activation = 'relu',input_dim = 7))\n",
    "regressor_1.add(Dense(1, kernel_initializer = 'uniform'))\n",
    "\n",
    "# Now we will compile the regressor\n",
    "\n",
    "regressor_1.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the Artifilial Neural Network to our training data\n",
    "regressor_1.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)\n",
    "\n",
    "y_pred_wide_network = regressor_1.predict(X_test)\n",
    "\n",
    "y_pred_wide_network=y_pred_wide_network.reshape(6091,)\n",
    "temp_1={'Actual Values': y_test,'Predicted Values': y_pred_wide_network}\n",
    "y_compare_1= pd.DataFrame(temp_1)\n",
    "\n",
    "y_compare_1['Mean Squared Error'] = ((np.diff(y_compare_1.values) ** 2).mean() ** .5)\n",
    "y_compare_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24362/24362 [==============================] - 4s 161us/step - loss: 4.4981e-04 - acc: 0.3445\n",
      "Epoch 2/100\n",
      "24362/24362 [==============================] - 3s 143us/step - loss: 4.4910e-04 - acc: 0.3445\n",
      "Epoch 3/100\n",
      "24362/24362 [==============================] - 4s 145us/step - loss: 4.5016e-04 - acc: 0.3445\n",
      "Epoch 4/100\n",
      "24362/24362 [==============================] - 3s 141us/step - loss: 4.4966e-04 - acc: 0.3445\n",
      "Epoch 5/100\n",
      "24362/24362 [==============================] - 3s 141us/step - loss: 4.4991e-04 - acc: 0.3445\n",
      "Epoch 6/100\n",
      "24362/24362 [==============================] - 4s 158us/step - loss: 4.5014e-04 - acc: 0.3445\n",
      "Epoch 7/100\n",
      "24362/24362 [==============================] - 4s 153us/step - loss: 4.4957e-04 - acc: 0.3445\n",
      "Epoch 8/100\n",
      "24362/24362 [==============================] - 3s 131us/step - loss: 4.4961e-04 - acc: 0.3445\n",
      "Epoch 9/100\n",
      "24362/24362 [==============================] - 3s 127us/step - loss: 4.4977e-04 - acc: 0.3445\n",
      "Epoch 10/100\n",
      "24362/24362 [==============================] - 3s 131us/step - loss: 4.5032e-04 - acc: 0.3445\n",
      "Epoch 11/100\n",
      "24362/24362 [==============================] - 3s 125us/step - loss: 4.5017e-04 - acc: 0.3445\n",
      "Epoch 12/100\n",
      "24362/24362 [==============================] - 3s 123us/step - loss: 4.5061e-04 - acc: 0.3445\n",
      "Epoch 13/100\n",
      "24362/24362 [==============================] - 3s 124us/step - loss: 4.4985e-04 - acc: 0.3445\n",
      "Epoch 14/100\n",
      "24362/24362 [==============================] - 3s 135us/step - loss: 4.4991e-04 - acc: 0.3445\n",
      "Epoch 15/100\n",
      "24362/24362 [==============================] - 3s 124us/step - loss: 4.5019e-04 - acc: 0.3445\n",
      "Epoch 16/100\n",
      "24362/24362 [==============================] - 3s 133us/step - loss: 4.4935e-04 - acc: 0.3445\n",
      "Epoch 17/100\n",
      "24362/24362 [==============================] - 3s 143us/step - loss: 4.4955e-04 - acc: 0.3445\n",
      "Epoch 18/100\n",
      "24362/24362 [==============================] - 4s 164us/step - loss: 4.4974e-04 - acc: 0.3445\n",
      "Epoch 19/100\n",
      "24362/24362 [==============================] - 3s 131us/step - loss: 4.5045e-04 - acc: 0.3445\n",
      "Epoch 20/100\n",
      "24362/24362 [==============================] - 3s 129us/step - loss: 4.4980e-04 - acc: 0.3445\n",
      "Epoch 21/100\n",
      "24362/24362 [==============================] - 3s 128us/step - loss: 4.4893e-04 - acc: 0.3445\n",
      "Epoch 22/100\n",
      "24362/24362 [==============================] - 3s 125us/step - loss: 4.4969e-04 - acc: 0.3445\n",
      "Epoch 23/100\n",
      "24362/24362 [==============================] - 3s 132us/step - loss: 4.5035e-04 - acc: 0.3445\n",
      "Epoch 24/100\n",
      "24362/24362 [==============================] - 3s 133us/step - loss: 4.4953e-04 - acc: 0.3445\n",
      "Epoch 25/100\n",
      "24362/24362 [==============================] - 3s 132us/step - loss: 4.5006e-04 - acc: 0.3445\n",
      "Epoch 26/100\n",
      "24362/24362 [==============================] - 3s 133us/step - loss: 4.4998e-04 - acc: 0.3445\n",
      "Epoch 27/100\n",
      "24362/24362 [==============================] - 3s 132us/step - loss: 4.4965e-04 - acc: 0.3445\n",
      "Epoch 28/100\n",
      "24362/24362 [==============================] - 4s 149us/step - loss: 4.5016e-04 - acc: 0.3445\n",
      "Epoch 29/100\n",
      "24362/24362 [==============================] - 3s 133us/step - loss: 4.5011e-04 - acc: 0.3445\n",
      "Epoch 30/100\n",
      "24362/24362 [==============================] - 4s 147us/step - loss: 4.4988e-04 - acc: 0.3445\n",
      "Epoch 31/100\n",
      "24362/24362 [==============================] - 3s 126us/step - loss: 4.4999e-04 - acc: 0.3445\n",
      "Epoch 32/100\n",
      "24362/24362 [==============================] - 3s 125us/step - loss: 4.5008e-04 - acc: 0.3445\n",
      "Epoch 33/100\n",
      "24362/24362 [==============================] - 3s 125us/step - loss: 4.5019e-04 - acc: 0.3445\n",
      "Epoch 34/100\n",
      "24362/24362 [==============================] - 3s 126us/step - loss: 4.4944e-04 - acc: 0.3445\n",
      "Epoch 35/100\n",
      "24362/24362 [==============================] - 3s 123us/step - loss: 4.4989e-04 - acc: 0.3445\n",
      "Epoch 36/100\n",
      "24362/24362 [==============================] - 3s 123us/step - loss: 4.4996e-04 - acc: 0.3445\n",
      "Epoch 37/100\n",
      "24362/24362 [==============================] - 3s 123us/step - loss: 4.5021e-04 - acc: 0.3445\n",
      "Epoch 38/100\n",
      "24362/24362 [==============================] - 3s 123us/step - loss: 4.4977e-04 - acc: 0.3445\n",
      "Epoch 39/100\n",
      "24362/24362 [==============================] - 3s 123us/step - loss: 4.5014e-04 - acc: 0.3445\n",
      "Epoch 40/100\n",
      "24362/24362 [==============================] - 3s 123us/step - loss: 4.5000e-04 - acc: 0.3445\n",
      "Epoch 41/100\n",
      "24362/24362 [==============================] - 3s 129us/step - loss: 4.4949e-04 - acc: 0.3445\n",
      "Epoch 42/100\n",
      "24362/24362 [==============================] - 3s 130us/step - loss: 4.5020e-04 - acc: 0.3445\n",
      "Epoch 43/100\n",
      "24362/24362 [==============================] - 3s 130us/step - loss: 4.5001e-04 - acc: 0.3445\n",
      "Epoch 44/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 4.4946e-04 - acc: 0.3445\n",
      "Epoch 45/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 4.4896e-04 - acc: 0.3445\n",
      "Epoch 46/100\n",
      "24362/24362 [==============================] - 3s 125us/step - loss: 4.5002e-04 - acc: 0.3445\n",
      "Epoch 47/100\n",
      "24362/24362 [==============================] - 3s 133us/step - loss: 4.4972e-04 - acc: 0.3445\n",
      "Epoch 48/100\n",
      "24362/24362 [==============================] - 3s 123us/step - loss: 4.5009e-04 - acc: 0.3445\n",
      "Epoch 49/100\n",
      "24362/24362 [==============================] - 3s 123us/step - loss: 4.5013e-04 - acc: 0.3445\n",
      "Epoch 50/100\n",
      "24362/24362 [==============================] - 3s 123us/step - loss: 4.5015e-04 - acc: 0.3445\n",
      "Epoch 51/100\n",
      "24362/24362 [==============================] - 3s 124us/step - loss: 4.4956e-04 - acc: 0.3445\n",
      "Epoch 52/100\n",
      "24362/24362 [==============================] - 3s 123us/step - loss: 4.5020e-04 - acc: 0.3445\n",
      "Epoch 53/100\n",
      "24362/24362 [==============================] - 3s 123us/step - loss: 4.4983e-04 - acc: 0.3445\n",
      "Epoch 54/100\n",
      "24362/24362 [==============================] - 3s 123us/step - loss: 4.4942e-04 - acc: 0.3445\n",
      "Epoch 55/100\n",
      "24362/24362 [==============================] - 3s 141us/step - loss: 4.5037e-04 - acc: 0.3445\n",
      "Epoch 56/100\n",
      "24362/24362 [==============================] - 4s 145us/step - loss: 4.5037e-04 - acc: 0.3445\n",
      "Epoch 57/100\n",
      "24362/24362 [==============================] - 3s 138us/step - loss: 4.4934e-04 - acc: 0.3445\n",
      "Epoch 58/100\n",
      "24362/24362 [==============================] - 4s 177us/step - loss: 4.5037e-04 - acc: 0.3445\n",
      "Epoch 59/100\n",
      "24362/24362 [==============================] - 3s 143us/step - loss: 4.4998e-04 - acc: 0.3445\n",
      "Epoch 60/100\n",
      "24362/24362 [==============================] - 3s 133us/step - loss: 4.4946e-04 - acc: 0.3445\n",
      "Epoch 61/100\n",
      "24362/24362 [==============================] - 4s 145us/step - loss: 4.4966e-04 - acc: 0.3445\n",
      "Epoch 62/100\n",
      "24362/24362 [==============================] - 4s 144us/step - loss: 4.4987e-04 - acc: 0.3445\n",
      "Epoch 63/100\n",
      "24362/24362 [==============================] - 4s 152us/step - loss: 4.4936e-04 - acc: 0.3445\n",
      "Epoch 64/100\n",
      "24362/24362 [==============================] - 4s 148us/step - loss: 4.4956e-04 - acc: 0.3445\n",
      "Epoch 65/100\n",
      "24362/24362 [==============================] - 4s 176us/step - loss: 4.4956e-04 - acc: 0.3445\n",
      "Epoch 66/100\n",
      "24362/24362 [==============================] - 4s 149us/step - loss: 4.4984e-04 - acc: 0.3445\n",
      "Epoch 67/100\n",
      "24362/24362 [==============================] - 4s 145us/step - loss: 4.5028e-04 - acc: 0.3445\n",
      "Epoch 68/100\n",
      "24362/24362 [==============================] - 3s 142us/step - loss: 4.4959e-04 - acc: 0.3445\n",
      "Epoch 69/100\n",
      "24362/24362 [==============================] - 3s 140us/step - loss: 4.4978e-04 - acc: 0.3445\n",
      "Epoch 70/100\n",
      "24362/24362 [==============================] - 3s 135us/step - loss: 4.4991e-04 - acc: 0.3445\n",
      "Epoch 71/100\n",
      "24362/24362 [==============================] - 3s 135us/step - loss: 4.5086e-04 - acc: 0.3445\n",
      "Epoch 72/100\n",
      "24362/24362 [==============================] - 3s 135us/step - loss: 4.4998e-04 - acc: 0.3445\n",
      "Epoch 73/100\n",
      "24362/24362 [==============================] - 3s 137us/step - loss: 4.4934e-04 - acc: 0.3445\n",
      "Epoch 74/100\n",
      "24362/24362 [==============================] - 3s 141us/step - loss: 4.5004e-04 - acc: 0.3445\n",
      "Epoch 75/100\n",
      "24362/24362 [==============================] - 4s 146us/step - loss: 4.5002e-04 - acc: 0.3445\n",
      "Epoch 76/100\n",
      "24362/24362 [==============================] - 3s 135us/step - loss: 4.4988e-04 - acc: 0.3445\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24362/24362 [==============================] - 3s 134us/step - loss: 4.5010e-04 - acc: 0.3445\n",
      "Epoch 78/100\n",
      "24362/24362 [==============================] - 3s 130us/step - loss: 4.4967e-04 - acc: 0.3445\n",
      "Epoch 79/100\n",
      "24362/24362 [==============================] - 3s 134us/step - loss: 4.4987e-04 - acc: 0.3445\n",
      "Epoch 80/100\n",
      "24362/24362 [==============================] - 3s 130us/step - loss: 4.5040e-04 - acc: 0.3445\n",
      "Epoch 81/100\n",
      "24362/24362 [==============================] - 3s 131us/step - loss: 4.4966e-04 - acc: 0.3445\n",
      "Epoch 82/100\n",
      "24362/24362 [==============================] - 3s 133us/step - loss: 4.4965e-04 - acc: 0.3445\n",
      "Epoch 83/100\n",
      "24362/24362 [==============================] - 3s 131us/step - loss: 4.5031e-04 - acc: 0.3445\n",
      "Epoch 84/100\n",
      "24362/24362 [==============================] - 3s 132us/step - loss: 4.5001e-04 - acc: 0.3445\n",
      "Epoch 85/100\n",
      "24362/24362 [==============================] - 3s 131us/step - loss: 4.5032e-04 - acc: 0.3445\n",
      "Epoch 86/100\n",
      "24362/24362 [==============================] - 3s 132us/step - loss: 4.4975e-04 - acc: 0.3445\n",
      "Epoch 87/100\n",
      "24362/24362 [==============================] - 3s 138us/step - loss: 4.4946e-04 - acc: 0.3445\n",
      "Epoch 88/100\n",
      "24362/24362 [==============================] - 3s 128us/step - loss: 4.5052e-04 - acc: 0.3445\n",
      "Epoch 89/100\n",
      "24362/24362 [==============================] - 3s 133us/step - loss: 4.4976e-04 - acc: 0.3445\n",
      "Epoch 90/100\n",
      "24362/24362 [==============================] - 3s 131us/step - loss: 4.4949e-04 - acc: 0.3445\n",
      "Epoch 91/100\n",
      "24362/24362 [==============================] - 3s 129us/step - loss: 4.5009e-04 - acc: 0.3445\n",
      "Epoch 92/100\n",
      "24362/24362 [==============================] - 3s 129us/step - loss: 4.5015e-04 - acc: 0.3445\n",
      "Epoch 93/100\n",
      "24362/24362 [==============================] - 3s 143us/step - loss: 4.4994e-04 - acc: 0.3445\n",
      "Epoch 94/100\n",
      "24362/24362 [==============================] - 3s 136us/step - loss: 4.5000e-04 - acc: 0.3445\n",
      "Epoch 95/100\n",
      "24362/24362 [==============================] - 3s 137us/step - loss: 4.5037e-04 - acc: 0.3445\n",
      "Epoch 96/100\n",
      "24362/24362 [==============================] - 3s 134us/step - loss: 4.4966e-04 - acc: 0.3445\n",
      "Epoch 97/100\n",
      "24362/24362 [==============================] - 3s 133us/step - loss: 4.4973e-04 - acc: 0.3445\n",
      "Epoch 98/100\n",
      "24362/24362 [==============================] - 3s 135us/step - loss: 4.5046e-04 - acc: 0.3445\n",
      "Epoch 99/100\n",
      "24362/24362 [==============================] - 3s 133us/step - loss: 4.4992e-04 - acc: 0.3445\n",
      "Epoch 100/100\n",
      "24362/24362 [==============================] - 3s 134us/step - loss: 4.5070e-04 - acc: 0.3445\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007846</td>\n",
       "      <td>0.007409</td>\n",
       "      <td>0.005702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001022</td>\n",
       "      <td>-0.000501</td>\n",
       "      <td>0.005702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000501</td>\n",
       "      <td>0.005702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001349</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>0.005702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001022</td>\n",
       "      <td>-0.000501</td>\n",
       "      <td>0.005702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual Values  Predicted Values  Mean Squared Error\n",
       "0       0.007846          0.007409            0.005702\n",
       "1       0.001022         -0.000501            0.005702\n",
       "2       0.000000         -0.000501            0.005702\n",
       "3       0.001349          0.001689            0.005702\n",
       "4       0.001022         -0.000501            0.005702"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_2 = Sequential()\n",
    "regressor_2.add(Dense(4, kernel_initializer = 'normal',activation = 'relu',input_dim = 7))\n",
    "regressor_2.add(Dense(4, kernel_initializer= 'normal', activation = 'relu'))\n",
    "regressor_2.add(Dense(4, kernel_initializer= 'normal', activation = 'relu'))\n",
    "regressor_2.add(Dense(1, kernel_initializer = 'normal'))\n",
    "\n",
    "# Now we will compile the regressor\n",
    "\n",
    "regressor_2.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the Artifilial Neural Network to our training data\n",
    "regressor_2.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)\n",
    "\n",
    "y_pred_deeper_network = regressor_2.predict(X_test)\n",
    "\n",
    "y_pred_deeper_network=y_pred_deeper_network.reshape(6091,)\n",
    "temp_2={'Actual Values': y_test,'Predicted Values': y_pred_deeper_network}\n",
    "y_compare_2= pd.DataFrame(temp_2)\n",
    "\n",
    "y_compare_2['Mean Squared Error'] = ((np.diff(y_compare_2.values) ** 2).mean() ** .5)\n",
    "y_compare_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24362/24362 [==============================] - 4s 185us/step - loss: 2.0310e-04 - acc: 0.3445\n",
      "Epoch 2/100\n",
      "24362/24362 [==============================] - 4s 169us/step - loss: 8.5786e-05 - acc: 0.3445\n",
      "Epoch 3/100\n",
      "24362/24362 [==============================] - 4s 151us/step - loss: 7.5044e-05 - acc: 0.3445\n",
      "Epoch 4/100\n",
      "24362/24362 [==============================] - 4s 147us/step - loss: 6.5136e-05 - acc: 0.3446\n",
      "Epoch 5/100\n",
      "24362/24362 [==============================] - 4s 146us/step - loss: 5.9394e-05 - acc: 0.3446\n",
      "Epoch 6/100\n",
      "24362/24362 [==============================] - 4s 148us/step - loss: 5.8911e-05 - acc: 0.3445\n",
      "Epoch 7/100\n",
      "24362/24362 [==============================] - 4s 155us/step - loss: 5.7938e-05 - acc: 0.3446\n",
      "Epoch 8/100\n",
      "24362/24362 [==============================] - 4s 157us/step - loss: 5.2949e-05 - acc: 0.3446\n",
      "Epoch 9/100\n",
      "24362/24362 [==============================] - 4s 163us/step - loss: 5.2727e-05 - acc: 0.3445\n",
      "Epoch 10/100\n",
      "24362/24362 [==============================] - 4s 157us/step - loss: 4.7820e-05 - acc: 0.3446\n",
      "Epoch 11/100\n",
      "24362/24362 [==============================] - 4s 151us/step - loss: 5.0830e-05 - acc: 0.3446\n",
      "Epoch 12/100\n",
      "24362/24362 [==============================] - 4s 148us/step - loss: 4.5040e-05 - acc: 0.3446\n",
      "Epoch 13/100\n",
      "24362/24362 [==============================] - 4s 152us/step - loss: 4.7605e-05 - acc: 0.3446\n",
      "Epoch 14/100\n",
      "24362/24362 [==============================] - 4s 163us/step - loss: 4.8933e-05 - acc: 0.3446\n",
      "Epoch 15/100\n",
      "24362/24362 [==============================] - 4s 148us/step - loss: 4.1485e-05 - acc: 0.3446\n",
      "Epoch 16/100\n",
      "24362/24362 [==============================] - 4s 144us/step - loss: 4.3644e-05 - acc: 0.3446\n",
      "Epoch 17/100\n",
      "24362/24362 [==============================] - 4s 145us/step - loss: 4.3002e-05 - acc: 0.3446\n",
      "Epoch 18/100\n",
      "24362/24362 [==============================] - 3s 144us/step - loss: 4.0194e-05 - acc: 0.3446\n",
      "Epoch 19/100\n",
      "24362/24362 [==============================] - 4s 144us/step - loss: 3.7430e-05 - acc: 0.3446\n",
      "Epoch 20/100\n",
      "24362/24362 [==============================] - 4s 147us/step - loss: 4.2224e-05 - acc: 0.3445\n",
      "Epoch 21/100\n",
      "24362/24362 [==============================] - 4s 148us/step - loss: 3.4593e-05 - acc: 0.3446\n",
      "Epoch 22/100\n",
      "24362/24362 [==============================] - 4s 180us/step - loss: 4.2221e-05 - acc: 0.3446\n",
      "Epoch 23/100\n",
      "24362/24362 [==============================] - 5s 186us/step - loss: 3.6481e-05 - acc: 0.3446\n",
      "Epoch 24/100\n",
      "24362/24362 [==============================] - 4s 170us/step - loss: 3.9129e-05 - acc: 0.3446\n",
      "Epoch 25/100\n",
      "24362/24362 [==============================] - 4s 145us/step - loss: 3.6250e-05 - acc: 0.3446\n",
      "Epoch 26/100\n",
      "24362/24362 [==============================] - 4s 150us/step - loss: 3.6582e-05 - acc: 0.3446\n",
      "Epoch 27/100\n",
      "24362/24362 [==============================] - 4s 145us/step - loss: 3.3793e-05 - acc: 0.3446\n",
      "Epoch 28/100\n",
      "24362/24362 [==============================] - 4s 144us/step - loss: 3.6351e-05 - acc: 0.3446\n",
      "Epoch 29/100\n",
      "24362/24362 [==============================] - 4s 153us/step - loss: 4.1642e-05 - acc: 0.3446\n",
      "Epoch 30/100\n",
      "24362/24362 [==============================] - 4s 148us/step - loss: 3.9356e-05 - acc: 0.3446\n",
      "Epoch 31/100\n",
      "24362/24362 [==============================] - 4s 147us/step - loss: 3.7344e-05 - acc: 0.3446\n",
      "Epoch 32/100\n",
      "24362/24362 [==============================] - 4s 145us/step - loss: 3.7622e-05 - acc: 0.3446\n",
      "Epoch 33/100\n",
      "24362/24362 [==============================] - 4s 160us/step - loss: 3.4563e-05 - acc: 0.3446\n",
      "Epoch 34/100\n",
      "24362/24362 [==============================] - 4s 150us/step - loss: 4.0692e-05 - acc: 0.3445\n",
      "Epoch 35/100\n",
      "24362/24362 [==============================] - 4s 160us/step - loss: 3.4015e-05 - acc: 0.3446\n",
      "Epoch 36/100\n",
      "24362/24362 [==============================] - 4s 161us/step - loss: 3.8961e-05 - acc: 0.3446\n",
      "Epoch 37/100\n",
      "24362/24362 [==============================] - 4s 171us/step - loss: 4.1142e-05 - acc: 0.3446\n",
      "Epoch 38/100\n",
      "24362/24362 [==============================] - 4s 184us/step - loss: 2.9403e-05 - acc: 0.3446\n",
      "Epoch 39/100\n",
      "24362/24362 [==============================] - 5s 201us/step - loss: 3.2451e-05 - acc: 0.3446\n",
      "Epoch 40/100\n",
      "24362/24362 [==============================] - 4s 160us/step - loss: 3.1896e-05 - acc: 0.3446\n",
      "Epoch 41/100\n",
      "24362/24362 [==============================] - 4s 161us/step - loss: 4.0354e-05 - acc: 0.3445\n",
      "Epoch 42/100\n",
      "24362/24362 [==============================] - 5s 188us/step - loss: 3.3422e-05 - acc: 0.3446\n",
      "Epoch 43/100\n",
      "24362/24362 [==============================] - 4s 168us/step - loss: 3.3448e-05 - acc: 0.3446\n",
      "Epoch 44/100\n",
      "24362/24362 [==============================] - 4s 153us/step - loss: 3.1286e-05 - acc: 0.3446\n",
      "Epoch 45/100\n",
      "24362/24362 [==============================] - 4s 155us/step - loss: 3.1893e-05 - acc: 0.3446\n",
      "Epoch 46/100\n",
      "24362/24362 [==============================] - 4s 168us/step - loss: 3.2345e-05 - acc: 0.3446\n",
      "Epoch 47/100\n",
      "24362/24362 [==============================] - 4s 152us/step - loss: 3.0670e-05 - acc: 0.3446\n",
      "Epoch 48/100\n",
      "24362/24362 [==============================] - 4s 152us/step - loss: 3.3362e-05 - acc: 0.3446\n",
      "Epoch 49/100\n",
      "24362/24362 [==============================] - 4s 164us/step - loss: 3.2920e-05 - acc: 0.3446\n",
      "Epoch 50/100\n",
      "24362/24362 [==============================] - 4s 167us/step - loss: 2.9551e-05 - acc: 0.3446\n",
      "Epoch 51/100\n",
      "24362/24362 [==============================] - 4s 163us/step - loss: 2.8741e-05 - acc: 0.3446\n",
      "Epoch 52/100\n",
      "24362/24362 [==============================] - 4s 163us/step - loss: 3.1257e-05 - acc: 0.3446\n",
      "Epoch 53/100\n",
      "24362/24362 [==============================] - 4s 150us/step - loss: 3.1353e-05 - acc: 0.3446\n",
      "Epoch 54/100\n",
      "24362/24362 [==============================] - 4s 150us/step - loss: 2.6134e-05 - acc: 0.3446\n",
      "Epoch 55/100\n",
      "24362/24362 [==============================] - 4s 150us/step - loss: 3.0070e-05 - acc: 0.3446\n",
      "Epoch 56/100\n",
      "24362/24362 [==============================] - 4s 152us/step - loss: 2.9672e-05 - acc: 0.3446\n",
      "Epoch 57/100\n",
      "24362/24362 [==============================] - 4s 151us/step - loss: 3.0958e-05 - acc: 0.3446\n",
      "Epoch 58/100\n",
      "24362/24362 [==============================] - 4s 147us/step - loss: 2.7940e-05 - acc: 0.3446\n",
      "Epoch 59/100\n",
      "24362/24362 [==============================] - 4s 158us/step - loss: 2.6299e-05 - acc: 0.3446\n",
      "Epoch 60/100\n",
      "24362/24362 [==============================] - 4s 170us/step - loss: 2.3051e-05 - acc: 0.3446\n",
      "Epoch 61/100\n",
      "24362/24362 [==============================] - 4s 170us/step - loss: 2.5712e-05 - acc: 0.3446\n",
      "Epoch 62/100\n",
      "24362/24362 [==============================] - 4s 151us/step - loss: 2.9125e-05 - acc: 0.3446\n",
      "Epoch 63/100\n",
      "24362/24362 [==============================] - 4s 155us/step - loss: 3.1025e-05 - acc: 0.3446\n",
      "Epoch 64/100\n",
      "24362/24362 [==============================] - 4s 153us/step - loss: 2.6371e-05 - acc: 0.3446\n",
      "Epoch 65/100\n",
      "24362/24362 [==============================] - 4s 153us/step - loss: 2.7395e-05 - acc: 0.3446\n",
      "Epoch 66/100\n",
      "24362/24362 [==============================] - 4s 173us/step - loss: 2.7615e-05 - acc: 0.3446\n",
      "Epoch 67/100\n",
      "24362/24362 [==============================] - 4s 152us/step - loss: 2.7312e-05 - acc: 0.3446\n",
      "Epoch 68/100\n",
      "24362/24362 [==============================] - 4s 154us/step - loss: 2.3679e-05 - acc: 0.3446\n",
      "Epoch 69/100\n",
      "24362/24362 [==============================] - 4s 153us/step - loss: 2.5650e-05 - acc: 0.3446\n",
      "Epoch 70/100\n",
      "24362/24362 [==============================] - 4s 153us/step - loss: 2.3308e-05 - acc: 0.3446\n",
      "Epoch 71/100\n",
      "24362/24362 [==============================] - 4s 151us/step - loss: 2.8029e-05 - acc: 0.3446\n",
      "Epoch 72/100\n",
      "24362/24362 [==============================] - 4s 152us/step - loss: 2.8198e-05 - acc: 0.3446\n",
      "Epoch 73/100\n",
      "24362/24362 [==============================] - 4s 152us/step - loss: 2.9611e-05 - acc: 0.3446\n",
      "Epoch 74/100\n",
      "24362/24362 [==============================] - 4s 156us/step - loss: 2.7863e-05 - acc: 0.3446\n",
      "Epoch 75/100\n",
      "24362/24362 [==============================] - 4s 158us/step - loss: 2.5806e-05 - acc: 0.3446\n",
      "Epoch 76/100\n",
      "24362/24362 [==============================] - 4s 170us/step - loss: 2.5287e-05 - acc: 0.3446\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24362/24362 [==============================] - 4s 148us/step - loss: 2.5286e-05 - acc: 0.3446\n",
      "Epoch 78/100\n",
      "24362/24362 [==============================] - 4s 148us/step - loss: 2.8206e-05 - acc: 0.3446\n",
      "Epoch 79/100\n",
      "24362/24362 [==============================] - 4s 145us/step - loss: 2.4572e-05 - acc: 0.3446\n",
      "Epoch 80/100\n",
      "24362/24362 [==============================] - 4s 169us/step - loss: 3.0552e-05 - acc: 0.3446\n",
      "Epoch 81/100\n",
      "24362/24362 [==============================] - 4s 168us/step - loss: 2.5865e-05 - acc: 0.3446\n",
      "Epoch 82/100\n",
      "24362/24362 [==============================] - 4s 153us/step - loss: 2.6859e-05 - acc: 0.3446\n",
      "Epoch 83/100\n",
      "24362/24362 [==============================] - 4s 182us/step - loss: 2.8239e-05 - acc: 0.3446\n",
      "Epoch 84/100\n",
      "24362/24362 [==============================] - 4s 168us/step - loss: 2.4137e-05 - acc: 0.3446\n",
      "Epoch 85/100\n",
      "24362/24362 [==============================] - 5s 194us/step - loss: 2.6195e-05 - acc: 0.3446\n",
      "Epoch 86/100\n",
      "24362/24362 [==============================] - 5s 191us/step - loss: 2.4242e-05 - acc: 0.3446\n",
      "Epoch 87/100\n",
      "24362/24362 [==============================] - 4s 151us/step - loss: 2.7845e-05 - acc: 0.3446\n",
      "Epoch 88/100\n",
      "24362/24362 [==============================] - 4s 182us/step - loss: 2.7197e-05 - acc: 0.3446\n",
      "Epoch 89/100\n",
      "24362/24362 [==============================] - 4s 160us/step - loss: 3.0294e-05 - acc: 0.3446\n",
      "Epoch 90/100\n",
      "24362/24362 [==============================] - 4s 185us/step - loss: 2.3188e-05 - acc: 0.3446\n",
      "Epoch 91/100\n",
      "24362/24362 [==============================] - 4s 177us/step - loss: 2.3140e-05 - acc: 0.3446\n",
      "Epoch 92/100\n",
      "24362/24362 [==============================] - 4s 182us/step - loss: 2.6697e-05 - acc: 0.3446\n",
      "Epoch 93/100\n",
      "24362/24362 [==============================] - 4s 174us/step - loss: 2.2114e-05 - acc: 0.3446\n",
      "Epoch 94/100\n",
      "24362/24362 [==============================] - 4s 161us/step - loss: 2.5658e-05 - acc: 0.3446\n",
      "Epoch 95/100\n",
      "24362/24362 [==============================] - 4s 154us/step - loss: 2.2112e-05 - acc: 0.3446\n",
      "Epoch 96/100\n",
      "24362/24362 [==============================] - 4s 167us/step - loss: 1.9183e-05 - acc: 0.3446\n",
      "Epoch 97/100\n",
      "24362/24362 [==============================] - 4s 171us/step - loss: 2.4713e-05 - acc: 0.3446\n",
      "Epoch 98/100\n",
      "24362/24362 [==============================] - 4s 183us/step - loss: 3.2720e-05 - acc: 0.3445\n",
      "Epoch 99/100\n",
      "24362/24362 [==============================] - 4s 180us/step - loss: 2.2923e-05 - acc: 0.3446\n",
      "Epoch 100/100\n",
      "24362/24362 [==============================] - 4s 175us/step - loss: 2.2099e-05 - acc: 0.3446\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007846</td>\n",
       "      <td>0.006895</td>\n",
       "      <td>0.005795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.005795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>0.005795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001349</td>\n",
       "      <td>0.007889</td>\n",
       "      <td>0.005795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.005795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual Values  Predicted Values  Mean Squared Error\n",
       "0       0.007846          0.006895            0.005795\n",
       "1       0.001022          0.001424            0.005795\n",
       "2       0.000000         -0.000063            0.005795\n",
       "3       0.001349          0.007889            0.005795\n",
       "4       0.001022          0.000148            0.005795"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "regressor_3 = Sequential()\n",
    "regressor_3.add(Dense(4, kernel_initializer = 'normal',input_dim = 7))\n",
    "regressor_3.add(LeakyReLU(alpha=0.05))\n",
    "regressor_3.add(Dense(4, kernel_initializer= 'normal'))\n",
    "regressor_3.add(LeakyReLU(alpha=0.05))\n",
    "regressor_3.add(Dense(4, kernel_initializer= 'normal'))\n",
    "regressor_3.add(LeakyReLU(alpha=0.05))\n",
    "regressor_3.add(Dense(1, kernel_initializer = 'normal'))\n",
    "\n",
    "# Now we will compile the regressor\n",
    "\n",
    "regressor_3.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the Artifilial Neural Network to our training data\n",
    "regressor_3.fit(X_train, y_train, batch_size=5, epochs=100, verbose = 1)\n",
    "\n",
    "y_pred_leakyrelu = regressor_3.predict(X_test)\n",
    "\n",
    "y_pred_leakyrelu=y_pred_leakyrelu.reshape(6091,)\n",
    "temp_3={'Actual Values': y_test,'Predicted Values': y_pred_leakyrelu}\n",
    "y_compare_3= pd.DataFrame(temp_3)\n",
    "\n",
    "y_compare_3['Mean Squared Error'] = ((np.diff(y_compare_3.values) ** 2).mean() ** .5)\n",
    "y_compare_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
